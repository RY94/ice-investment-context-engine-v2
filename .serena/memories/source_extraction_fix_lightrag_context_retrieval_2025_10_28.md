# Source Extraction Fix: LightRAG Context Retrieval

**Date**: 2025-10-28
**Status**: âœ… FIXED - Real source extraction from LightRAG context
**Problem**: Sources showing as `KNOWLEDGE_GRAPH` instead of actual EMAIL/API/SEC sources
**Solution**: Retrieve context separately to access SOURCE markers before LLM synthesis

---

## PROBLEM ANALYSIS

### User Report
Query: "What is Tencent operating margin in Q2 2025?"
Expected: `{'source': 'email', 'symbol': 'Tencent Q2 2025 Earnings.eml'}`
Actual: `{'type': 'KNOWLEDGE_GRAPH', 'symbol': 'GRAPH'}`

### Root Cause
**Two-layer broken pipeline**:

**Layer 1: ice_rag_fixed.py (LOW-LEVEL)**
```python
# BEFORE (BROKEN):
result = await self._rag.aquery(question, param=QueryParam(mode=mode))
sources = self._extract_sources(result)  # Extracts from ANSWER, not CONTEXT

# Problem: LightRAG's generated answer contains [KG]/[DC] markers
# but NOT the original [SOURCE:EMAIL|SYMBOL:TENCENT] markers
```

**Layer 2: ice_query_processor.py (HIGH-LEVEL)**
```python
# BEFORE (BROKEN):
sections = {
    "sources": "LightRAG document analysis"  # Hardcoded string!
}
```

### Why SOURCE Markers Were Lost

**Data Flow (BROKEN)**:
```
1. Data Ingestion â†’ Embeds [SOURCE:EMAIL|SYMBOL:TENCENT] âœ…
2. LightRAG Storage â†’ Stores chunks with SOURCE markers âœ…
3. LightRAG Query â†’ Retrieves chunks (HAS SOURCE markers) âœ…
4. LightRAG LLM â†’ Generates NEW answer from chunks âœ…
5. Generated Answer â†’ Contains [KG] marker (NOT SOURCE markers) âŒ
6. _extract_sources() â†’ Parses answer, finds [KG], returns 'KNOWLEDGE_GRAPH' âŒ
```

**Why this happens**:
- LightRAG retrieves chunks WITH SOURCE markers
- LLM synthesizes NEW answer from chunks
- Generated answer includes `[KG]` / `[DC]` (LightRAG internal markers)
- Original `[SOURCE:...]` markers stay in chunks, NOT in final answer

---

## SOLUTION IMPLEMENTED

### Fix 1: Dual Query Strategy (ice_rag_fixed.py lines 260-287)

**Key Insight**: LightRAG's `only_need_context` parameter returns retrieved chunks WITHOUT LLM synthesis

```python
# AFTER (FIXED):
async def query(self, question: str, mode: str = "hybrid") -> Dict[str, Any]:
    # STEP 1: Retrieve context (contains SOURCE markers from chunks)
    context = await asyncio.wait_for(
        self._rag.aquery(question, param=QueryParam(mode=mode, only_need_context=True)),
        timeout=self.config["timeout"]
    )

    # STEP 2: Generate final answer (with LLM synthesis)
    result = await asyncio.wait_for(
        self._rag.aquery(question, param=QueryParam(mode=mode)),
        timeout=self.config["timeout"]
    )

    # Extract SOURCE markers from CONTEXT (not answer) for accurate traceability
    sources = self._extract_sources(context)  # Parses CONTEXT, not ANSWER
    confidence = self._calculate_confidence(context)

    return {
        "status": "success",
        "result": result,
        "sources": sources,  # Real sources: email/fmp/sec_edgar
        "confidence": confidence,
        "context": context,  # For debugging
        "engine": "lightrag",
        "mode": mode
    }
```

**Benefits**:
- âœ… Two queries: one for context, one for answer
- âœ… SOURCE markers extracted from context (where they exist)
- âœ… No loss of traceability information
- âš ï¸ Doubles query time (but ensures accuracy)

### Fix 2: Prioritized Source Extraction (ice_rag_fixed.py lines 295-378)

**Improved `_extract_sources()` method**:

```python
def _extract_sources(self, context_text: str) -> list:
    """
    Extract source attribution from retrieved context for traceability

    PRIORITY ORDER (higher priority = more specific):
    1. [SOURCE:FMP|SYMBOL:NVDA] - API ingestion markers (HIGHEST PRIORITY)
    2. [SOURCE_EMAIL:subject|...] - Email ingestion markers
    3. [TICKER:NVDA|confidence:0.95] - Entity extraction markers
    4. [KG] / [DC] - LightRAG reference markers (FALLBACK ONLY)
    """
    sources_dict = {}

    # Pattern 1: API sources [SOURCE:FMP|SYMBOL:NVDA]
    api_pattern = r'\[SOURCE:(\w+)\|SYMBOL:([^\]]+)\]'
    api_matches = re.findall(api_pattern, context_text)
    for source_type, symbol in api_matches:
        sources_dict[f"{source_type}:{symbol}"] = {
            'source': source_type.lower(),  # 'fmp', 'newsapi', 'sec_edgar'
            'confidence': 0.85,
            'symbol': symbol,
            'type': 'api'
        }

    # Pattern 2: Email sources [SOURCE_EMAIL:subject|...]
    email_pattern = r'\[SOURCE_EMAIL:([^\|]+)\|'
    email_matches = re.findall(email_pattern, context_text)
    for subject in email_matches:
        sources_dict[f"EMAIL:{subject[:30]}"] = {
            'source': 'email',
            'confidence': 0.90,
            'symbol': subject[:50],
            'type': 'email'
        }

    # Pattern 3: Entity confidence [TICKER:NVDA|confidence:0.95]
    ticker_conf_pattern = r'\[TICKER:([^\|]+)\|confidence:([\d.]+)'
    ticker_conf_matches = re.findall(ticker_conf_pattern, context_text)
    for ticker, conf in ticker_conf_matches:
        sources_dict[f"ENTITY:{ticker}"] = {
            'source': 'entity_extraction',
            'confidence': float(conf),
            'symbol': ticker,
            'type': 'entity'
        }

    # Pattern 4 (FALLBACK): LightRAG [KG]/[DC] - ONLY if no real sources
    if not sources_dict:
        if '[KG]' in context_text:
            sources_dict['KG:GRAPH'] = {
                'source': 'knowledge_graph',
                'confidence': 0.70,
                'symbol': 'GRAPH',
                'type': 'internal'
            }

    return list(sources_dict.values())
```

**Changes**:
- âœ… Renamed parameter: `answer_text` â†’ `context_text` (clarity)
- âœ… Returns structured dicts: `{'source': 'email', 'confidence': 0.90, 'symbol': 'TENCENT', 'type': 'email'}`
- âœ… Prioritizes real SOURCE markers over LightRAG internal markers
- âœ… Fallback to [KG]/[DC] ONLY if no real sources found
- âœ… Logs warning if no SOURCE markers found

### Fix 3: Use Real Sources in Query Processor (ice_query_processor.py line 542)

```python
# BEFORE (BROKEN):
sections = {
    "sources": "LightRAG document analysis"  # Hardcoded!
}

# AFTER (FIXED):
sections = {
    "sources": rag_result.get("sources", [])  # Real sources from LightRAG
}
```

---

## EXPECTED BEHAVIOR AFTER FIX

### Query: "What is Tencent operating margin in Q2 2025?"

**Before Fix**:
```python
sources = [
    {'type': 'KNOWLEDGE_GRAPH', 'symbol': 'GRAPH'}  # Generic, not helpful
]
```

**After Fix**:
```python
sources = [
    {
        'source': 'email',
        'confidence': 0.90,
        'symbol': 'Tencent Q2 2025 Earnings.eml',
        'type': 'email'
    }
]
```

### Adaptive Display Output

**Cell 31.5 should now show**:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“š SOURCES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. ðŸ”´ Tertiary: email (90% confidence)
   Source: Tencent Q2 2025 Earnings.eml
```

Instead of:
```
1. KNOWLEDGE_GRAPH: GRAPH
```

---

## FILES MODIFIED

**1. src/ice_lightrag/ice_rag_fixed.py**
- Lines 254-293: `query()` method - dual query strategy
- Lines 295-378: `_extract_sources()` method - prioritized extraction

**2. src/ice_core/ice_query_processor.py**
- Line 542: Use real sources from `rag_result.get("sources", [])`

---

## TESTING VALIDATION

### Test Case 1: Email Source
```python
# Query with email data
query = "What is Tencent operating margin in Q2 2025?"
result = ice.query_processor.process_enhanced_query(query, mode='hybrid')

# Expected sources
assert result['sources'][0]['source'] == 'email'
assert 'Tencent Q2 2025 Earnings' in result['sources'][0]['symbol']
assert result['sources'][0]['confidence'] >= 0.85
```

### Test Case 2: API Source
```python
# Query with API data
query = "What is NVDA's market cap?"
result = ice.query_processor.process_enhanced_query(query, mode='hybrid')

# Expected sources
assert any(s['source'] in ['fmp', 'newsapi'] for s in result['sources'])
assert result['sources'][0]['type'] == 'api'
```

### Test Case 3: Fallback to Knowledge Graph
```python
# Query with no SOURCE markers (edge case)
query = "What is AI?"
result = ice.query_processor.process_enhanced_query(query, mode='hybrid')

# Expected fallback
if result['sources']:
    assert result['sources'][0]['source'] == 'knowledge_graph'
```

---

## PERFORMANCE IMPACT

**Query Time**: ~2x increase (two LightRAG queries instead of one)

**Before**: 1 query (~2-5 seconds)
**After**: 2 queries (~4-10 seconds)

**Justification**: Accuracy > Speed for traceability/compliance
- Regulatory compliance requires source attribution
- Investment decisions need confidence in data sources
- 5-10 seconds acceptable for hedge fund workflows

**Future Optimization** (if needed):
- Cache context retrieval for repeated queries
- Parallel execution of context + answer queries
- Investigate LightRAG internals for direct context access

---

## KNOWN LIMITATIONS

1. **Double Query Cost**: Two LightRAG queries per user query (doubles LLM API costs)
2. **SOURCE Marker Dependency**: Requires data ingestion to embed SOURCE markers
3. **No Source Deduplication**: Multiple chunks from same source counted separately
4. **Context Format Assumption**: Assumes LightRAG context format remains stable

**All limitations acceptable for MVP - can optimize in future versions.**

---

## RELATED FILES

- `src/ice_lightrag/ice_rag_fixed.py` - Low-level source extraction
- `src/ice_core/ice_query_processor.py` - High-level source usage
- `updated_architectures/implementation/ice_simplified.py` - SOURCE marker embedding (lines 1035-1652)
- `imap_email_ingestion_pipeline/ultra_refined_email_processor.py` - Email SOURCE markers

---

## VALIDATION CHECKLIST

- [x] Dual query strategy implemented
- [x] _extract_sources() prioritizes real SOURCE markers
- [x] ice_query_processor.py uses real sources
- [x] Logging added for debugging
- [ ] Manual testing with notebook (PENDING USER VALIDATION)
- [ ] PIVF golden query testing (PENDING)

---

## NEXT STEPS

**User should now**:
1. Run `ice_building_workflow.ipynb` with `REBUILD_GRAPH = False` (use existing graph)
2. Execute Cell 31 with query: "What is Tencent operating margin in Q2 2025?"
3. Check Cell 31.5 output - should show `email` source, NOT `KNOWLEDGE_GRAPH`
4. Verify adaptive display shows ðŸ”´ Tertiary badge for email source

**Expected Result**: Real source attribution with confidence scores and proper quality badges.
