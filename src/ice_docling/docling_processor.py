# Location: src/ice_docling/docling_processor.py
# Purpose: Drop-in replacement for AttachmentProcessor using docling
# Why: Improve table extraction accuracy from 42% (PyPDF2) to 97.9% (docling)
# Relevant Files: attachment_processor.py, data_ingestion.py

"""
Docling Email Attachment Processor

API-compatible replacement for AttachmentProcessor with enhanced table extraction.

Architecture: REPLACEMENT Pattern
- Both implementations coexist (AttachmentProcessor remains untouched)
- Identical API: process_attachment(attachment_data, email_uid) ‚Üí Dict
- Toggle controls which processor is used (config.use_docling_email)
- Storage paths match exactly for seamless switching

Key Improvements:
- Table accuracy: 42% (PyPDF2) ‚Üí 97.9% (docling)
- AI-powered layout analysis (DocLayNet model)
- AI-powered table detection (TableFormer model)
- Supports: PDF, Excel, Word, PowerPoint

Design Decisions:
- No base class: Standalone for simplicity (~150 lines)
- API compatibility: Same signature as AttachmentProcessor
- Storage compatibility: Exact same directory structure
- Error handling: Clear messages with actionable solutions
"""

from pathlib import Path
from typing import Dict, Any, List
import hashlib
import logging

class DoclingProcessor:
    """
    Email attachment processor using docling

    Drop-in replacement for AttachmentProcessor:
    - Same __init__ signature
    - Same process_attachment() signature
    - Same return dict structure
    - Same storage path structure
    """

    def __init__(self, storage_path: str = "./data/attachments"):
        """
        Initialize docling processor

        Args:
            storage_path: Directory for storing processed attachments
                         MUST match AttachmentProcessor for compatibility
                         Example: "data/attachments"
                         Default: "./data/attachments" (matches AttachmentProcessor)
        """
        # Initialize docling converter
        try:
            from docling.document_converter import DocumentConverter
            self.converter = DocumentConverter()
        except ImportError as e:
            raise ImportError(
                "Docling not installed. Install with: pip install docling\n"
                "Or run: python scripts/download_docling_models.py"
            ) from e

        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        # Match AttachmentProcessor settings exactly
        self.max_file_size = 50 * 1024 * 1024  # 50MB (same as AttachmentProcessor)

        self.logger = logging.getLogger(__name__)
        self.logger.info(f"DoclingProcessor initialized: storage={storage_path}")

    def process_attachment(self, attachment_data: Dict[str, Any], email_uid: str) -> Dict[str, Any]:
        """
        Process attachment with docling (API-compatible with AttachmentProcessor)

        Args:
            attachment_data: Dict with keys:
                - 'part': Email part object
                - 'filename': Attachment filename
                - 'content_type': MIME type
            email_uid: Email unique identifier (for storage organization)

        Returns:
            Dict with exact same structure as AttachmentProcessor:
            {
                'filename': str,
                'file_hash': str,
                'mime_type': str,
                'file_size': int,
                'storage_path': str,
                'processing_status': 'completed' | 'failed',
                'extraction_method': 'docling',  # Identifies which processor used
                'extracted_text': str,
                'extracted_data': dict,  # {'tables': [...]}
                'page_count': int,
                'error': str | None
            }
        """
        try:
            # 1. Extract and validate content (match AttachmentProcessor logic)
            content = attachment_data['part'].get_payload(decode=True)
            if not content:
                return {
                    'error': 'No content in attachment',
                    'processing_status': 'failed',
                    'filename': attachment_data.get('filename', 'unknown')
                }

            if len(content) > self.max_file_size:
                return {
                    'error': f'File too large: {len(content)} bytes (max: {self.max_file_size})',
                    'filename': attachment_data['filename'],
                    'file_size': len(content),
                    'processing_status': 'failed'
                }

            # 2. Generate file hash (for deduplication, match AttachmentProcessor)
            file_hash = hashlib.sha256(content).hexdigest()

            # 3. Create storage directory (EXACT same structure as AttachmentProcessor)
            # Structure: storage_path / email_uid / file_hash / {original, extracted.txt}
            storage_dir = self.storage_path / email_uid / file_hash
            storage_dir.mkdir(parents=True, exist_ok=True)

            # 4. Save original file
            original_path = storage_dir / 'original' / attachment_data['filename']
            original_path.parent.mkdir(parents=True, exist_ok=True)
            original_path.write_bytes(content)
            self.logger.debug(f"Saved original: {original_path}")

            # 5. Convert with docling
            try:
                # Log processing start for large files
                if len(content) > 1024 * 1024:  # > 1MB
                    self.logger.info(f"üîÑ Processing large file ({len(content) / (1024 * 1024):.1f}MB): {attachment_data['filename']}")

                result = self.converter.convert(str(original_path))
                text = result.document.export_to_markdown()

                # Extract tables (docling-specific)
                tables = self._extract_tables(result)

                page_count = getattr(result.document, 'num_pages', 1)

                # Enhanced logging with more context
                log_msg = f"‚úÖ Docling conversion: {attachment_data['filename']}, "
                log_msg += f"{len(text)} chars, {len(tables)} tables, {page_count} pages"

                # Add warnings for potentially concerning scenarios
                if len(tables) == 0 and 'financial' in attachment_data['filename'].lower():
                    log_msg += " ‚ö†Ô∏è No tables extracted from financial document"
                if len(text) < 100:
                    log_msg += " ‚ö†Ô∏è Very little text extracted"

                self.logger.info(log_msg)

            except ImportError as e:
                # Specific error for missing Docling installation
                self.logger.error(f"‚ùå Docling not properly installed: {e}")
                return {
                    'error': (
                        f"‚ùå Docling installation issue for {attachment_data.get('filename')}\n"
                        f"Reason: {str(e)}\n"
                        f"Solutions:\n"
                        f"  1. Install: pip install docling\n"
                        f"  2. Run: python scripts/download_docling_models.py\n"
                        f"  3. Fallback: export USE_DOCLING_EMAIL=false"
                    ),
                    'filename': attachment_data.get('filename', 'unknown'),
                    'processing_status': 'failed'
                }
            except (OSError, IOError) as e:
                # File access errors
                self.logger.error(f"‚ùå File access error: {e}")
                return {
                    'error': (
                        f"‚ùå Cannot access file {attachment_data.get('filename')}\n"
                        f"Reason: {str(e)}\n"
                        f"Check: File permissions and path"
                    ),
                    'filename': attachment_data.get('filename', 'unknown'),
                    'processing_status': 'failed'
                }
            except Exception as e:
                # Generic docling conversion error with detailed context
                self.logger.error(f"‚ùå Docling conversion failed for {attachment_data.get('filename')}: {e}", exc_info=True)
                return {
                    'error': (
                        f"‚ùå Docling processing failed for {attachment_data.get('filename')}\n"
                        f"Error type: {type(e).__name__}\n"
                        f"Reason: {str(e)}\n"
                        f"Solutions:\n"
                        f"  1. Check file format compatibility (PDF, DOCX, PPTX, XLSX, images)\n"
                        f"  2. Try fallback: export USE_DOCLING_EMAIL=false\n"
                        f"  3. Report issue with file type and error details"
                    ),
                    'filename': attachment_data.get('filename', 'unknown'),
                    'processing_status': 'failed'
                }

            # 6. Save extracted text
            extracted_path = storage_dir / 'extracted.txt'
            extracted_path.write_text(text, encoding='utf-8')
            self.logger.debug(f"Saved extracted text: {extracted_path}")

            # 7. Build result dict (API-compatible with AttachmentProcessor)
            return {
                'filename': attachment_data['filename'],
                'file_hash': file_hash,
                'mime_type': attachment_data.get('content_type', 'application/octet-stream'),
                'file_size': len(content),
                'storage_path': str(storage_dir),
                'processing_status': 'completed',
                'extraction_method': 'docling',  # Identifies processor used (vs 'pypdf2')
                'extracted_text': text,
                'extracted_data': {'tables': tables},  # Match AttachmentProcessor format
                'page_count': page_count,
                'error': None
            }

        except Exception as e:
            # Catch-all error handling
            self.logger.error(f"Unexpected error processing {attachment_data.get('filename')}: {e}")
            return {
                'error': f'Processing error: {str(e)}',
                'filename': attachment_data.get('filename', 'unknown'),
                'processing_status': 'failed'
            }

    def process_pdf_bytes(self, pdf_bytes: bytes, filename: str) -> Dict[str, Any]:
        """
        Process PDF from bytes (for URL-downloaded PDFs)

        API-compatible with process_attachment() - returns same dict structure.
        Optimized for processing PDF bytes from URL downloads without temp files.

        Args:
            pdf_bytes: PDF content as bytes (from URL download)
            filename: Original filename for identification and error messages

        Returns:
            Dict with same structure as process_attachment():
            {
                'filename': str,
                'extracted_text': str,
                'extracted_data': {'tables': [...]},
                'extraction_method': 'docling',
                'page_count': int,
                'processing_status': 'completed' | 'failed',
                'error': str | None
            }

        Reference:
            Official BytesIO API: https://github.com/docling-project/docling/blob/main/docling/document_converter.py#L278-303
        """
        try:
            # 1. Validate input
            if not pdf_bytes or len(pdf_bytes) < 1024:  # Minimum valid PDF size
                return {
                    'error': f'Invalid PDF content for {filename} (size: {len(pdf_bytes)} bytes, minimum: 1024)',
                    'filename': filename,
                    'processing_status': 'failed'
                }

            if len(pdf_bytes) > self.max_file_size:
                return {
                    'error': f'File too large: {len(pdf_bytes)} bytes (max: {self.max_file_size})',
                    'filename': filename,
                    'file_size': len(pdf_bytes),
                    'processing_status': 'failed'
                }

            # 2. Create BytesIO stream + DocumentStream (official API)
            from io import BytesIO
            from docling_core.types.io import DocumentStream

            buffer = BytesIO(pdf_bytes)
            doc_stream = DocumentStream(
                name=filename,      # Filename for identification
                stream=buffer       # Byte stream content
            )

            # 3. Convert with docling (same API as file path approach)
            try:
                # Log processing start for large files
                if len(pdf_bytes) > 1024 * 1024:  # > 1MB
                    self.logger.info(f"üîÑ Processing large URL PDF ({len(pdf_bytes) / (1024 * 1024):.1f}MB): {filename}")

                result = self.converter.convert(doc_stream)
                text = result.document.export_to_markdown()

                # Extract tables (reuse existing method)
                tables = self._extract_tables(result)

                page_count = getattr(result.document, 'num_pages', 1)

                # Enhanced logging with more context
                log_msg = f"‚úÖ Docling conversion from bytes: {filename}, "
                log_msg += f"{len(text)} chars, {len(tables)} tables, {page_count} pages"

                # Add warnings for potentially concerning scenarios
                if len(tables) == 0 and ('financial' in filename.lower() or 'earning' in filename.lower()):
                    log_msg += " ‚ö†Ô∏è No tables extracted from financial document"
                if len(text) < 100:
                    log_msg += " ‚ö†Ô∏è Very little text extracted"

                self.logger.info(log_msg)

            except ImportError as e:
                # Specific error for missing Docling installation
                self.logger.error(f"‚ùå Docling not properly installed: {e}")
                return {
                    'error': (
                        f"‚ùå Docling installation issue for {filename}\n"
                        f"Reason: {str(e)}\n"
                        f"Solutions:\n"
                        f"  1. Install: pip install docling docling-core\n"
                        f"  2. Run: python scripts/download_docling_models.py\n"
                        f"  3. Fallback: export USE_DOCLING_URLS=false"
                    ),
                    'filename': filename,
                    'processing_status': 'failed'
                }
            except Exception as e:
                # Generic docling conversion error with detailed context
                self.logger.error(f"‚ùå Docling conversion failed for {filename}: {e}", exc_info=True)
                return {
                    'error': (
                        f"‚ùå Docling processing failed for {filename}\n"
                        f"Error type: {type(e).__name__}\n"
                        f"Reason: {str(e)}\n"
                        f"Solutions:\n"
                        f"  1. Check PDF format compatibility\n"
                        f"  2. Try fallback: export USE_DOCLING_URLS=false (to use pdfplumber)\n"
                        f"  3. Report issue with URL and error details"
                    ),
                    'filename': filename,
                    'processing_status': 'failed'
                }

            # 4. Return result (API-compatible format)
            return {
                'filename': filename,
                'extracted_text': text,
                'extracted_data': {'tables': tables},
                'extraction_method': 'docling',
                'page_count': page_count,
                'processing_status': 'completed',
                'error': None
            }

        except Exception as e:
            # Catch-all error handling
            self.logger.error(f"Unexpected error processing PDF bytes for {filename}: {e}")
            return {
                'error': f'Processing error: {str(e)}',
                'filename': filename,
                'processing_status': 'failed'
            }

    def _extract_tables(self, result) -> List[Dict[str, Any]]:
        """
        Extract tables from docling result using AI-powered table detection
        
        Docling provides professional-grade table extraction via TableFormer model.
        Each table is converted to pandas DataFrame for structured access.
        
        Args:
            result: Docling ConversionResult object with document attribute
        
        Returns:
            List of table dictionaries:
            [
                {
                    'index': 0,
                    'data': pd.DataFrame as dict (orient='records'),
                    'num_rows': int,
                    'num_cols': int,
                    'markdown': str (optional table preview),
                    'error': None | str (if export failed)
                },
                ...
            ]
        
        Reference: 
        - Official example: https://github.com/docling-project/docling/blob/main/docs/examples/export_tables.py
        - API: table.export_to_dataframe(doc=document) returns pandas DataFrame
        """
        tables = []
        
        # Access docling's detected tables
        if not hasattr(result, 'document'):
            self.logger.warning("Result has no 'document' attribute, cannot extract tables")
            return tables
        
        if not hasattr(result.document, 'tables'):
            self.logger.warning("Document has no 'tables' attribute, cannot extract tables")
            return tables
        
        # Iterate through detected tables
        for table_ix, table in enumerate(result.document.tables):
            try:
                # Export to pandas DataFrame (official docling API)
                # Pass doc argument to avoid deprecation warning (as of docling 1.7+)
                # This leverages TableFormer AI model for structure recognition
                table_df = table.export_to_dataframe(doc=result.document)
                
                # Convert DataFrame to structured dict
                table_data = {
                    'index': table_ix,
                    'data': table_df.to_dict(orient='records'),  # List of row dicts
                    'num_rows': len(table_df),
                    'num_cols': len(table_df.columns),
                    'error': None
                }
                
                # Add markdown preview for debugging/logging
                try:
                    table_data['markdown'] = table_df.to_markdown(index=False)
                except:
                    pass  # Markdown conversion optional, don't fail on error
                
                tables.append(table_data)
                
                self.logger.debug(
                    f"Extracted table {table_ix}: {table_data['num_rows']} rows, "
                    f"{table_data['num_cols']} cols"
                )
                
            except Exception as e:
                # Log error but continue processing other tables
                self.logger.error(f"Failed to extract table {table_ix}: {e}")
                tables.append({
                    'index': table_ix,
                    'data': [],
                    'num_rows': 0,
                    'num_cols': 0,
                    'error': str(e)
                })
        
        self.logger.info(f"Extracted {len(tables)} table(s) from document")
        return tables
