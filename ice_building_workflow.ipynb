{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICE Building Workflow - Knowledge Graph Construction\n",
    "\n",
    "**Purpose**: Comprehensive data ingestion and knowledge graph building for investment intelligence\n",
    "**Architecture**: ICE Simplified (2,508 lines) with LightRAG integration\n",
    "**Input**: Financial data from multiple sources ‚Üí **Output**: Searchable knowledge graph\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Environment Setup** - Initialize ICE system and configure data sources\n",
    "2. **Workflow Mode Selection** - Choose between initial build or incremental update\n",
    "3. **Data Ingestion** - Fetch financial data from APIs and process documents\n",
    "4. **Knowledge Graph Building** - Extract entities, relationships, and build LightRAG graph\n",
    "5. **Storage & Validation** - Verify graph construction and monitor storage\n",
    "6. **Metrics & Monitoring** - Track processing metrics and system health\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & System Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ICE Building Workflow\n",
      "üìÖ 2025-10-12 22:51\n",
      "üìÅ Working Directory: /Users/royyeo/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Capstone Project\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Configure environment\n",
    "os.environ.setdefault('ICE_WORKING_DIR', './src/ice_lightrag/storage')\n",
    "\n",
    "print(f\"üöÄ ICE Building Workflow\")\n",
    "print(f\"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"üìÅ Working Directory: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ice_data_ingestion.ice_integration:ICE LightRAG system initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LightRAG successfully imported!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ice_data_ingestion.ice_integration:ICE LightRAG system initialized successfully\n",
      "INFO:updated_architectures.implementation.ice_simplified:ICE Core initializing with ICESystemManager orchestration\n",
      "INFO:src.ice_core.ice_system_manager:ICE System Manager initialized with working_dir: ice_lightrag/storage\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ ICESystemManager initialized successfully\n",
      "INFO:updated_architectures.implementation.ice_simplified:Data Ingester initialized with 4 API services\n",
      "INFO:updated_architectures.implementation.ice_simplified:Query Engine initialized\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ ICE Simplified system initialized successfully\n",
      "INFO:src.ice_core.ice_system_manager:LightRAG wrapper created successfully (lazy initialization mode)\n",
      "INFO:src.ice_core.ice_system_manager:Exa MCP connector initialized successfully\n",
      "INFO:src.ice_core.ice_graph_builder:ICE Graph Builder initialized\n",
      "INFO:src.ice_core.ice_graph_builder:LightRAG instance updated in Graph Builder\n",
      "INFO:src.ice_core.ice_system_manager:Graph Builder initialized successfully\n",
      "INFO:src.ice_core.ice_query_processor:ICE Query Processor initialized\n",
      "INFO:src.ice_core.ice_system_manager:Query Processor initialized successfully\n",
      "INFO:updated_architectures.implementation.ice_simplified:System health: ready=True\n",
      "INFO:updated_architectures.implementation.ice_simplified:Components: {'lightrag': True, 'exa_connector': True, 'graph_builder': True, 'query_processor': True, 'data_manager': False}\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ ICE system created and ready for operations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ICE System Initialized\n",
      "üß† LightRAG Status: Ready\n",
      "üìä Architecture: ICE Simplified (2,508 lines)\n",
      "üîó Components: Core + Ingester + QueryEngine\n"
     ]
    }
   ],
   "source": [
    "# Initialize ICE system\n",
    "from updated_architectures.implementation.ice_simplified import create_ice_system\n",
    "\n",
    "try:\n",
    "    ice = create_ice_system()\n",
    "    system_ready = ice.is_ready()\n",
    "    print(f\"‚úÖ ICE System Initialized\")\n",
    "    print(f\"üß† LightRAG Status: {'Ready' if system_ready else 'Initializing'}\")\n",
    "    print(f\"üìä Architecture: ICE Simplified (2,508 lines)\")\n",
    "    print(f\"üîó Components: Core + Ingester + QueryEngine\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Initialization Error: {e}\")\n",
    "    raise  # Let errors surface for proper debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ LightRAG Storage Architecture Verification\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "LightRAG Storage Components:\n",
      "  chunks_vdb: ‚úÖ Initialized\n",
      "    Purpose: Vector database for document chunks\n",
      "    File: vdb_chunks.json\n",
      "    Size: 0.01 MB\n",
      "  entities_vdb: ‚úÖ Initialized\n",
      "    Purpose: Vector database for extracted entities\n",
      "    File: vdb_entities.json\n",
      "    Size: 0.04 MB\n",
      "  relationships_vdb: ‚úÖ Initialized\n",
      "    Purpose: Vector database for entity relationships\n",
      "    File: vdb_relationships.json\n",
      "    Size: 0.03 MB\n",
      "  graph: ‚úÖ Initialized\n",
      "    Purpose: NetworkX graph structure\n",
      "    File: graph_chunk_entity_relation.graphml\n",
      "    Size: 0.01 MB\n",
      "\n",
      "üìÅ Working Directory: ice_lightrag/storage\n",
      "üóÑÔ∏è Storage Backend: File-based (development mode)\n",
      "üíæ Total Storage: 0.12 MB\n"
     ]
    }
   ],
   "source": [
    "# Verify storage architecture and components\n",
    "print(f\"üì¶ LightRAG Storage Architecture Verification\")\n",
    "print(f\"‚îÅ\" * 40)\n",
    "\n",
    "if not (ice and ice.core.is_ready()):\n",
    "    raise RuntimeError(\"ICE system not ready - cannot verify storage\")\n",
    "\n",
    "# Get storage statistics using new method\n",
    "storage_stats = ice.core.get_storage_stats()\n",
    "\n",
    "print(f\"LightRAG Storage Components:\")\n",
    "for component_name, component_info in storage_stats['components'].items():\n",
    "    status = \"‚úÖ Initialized\" if component_info['exists'] else \"‚ö†Ô∏è Not created yet\"\n",
    "    size_mb = component_info['size_bytes'] / (1024 * 1024) if component_info['size_bytes'] > 0 else 0\n",
    "    print(f\"  {component_name}: {status}\")\n",
    "    print(f\"    Purpose: {component_info['description']}\")\n",
    "    print(f\"    File: {component_info['file']}\")\n",
    "    if size_mb > 0:\n",
    "        print(f\"    Size: {size_mb:.2f} MB\")\n",
    "\n",
    "print(f\"\\nüìÅ Working Directory: {storage_stats['working_dir']}\")\n",
    "print(f\"üóÑÔ∏è Storage Backend: File-based (development mode)\")\n",
    "print(f\"üíæ Total Storage: {storage_stats['total_storage_bytes'] / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì° Data Sources Available: 4\n",
      "  ‚úÖ alpha_vantage\n",
      "  ‚úÖ newsapi\n",
      "  ‚úÖ polygon\n",
      "  ‚úÖ finnhub\n",
      "\n",
      "üîë OpenAI API: ‚úÖ Configured\n"
     ]
    }
   ],
   "source": [
    "# Data sources configuration status\n",
    "if not (ice and hasattr(ice, 'ingester')):\n",
    "    raise RuntimeError(\"Data ingester not initialized\")\n",
    "\n",
    "available_services = ice.ingester.available_services\n",
    "print(f\"\\nüì° Data Sources Available: {len(available_services)}\")\n",
    "for service in available_services:\n",
    "    print(f\"  ‚úÖ {service}\")\n",
    "\n",
    "if not available_services:\n",
    "    print(f\"  ‚ö†Ô∏è No APIs configured - will use sample data\")\n",
    "    print(f\"  üí° Set NEWSAPI_ORG_API_KEY for real news\")\n",
    "    print(f\"  üí° Set ALPHA_VANTAGE_API_KEY for financial data\")\n",
    "\n",
    "# Validate OpenAI for LightRAG\n",
    "openai_configured = bool(os.getenv('OPENAI_API_KEY'))\n",
    "print(f\"\\nüîë OpenAI API: {'‚úÖ Configured' if openai_configured else '‚ùå Required for full functionality'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workflow Mode Selection & Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Model Provider Configuration\n",
    "\n",
    "ICE supports **OpenAI** (paid) or **Ollama** (free local) for LLM and embeddings:\n",
    "\n",
    "#### Option 1: OpenAI (Default - No setup required)\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"sk-...\"\n",
    "```\n",
    "- **Cost**: ~$5/month for typical usage\n",
    "- **Quality**: Highest accuracy for entity extraction and reasoning\n",
    "- **Setup**: Just set API key\n",
    "\n",
    "#### Option 2: Ollama (Free Local - Requires setup)\n",
    "```bash\n",
    "# Set provider\n",
    "export LLM_PROVIDER=\"ollama\"\n",
    "\n",
    "# One-time setup:\n",
    "ollama serve                      # Start Ollama service\n",
    "ollama pull qwen3:30b-32k        # Pull LLM model (32k context required)\n",
    "ollama pull nomic-embed-text      # Pull embedding model\n",
    "```\n",
    "- **Cost**: $0/month (completely free)\n",
    "- **Quality**: Good for most investment analysis tasks\n",
    "- **Setup**: Requires local Ollama installation and model download\n",
    "\n",
    "#### Option 3: Hybrid (Recommended for cost-conscious users)\n",
    "```bash\n",
    "export LLM_PROVIDER=\"ollama\"           # Use Ollama for LLM\n",
    "export EMBEDDING_PROVIDER=\"openai\"     # Use OpenAI for embeddings\n",
    "export OPENAI_API_KEY=\"sk-...\"\n",
    "```\n",
    "- **Cost**: ~$2/month (embeddings only)\n",
    "- **Quality**: Balanced - free LLM with high-quality embeddings\n",
    "\n",
    "**Current configuration will be logged when you run the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Switched to Full Ollama (llama3.1:8b - faster)\n"
     ]
    }
   ],
   "source": [
    "# ### Provider Switching - Uncomment ONE option below, then restart kernel\n",
    "\n",
    "#############################################################################\n",
    "#                              Model Selection                              #\n",
    "#############################################################################\n",
    "\n",
    "# ### Option 1: OpenAI ($5/mo, highest quality)\n",
    "# import os; os.environ['LLM_PROVIDER'] = 'openai'\n",
    "# print(\"‚úÖ Switched to OpenAI\")\n",
    "\n",
    "# ###Option 2: Hybrid ($2/mo, 60% savings, recommended)\n",
    "# import os; os.environ['LLM_PROVIDER'] = 'ollama'; os.environ['EMBEDDING_PROVIDER'] = 'openai'\n",
    "# print(\"‚úÖ Switched to Hybrid\")\n",
    "\n",
    "### Option 3: Full Ollama ($0/mo, faster model)\n",
    "import os; os.environ['LLM_PROVIDER'] = 'ollama'; os.environ['EMBEDDING_PROVIDER'] = 'ollama'; \n",
    "# os.environ['LLM_MODEL'] = 'llama3.1:8b'\n",
    "os.environ['LLM_MODEL'] = 'qwen3:8b'\n",
    "# os.environ['LLM_MODEL'] = 'qwen3:14b'\n",
    "# os.environ['LLM_MODEL'] = 'qwen3:30b-32k'\n",
    "print(\"‚úÖ Switched to Full Ollama (llama3.1:8b - faster)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóëÔ∏è Graph Management (Optional)\n",
    "\n",
    "**When to clear the graph:**\n",
    "- ‚úÖ Switching to Full Ollama (1536-dim ‚Üí 768-dim embeddings)\n",
    "- ‚úÖ Graph corrupted or very old (>30 days without updates)\n",
    "- ‚úÖ Testing fresh graph builds from scratch\n",
    "\n",
    "**When NOT to clear:**\n",
    "- ‚ùå Just switching LLM provider (OpenAI ‚Üî Hybrid use same embeddings)\n",
    "- ‚ùå Adding new documents (incremental updates work fine)\n",
    "- ‚ùå Changing query modes (local, hybrid, etc.)\n",
    "\n",
    "**How to clear:**\n",
    "Run the code cell below (uncomment lines to activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:updated_architectures.implementation.ice_simplified:ICE Core initializing with ICESystemManager orchestration\n",
      "INFO:src.ice_core.ice_system_manager:ICE System Manager initialized with working_dir: ice_lightrag/storage\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ ICESystemManager initialized successfully\n",
      "INFO:updated_architectures.implementation.ice_simplified:Data Ingester initialized with 4 API services\n",
      "INFO:updated_architectures.implementation.ice_simplified:Query Engine initialized\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ ICE Simplified system initialized successfully\n",
      "INFO:src.ice_core.ice_system_manager:LightRAG wrapper created successfully (lazy initialization mode)\n",
      "INFO:src.ice_core.ice_system_manager:Exa MCP connector initialized successfully\n",
      "INFO:src.ice_core.ice_graph_builder:ICE Graph Builder initialized\n",
      "INFO:src.ice_core.ice_graph_builder:LightRAG instance updated in Graph Builder\n",
      "INFO:src.ice_core.ice_system_manager:Graph Builder initialized successfully\n",
      "INFO:src.ice_core.ice_query_processor:ICE Query Processor initialized\n",
      "INFO:src.ice_core.ice_system_manager:Query Processor initialized successfully\n",
      "INFO:updated_architectures.implementation.ice_simplified:System health: ready=True\n",
      "INFO:updated_architectures.implementation.ice_simplified:Components: {'lightrag': True, 'exa_connector': True, 'graph_builder': True, 'query_processor': True, 'data_manager': False}\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ ICE system created and ready for operations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ vdb_entities.json: 0.04 MB\n",
      "  ‚úÖ vdb_relationships.json: 0.03 MB\n",
      "  ‚úÖ vdb_chunks.json: 0.01 MB\n",
      "  ‚úÖ graph_chunk_entity_relation.graphml: 0.01 MB\n",
      "  üíæ Total: 0.09 MB\n",
      "\n",
      "üß¨ Graph Health Metrics:\n",
      "  üìä Content Coverage:\n",
      "    Tickers: None (0/4 portfolio holdings)\n",
      "\n",
      "  üï∏Ô∏è Graph Structure:\n",
      "    Total entities: 6\n",
      "    Total relationships: 5\n",
      "    Avg connections: 0.83\n",
      "\n",
      "  üíº Investment Signals:\n",
      "    BUY signals: 0\n",
      "    SELL signals: 0\n",
      "    Price targets: 0\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#                    Check graph info                    #\n",
    "##########################################################\n",
    "from updated_architectures.implementation.ice_simplified import create_ice_system\n",
    "ice = create_ice_system()\n",
    "\n",
    "\n",
    "##########################################################\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def check_storage(storage_path):\n",
    "    \"\"\"Check and display storage file inventory\"\"\"\n",
    "    files = ['vdb_entities.json', 'vdb_relationships.json', 'vdb_chunks.json', 'graph_chunk_entity_relation.graphml']\n",
    "    total_size = 0\n",
    "    for fname in files:\n",
    "        fpath = storage_path / fname\n",
    "        if fpath.exists():\n",
    "            size_mb = fpath.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  ‚úÖ {fname}: {size_mb:.2f} MB\")\n",
    "            total_size += size_mb\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  {fname}: not found\")\n",
    "    print(f\"  üíæ Total: {total_size:.2f} MB\")\n",
    "\n",
    "# Use actual config path instead of hardcoded path to avoid path mismatches\n",
    "storage_path = Path(ice.config.working_dir)\n",
    "\n",
    "check_storage(storage_path)\n",
    "\n",
    "#####################################################################\n",
    "ice.core.get_graph_stats()\n",
    "\n",
    "##########################################################\n",
    "#              Graph Health Metrics (P0)                 #\n",
    "##########################################################\n",
    "\n",
    "def check_graph_health(storage_path):\n",
    "    \"\"\"Check critical graph health metrics (P0 only)\"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    \n",
    "    TICKERS = {'NVDA', 'TSMC', 'AMD', 'ASML'}  # Known portfolio tickers\n",
    "    \n",
    "    result = {\n",
    "        'tickers_covered': set(),\n",
    "        'total_entities': 0,\n",
    "        'total_relationships': 0,\n",
    "        'buy_signals': 0,\n",
    "        'sell_signals': 0,\n",
    "        'price_targets': 0\n",
    "    }\n",
    "    \n",
    "    # Parse entities\n",
    "    entities_file = Path(storage_path) / 'vdb_entities.json'\n",
    "    if entities_file.exists():\n",
    "        data = json.loads(entities_file.read_text())\n",
    "        result['total_entities'] = len(data.get('data', []))\n",
    "        \n",
    "        for entity in data.get('data', []):\n",
    "            text = f\"{entity.get('entity_name', '')} {entity.get('content', '')}\".upper()\n",
    "            \n",
    "            # Detect tickers\n",
    "            for ticker in TICKERS:\n",
    "                if ticker in text:\n",
    "                    result['tickers_covered'].add(ticker)\n",
    "            \n",
    "            # Detect signals\n",
    "            if 'BUY' in text:\n",
    "                result['buy_signals'] += 1\n",
    "            if 'SELL' in text:\n",
    "                result['sell_signals'] += 1\n",
    "            if 'PRICE TARGET' in text or 'PRICE_TARGET' in text:\n",
    "                result['price_targets'] += 1\n",
    "    \n",
    "    # Parse relationships\n",
    "    rels_file = Path(storage_path) / 'vdb_relationships.json'\n",
    "    if rels_file.exists():\n",
    "        data = json.loads(rels_file.read_text())\n",
    "        result['total_relationships'] = len(data.get('data', []))\n",
    "    \n",
    "    result['tickers_covered'] = sorted(list(result['tickers_covered']))\n",
    "    return result\n",
    "\n",
    "# Run health check\n",
    "health = check_graph_health(storage_path)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüß¨ Graph Health Metrics:\")\n",
    "print(f\"  üìä Content Coverage:\")\n",
    "print(f\"    Tickers: {', '.join(health['tickers_covered']) if health['tickers_covered'] else 'None'} ({len(health['tickers_covered'])}/4 portfolio holdings)\")\n",
    "\n",
    "print(f\"\\n  üï∏Ô∏è Graph Structure:\")\n",
    "print(f\"    Total entities: {health['total_entities']:,}\")\n",
    "print(f\"    Total relationships: {health['total_relationships']:,}\")\n",
    "if health['total_entities'] > 0:\n",
    "    avg_conn = health['total_relationships'] / health['total_entities']\n",
    "    print(f\"    Avg connections: {avg_conn:.2f}\")\n",
    "\n",
    "print(f\"\\n  üíº Investment Signals:\")\n",
    "print(f\"    BUY signals: {health['buy_signals']}\")\n",
    "print(f\"    SELL signals: {health['sell_signals']}\")\n",
    "print(f\"    Price targets: {health['price_targets']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test: Hybrid Entity Categorization with Qwen2.5-3B\n",
    "\n",
    "**Purpose**: Compare categorization accuracy between keyword-only and hybrid (keyword+LLM) approaches\n",
    "\n",
    "**What this tests**:\n",
    "- Baseline: Fast keyword pattern matching (~1ms per entity)\n",
    "- Enhanced: Confidence scoring to identify ambiguous cases\n",
    "- Hybrid: LLM fallback for low-confidence entities (~40ms per entity)\n",
    "\n",
    "**Prerequisites**:\n",
    "- ‚úÖ Ollama installed with qwen2.5:3b model (optional - degrades gracefully)\n",
    "- ‚úÖ LightRAG graph built (previous cells completed)\n",
    "\n",
    "**Expected runtime**: ~0.5 seconds for 12 sample entities (hybrid mode)\n",
    "\n",
    "**Configuration**: `src/ice_lightrag/graph_categorization.py` - Change `CATEGORIZATION_MODE` to enable hybrid by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Purpose: Test hybrid entity categorization with Ollama LLM fallback\n",
    "# # Location: ice_building_workflow.ipynb Cell 12 (after Cell 10)\n",
    "# # Dependencies: graph_categorization.py, entity_categories.py, LightRAG storage\n",
    "\n",
    "# import json\n",
    "# import time\n",
    "# import sys\n",
    "# import random\n",
    "# import requests\n",
    "# from pathlib import Path\n",
    "# from collections import Counter\n",
    "\n",
    "# # ===== SETUP: Imports with error handling =====\n",
    "# print(\"=\" * 70)\n",
    "# print(\"üß™ Hybrid Entity Categorization Test\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Ensure src is in path for notebook context\n",
    "# project_root = Path.cwd()\n",
    "# if str(project_root) not in sys.path:\n",
    "#     sys.path.insert(0, str(project_root))\n",
    "\n",
    "# try:\n",
    "#     from src.ice_lightrag.graph_categorization import (\n",
    "#         categorize_entity,\n",
    "#         categorize_entity_with_confidence,\n",
    "#         categorize_entity_hybrid\n",
    "#     )\n",
    "#     from src.ice_lightrag.entity_categories import CATEGORY_DISPLAY_ORDER\n",
    "#     print(\"‚úÖ Categorization functions imported successfully\\n\")\n",
    "# except ImportError as e:\n",
    "#     print(f\"‚ùå Import error: {e}\")\n",
    "#     print(\"   ‚Üí Ensure previous cells completed successfully\")\n",
    "#     print(\"   ‚Üí Check that src/ice_lightrag/graph_categorization.py exists\\n\")\n",
    "#     raise\n",
    "\n",
    "# # ===== HEALTH CHECK: Ollama service availability =====\n",
    "# def check_ollama_service():\n",
    "#     \"\"\"Check if Ollama service is running and qwen2.5:3b is available\"\"\"\n",
    "#     try:\n",
    "#         response = requests.get(\"http://localhost:11434/api/tags\", timeout=2)\n",
    "#         if response.status_code == 200:\n",
    "#             models = response.json().get('models', [])\n",
    "#             qwen_available = any('qwen2.5:3b' in m.get('name', '') for m in models)\n",
    "#             return True, qwen_available\n",
    "#         return False, False\n",
    "#     except requests.RequestException:\n",
    "#         return False, False\n",
    "#     except (KeyError, json.JSONDecodeError):\n",
    "#         return True, False  # Ollama running but malformed response\n",
    "\n",
    "# ollama_running, qwen_available = check_ollama_service()\n",
    "# if ollama_running and qwen_available:\n",
    "#     print(\"‚úÖ Ollama service running with qwen2.5:3b model\")\n",
    "# elif ollama_running:\n",
    "#     print(\"‚ö†Ô∏è  Ollama running but qwen2.5:3b not found\")\n",
    "#     print(\"   ‚Üí Install: ollama pull qwen2.5:3b\")\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è  Ollama not running - hybrid mode will fall back to keyword matching\")\n",
    "#     print(\"   ‚Üí Start Ollama: brew services start ollama (macOS)\\n\")\n",
    "\n",
    "# # ===== DATA LOADING: Entities with validation =====\n",
    "# # Use ICE config for robust path resolution\n",
    "# storage_path = Path(ice.config.working_dir) / \"vdb_entities.json\"\n",
    "\n",
    "# if not storage_path.exists():\n",
    "#     print(f\"‚ùå Storage file not found: {storage_path}\")\n",
    "#     print(\"   ‚Üí Run previous cells to build the knowledge graph first\\n\")\n",
    "#     raise FileNotFoundError(f\"LightRAG storage not found at {storage_path}\")\n",
    "\n",
    "# with open(storage_path) as f:\n",
    "#     entities_data = json.load(f)\n",
    "\n",
    "# # Validate LightRAG storage structure: {\"data\": [...]}\n",
    "# if not isinstance(entities_data, dict) or 'data' not in entities_data:\n",
    "#     print(f\"‚ùå Invalid storage format (expected dict with 'data' key)\")\n",
    "#     raise ValueError(\"Invalid LightRAG storage format - expected {'data': [...]}\")\n",
    "\n",
    "# entities_list = entities_data.get('data', [])\n",
    "# if not isinstance(entities_list, list) or len(entities_list) == 0:\n",
    "#     print(f\"‚ùå No entities found in storage\")\n",
    "#     raise ValueError(\"No entities found in LightRAG storage\")\n",
    "\n",
    "# print(f\"‚úÖ Loaded {len(entities_list)} entities from knowledge graph\")\n",
    "\n",
    "# # Random sampling for better test coverage (avoids bias from first N entities)\n",
    "# random.seed(42)  # Reproducible sampling\n",
    "# test_entities = random.sample(entities_list, min(12, len(entities_list)))\n",
    "# print(f\"   Testing with {len(test_entities)} randomly sampled entities\\n\")\n",
    "\n",
    "# # ===== HELPER: Compact result display =====\n",
    "# def display_results(results, title, show_confidence=False, show_llm=False):\n",
    "#     \"\"\"Display categorization results in compact format\"\"\"\n",
    "#     print(f\"\\n{title}\")\n",
    "#     print(\"-\" * 70)\n",
    "    \n",
    "#     for i, (name, category, confidence, used_llm) in enumerate(results, 1):\n",
    "#         # Truncate long entity names for readability\n",
    "#         display_name = name[:40] + \"...\" if len(name) > 40 else name\n",
    "        \n",
    "#         if show_llm and used_llm:\n",
    "#             indicator = \"ü§ñ\"  # LLM was used\n",
    "#         else:\n",
    "#             indicator = \"‚ö°\"  # Keyword matching\n",
    "        \n",
    "#         if show_confidence:\n",
    "#             print(f\"{i:2d}. {indicator} {display_name:43s} ‚Üí {category:20s} (conf: {confidence:.2f})\")\n",
    "#         else:\n",
    "#             print(f\"{i:2d}. {display_name:45s} ‚Üí {category}\")\n",
    "    \n",
    "#     # Category distribution summary\n",
    "#     category_counts = Counter(cat for _, cat, _, _ in results)\n",
    "#     print(f\"\\nüìä Distribution: {dict(category_counts)}\")\n",
    "\n",
    "# # ===== TEST 1: Keyword-Only Baseline =====\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"TEST 1: Keyword-Only Categorization (Baseline)\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# start_time = time.time()\n",
    "# keyword_results = []\n",
    "\n",
    "# for entity in test_entities:\n",
    "#     name = entity.get('entity_name', '')\n",
    "#     content = entity.get('content', '')\n",
    "#     category = categorize_entity(name, content)\n",
    "#     keyword_results.append((name, category, 1.0, False))  # No confidence/LLM info\n",
    "\n",
    "# elapsed = time.time() - start_time\n",
    "# display_results(keyword_results, \"Results (Keyword Matching):\", show_confidence=False)\n",
    "# print(f\"\\n‚è±Ô∏è  Time: {elapsed*1000:.1f}ms ({elapsed*1000/len(test_entities):.1f}ms per entity)\")\n",
    "\n",
    "# # ===== TEST 2: Confidence Scoring Analysis =====\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"TEST 2: Keyword + Confidence Scoring\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# start_time = time.time()\n",
    "# confidence_results = []\n",
    "\n",
    "# for entity in test_entities:\n",
    "#     name = entity.get('entity_name', '')\n",
    "#     content = entity.get('content', '')\n",
    "#     category, confidence = categorize_entity_with_confidence(name, content)\n",
    "#     confidence_results.append((name, category, confidence, False))\n",
    "\n",
    "# elapsed = time.time() - start_time\n",
    "# display_results(confidence_results, \"Results (with confidence scores):\", show_confidence=True)\n",
    "\n",
    "# # Highlight ambiguous entities (confidence < 0.70)\n",
    "# low_confidence = [(n, c, conf) for n, c, conf, _ in confidence_results if conf < 0.70]\n",
    "# if low_confidence:\n",
    "#     print(f\"\\nüîç Ambiguous entities (confidence < 0.70): {len(low_confidence)}\")\n",
    "#     for name, cat, conf in low_confidence:\n",
    "#         print(f\"   - {name[:50]:50s} ‚Üí {cat:20s} (conf: {conf:.2f})\")\n",
    "# else:\n",
    "#     print(f\"\\n‚úÖ All entities have high confidence (‚â•0.70) - no LLM fallback needed\")\n",
    "\n",
    "# print(f\"\\n‚è±Ô∏è  Time: {elapsed*1000:.1f}ms ({elapsed*1000/len(test_entities):.1f}ms per entity)\")\n",
    "\n",
    "# # ===== TEST 3: Hybrid Mode (if Ollama available) =====\n",
    "# if ollama_running and qwen_available:\n",
    "#     print(\"\\n\" + \"=\" * 70)\n",
    "#     print(\"TEST 3: Hybrid Categorization (Keyword + LLM Fallback)\")\n",
    "#     print(\"=\" * 70)\n",
    "#     print(\"‚è±Ô∏è  Note: LLM calls may take 5-10 seconds total...\\n\")\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     hybrid_results = []\n",
    "#     llm_call_count = 0\n",
    "    \n",
    "#     for entity in test_entities:\n",
    "#         name = entity.get('entity_name', '')\n",
    "#         content = entity.get('content', '')\n",
    "        \n",
    "#         # Optimization: Compute keyword confidence once and reuse\n",
    "#         keyword_cat, keyword_conf = categorize_entity_with_confidence(name, content)\n",
    "        \n",
    "#         if keyword_conf >= 0.70:\n",
    "#             # High confidence - use keyword result (skip LLM call)\n",
    "#             category, confidence = keyword_cat, keyword_conf\n",
    "#             used_llm = False\n",
    "#         else:\n",
    "#             # Low confidence - use hybrid (may call LLM)\n",
    "#             category, confidence = categorize_entity_hybrid(name, content, confidence_threshold=0.70)\n",
    "#             # LLM was used if confidence jumped to 0.90\n",
    "#             used_llm = (confidence == 0.90)\n",
    "#             if used_llm:\n",
    "#                 llm_call_count += 1\n",
    "        \n",
    "#         hybrid_results.append((name, category, confidence, used_llm))\n",
    "    \n",
    "#     elapsed = time.time() - start_time\n",
    "#     display_results(hybrid_results, \"Results (Hybrid mode - keyword + LLM):\", show_confidence=True, show_llm=True)\n",
    "    \n",
    "#     print(f\"\\nü§ñ LLM calls: {llm_call_count}/{len(test_entities)} ({100*llm_call_count/len(test_entities):.1f}%)\")\n",
    "#     print(f\"‚è±Ô∏è  Time: {elapsed*1000:.1f}ms ({elapsed*1000/len(test_entities):.1f}ms per entity)\")\n",
    "    \n",
    "#     # ===== COMPARISON SUMMARY =====\n",
    "#     print(\"\\n\" + \"=\" * 70)\n",
    "#     print(\"üìä COMPARISON SUMMARY\")\n",
    "#     print(\"=\" * 70)\n",
    "    \n",
    "#     # Count category changes between keyword and hybrid\n",
    "#     changes = 0\n",
    "#     for i in range(len(test_entities)):\n",
    "#         if keyword_results[i][1] != hybrid_results[i][1]:\n",
    "#             changes += 1\n",
    "    \n",
    "#     print(f\"Entities recategorized by LLM: {changes}/{len(test_entities)} ({100*changes/len(test_entities):.1f}%)\")\n",
    "    \n",
    "#     if changes > 0:\n",
    "#         print(\"\\nRecategorization details:\")\n",
    "#         for i in range(len(test_entities)):\n",
    "#             kw_cat = keyword_results[i][1]\n",
    "#             hyb_cat = hybrid_results[i][1]\n",
    "#             if kw_cat != hyb_cat:\n",
    "#                 name = test_entities[i].get('entity_name', '')[:50]\n",
    "#                 print(f\"   - {name:50s}: {kw_cat:20s} ‚Üí {hyb_cat}\")\n",
    "    \n",
    "#     print(f\"\\n‚úÖ Hybrid categorization complete!\")\n",
    "    \n",
    "# else:\n",
    "#     print(\"\\n\" + \"=\" * 70)\n",
    "#     print(\"‚ö†Ô∏è  TEST 3 SKIPPED: Ollama not available\")\n",
    "#     print(\"=\" * 70)\n",
    "#     print(\"To enable hybrid mode:\")\n",
    "#     print(\"   1. Install Ollama: https://ollama.com\")\n",
    "#     print(\"   2. Pull model: ollama pull qwen2.5:3b\")\n",
    "#     print(\"   3. Start service: brew services start ollama (macOS)\")\n",
    "#     print(\"   4. Re-run this cell\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PRE-DELETION CHECK\n",
      "  ‚úÖ vdb_entities.json: 0.04 MB\n",
      "  ‚úÖ vdb_relationships.json: 0.03 MB\n",
      "  ‚úÖ vdb_chunks.json: 0.01 MB\n",
      "  ‚úÖ graph_chunk_entity_relation.graphml: 0.01 MB\n",
      "  üíæ Total: 0.09 MB\n",
      "\n",
      "‚úÖ POST-DELETION CHECK\n",
      "  ‚ö†Ô∏è  vdb_entities.json: not found\n",
      "  ‚ö†Ô∏è  vdb_relationships.json: not found\n",
      "  ‚ö†Ô∏è  vdb_chunks.json: not found\n",
      "  ‚ö†Ô∏è  graph_chunk_entity_relation.graphml: not found\n",
      "  üíæ Total: 0.00 MB\n",
      "\n",
      "‚úÖ Graph cleared - will rebuild from scratch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Clear graph storage (COMMENTED BY DEFAULT FOR SAFETY)\n",
    "## Uncomment lines below to clear existing graph:\n",
    "\n",
    "##########################################################\n",
    "#                      Clear Graph                       #\n",
    "##########################################################\n",
    "\n",
    "if storage_path.exists():\n",
    "    print(\"üìä PRE-DELETION CHECK\")\n",
    "    check_storage(storage_path)\n",
    "    \n",
    "    shutil.rmtree(storage_path) # Deletes directory + all contents.\n",
    "    storage_path.mkdir(parents=True, exist_ok=True) # This re-creates empty directory.\n",
    "    \n",
    "    print(\"\\n‚úÖ POST-DELETION CHECK\")\n",
    "    check_storage(storage_path)\n",
    "    print(\"\\n‚úÖ Graph cleared - will rebuild from scratch\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Storage path doesn't exist - nothing to clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Portfolio Configuration\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Holdings: NVDA, TSMC, AMD, ASML, FICO (5 stocks)\n",
      "Sector: Semiconductor\n",
      "Data Range: 2 years historical (editable in Cell 21)\n",
      "üìÑ Source: portfolio_holdings.csv\n"
     ]
    }
   ],
   "source": [
    "# Portfolio configuration\n",
    "import pandas as pd\n",
    "\n",
    "portfolio_df = pd.read_csv('portfolio_holdings.csv')\n",
    "\n",
    "# Basic validation\n",
    "if portfolio_df.empty:\n",
    "    raise ValueError(\"Portfolio CSV is empty\")\n",
    "if 'ticker' not in portfolio_df.columns:\n",
    "    raise ValueError(\"CSV must have 'ticker' column\")\n",
    "\n",
    "holdings = portfolio_df['ticker'].tolist()\n",
    "\n",
    "print(f\"üéØ Portfolio Configuration\")\n",
    "print(f\"‚îÅ\" * 40)\n",
    "print(f\"Holdings: {', '.join(holdings)} ({len(holdings)} stocks)\")\n",
    "print(f\"Sector: {portfolio_df['sector'].iloc[0] if len(portfolio_df) > 0 else 'N/A'}\")\n",
    "print(f\"Data Range: 2 years historical (editable in Cell 21)\")\n",
    "print(f\"üìÑ Source: portfolio_holdings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Ingestion & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Source Summary\n",
      "==================================================\n",
      "üíæ Current Graph Size: 0.00 MB\n",
      "‚ÑπÔ∏è Data source metrics available after ingestion completes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä Data Source Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show ACTUAL metrics if available (not fake percentages)\n",
    "if ice and ice.core.is_ready():\n",
    "    storage_stats = ice.core.get_storage_stats()\n",
    "    print(f\"üíæ Current Graph Size: {storage_stats['total_storage_bytes'] / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Show real source info if ingestion has run\n",
    "    if 'ingestion_result' in locals() and 'metrics' in ingestion_result:\n",
    "        metrics = ingestion_result['metrics']\n",
    "        if 'data_sources_used' in metrics:\n",
    "            print(f\"‚úÖ Active sources: {', '.join(metrics['data_sources_used'])}\")\n",
    "        print(f\"üìÑ Total documents: {ingestion_result.get('total_documents', 0)}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Data source metrics available after ingestion completes\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Knowledge graph not ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Data Source Contribution Visualization (Week 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_ready': True,\n",
       " 'storage_indicators': {'all_components_present': False,\n",
       "  'chunks_file_size': 0.0,\n",
       "  'entities_file_size': 0.0,\n",
       "  'relationships_file_size': 0.0,\n",
       "  'graph_file_size': 0.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice.core.get_graph_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ICE Data Sources Summary (Phase 1 Integration)\n",
      "============================================================\n",
      "\n",
      "‚ÑπÔ∏è  Phase 1 focuses on architecture and data flow patterns.\n",
      "Actual data ingestion depends on configured API keys.\n",
      "\n",
      "\n",
      "1Ô∏è‚É£ API/MCP Sources:\n",
      "   - NewsAPI: Real-time financial news\n",
      "   - SEC EDGAR: Regulatory filings (10-K, 10-Q, 8-K)\n",
      "   - Alpha Vantage: Market data\n",
      "\n",
      "2Ô∏è‚É£ Email Pipeline (Phase 1 Enhanced Documents):\n",
      "   - Broker research with BUY/SELL signals\n",
      "   - Enhanced documents: [TICKER:NVDA|confidence:0.95]\n",
      "   - See detailed demo: imap_email_ingestion_pipeline/investment_email_extractor_simple.ipynb\n",
      "\n",
      "3Ô∏è‚É£ SEC Filings:\n",
      "   - Management commentary and financial statements\n",
      "   - Integrated via SEC EDGAR connector\n",
      "\n",
      "üí° All sources ‚Üí Single LightRAG knowledge graph via ice_simplified.py\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä ICE Data Sources Summary (Phase 1 Integration)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚ÑπÔ∏è  Phase 1 focuses on architecture and data flow patterns.\")\n",
    "print(\"Actual data ingestion depends on configured API keys.\\n\")\n",
    "print(\"\\n1Ô∏è‚É£ API/MCP Sources:\")\n",
    "print(\"   - NewsAPI: Real-time financial news\")\n",
    "print(\"   - SEC EDGAR: Regulatory filings (10-K, 10-Q, 8-K)\")\n",
    "print(\"   - Alpha Vantage: Market data\")\n",
    "print(\"\\n2Ô∏è‚É£ Email Pipeline (Phase 1 Enhanced Documents):\")\n",
    "print(\"   - Broker research with BUY/SELL signals\")\n",
    "print(\"   - Enhanced documents: [TICKER:NVDA|confidence:0.95]\")\n",
    "print(\"   - See detailed demo: imap_email_ingestion_pipeline/investment_email_extractor_simple.ipynb\")\n",
    "print(\"\\n3Ô∏è‚É£ SEC Filings:\")\n",
    "print(\"   - Management commentary and financial statements\")\n",
    "print(\"   - Integrated via SEC EDGAR connector\")\n",
    "print(\"\\nüí° All sources ‚Üí Single LightRAG knowledge graph via ice_simplified.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. ICE Data Sources Integration (Week 5)\n",
    "\n",
    "ICE integrates 3 heterogeneous data sources into unified knowledge graph:\n",
    "\n",
    "**Detailed Demonstrations Available**:\n",
    "- üìß **Email Pipeline**: See `imap_email_ingestion_pipeline/investment_email_extractor_simple.ipynb` (25 cells)\n",
    "  - Entity extraction (tickers, ratings, price targets)\n",
    "  - BUY/SELL signal extraction with confidence scores\n",
    "  - Enhanced document creation with inline metadata\n",
    "  \n",
    "- üìä **Quick Summary Below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:updated_architectures.implementation.ice_simplified:Starting historical data ingestion for 5 holdings (1 years)\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetching 1 years of historical data for NVDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Fetching Portfolio Data\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "üîÑ Fetching data for 5 holdings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:updated_architectures.implementation.ice_simplified:Fetched company overview for NVDA from Alpha Vantage\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 5 news articles for NVDA from NewsAPI\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 6 total documents for NVDA\n",
      "WARNING:src.ice_lightrag.model_provider:Ollama model 'qwen3:8b' not available\n",
      "WARNING:src.ice_lightrag.model_provider:‚ö†Ô∏è  Falling back to OpenAI: Model not found. Pull with: ollama pull qwen3:8b\n",
      "INFO:src.ice_lightrag.model_provider:‚úÖ Using OpenAI provider (fallback from Ollama)\n",
      "INFO: [_] Created new empty graph fiel: ice_lightrag/storage/graph_chunk_entity_relation.graphml\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'ice_lightrag/storage/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'ice_lightrag/storage/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'ice_lightrag/storage/vdb_chunks.json'} 0 data\n",
      "INFO: [_] Process 88551 KV load full_docs with 0 records\n",
      "INFO: [_] Process 88551 KV load text_chunks with 0 records\n",
      "INFO: [_] Process 88551 KV load full_entities with 0 records\n",
      "INFO: [_] Process 88551 KV load full_relations with 0 records\n",
      "INFO: [_] Process 88551 KV load llm_response_cache with 0 records\n",
      "INFO: [_] Process 88551 doc status load doc_status with 0 records\n",
      "INFO:src.ice_lightrag.ice_rag_fixed:‚úÖ Pipeline status initialized successfully\n",
      "INFO:src.ice_lightrag.ice_rag_fixed:‚úÖ JupyterICERAG initialized successfully\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-a73da747f039730fbc8763b316a6724d\n",
      "INFO: Embedding func: 8 new workers initialized  (Timeouts: Func: 30s, Worker: 60s, Health Check: 75s)\n",
      "INFO: LLM func: 4 new workers initialized  (Timeouts: Func: 180s, Worker: 360s, Health Check: 375s)\n",
      "INFO:  == LLM cache == saving: default:extract:7806bd2abe2f4c4ad0e0407fcdf4c320\n",
      "INFO:  == LLM cache == saving: default:extract:16c0f53b0b799668f6de69a414f8b94b\n",
      "INFO: Chunk 1 of 1 extracted 12 Ent + 7 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 12 entities from doc-a73da747f039730fbc8763b316a6724d (async: 8)\n",
      "INFO: Merged: `NVIDIA Corporation` | 0+1\n",
      "INFO: Merged: `Santa Clara` | 0+1\n",
      "INFO: Merged: `NASDAQ` | 0+1\n",
      "INFO: Merged: `GPU` | 0+1\n",
      "INFO: Merged: `AI Technologies` | 0+1\n",
      "INFO: Merged: `System on a Chip (SoC)` | 0+1\n",
      "INFO: Merged: `Market Capitalization` | 0+1\n",
      "INFO: Merged: `Profit Margin` | 0+1\n",
      "INFO: Merged: `Revenue Per Share` | 0+1\n",
      "INFO: Merged: `USA` | 0+1\n",
      "INFO: Merged: `Technology Sector` | 0+1\n",
      "INFO: Merged: `Semiconductors` | 0+1\n",
      "INFO: Phase 2: Processing 7 relations from doc-a73da747f039730fbc8763b316a6724d (async: 8)\n",
      "INFO: Merged: `NVIDIA Corporation`~`Santa Clara` | 0+1\n",
      "INFO: Merged: `NASDAQ`~`NVIDIA Corporation` | 0+1\n",
      "INFO: Merged: `GPU`~`NVIDIA Corporation` | 0+1\n",
      "INFO: Merged: `AI Technologies`~`NVIDIA Corporation` | 0+1\n",
      "INFO: Merged: `NVIDIA Corporation`~`System on a Chip (SoC)` | 0+1\n",
      "INFO: Merged: `NVIDIA Corporation`~`USA` | 0+1\n",
      "INFO: Merged: `NVIDIA Corporation`~`Semiconductors` | 0+1\n",
      "INFO: Phase 3: Updating final 12(12+0) entities and  7 relations from doc-a73da747f039730fbc8763b316a6724d\n",
      "INFO: Completed merging: 12 entities, 0 extra entities, 7 relations\n",
      "INFO: [_] Writing graph with 12 nodes, 7 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-b44ec56b9ae5d4ae05f9444d63f17ff7\n",
      "INFO:  == LLM cache == saving: default:extract:98923b935b67c85042fcea764e0976b5\n",
      "INFO:  == LLM cache == saving: default:extract:b50007cb50ea149fbb2b2f34d8e34fde\n",
      "INFO: Chunk 1 of 1 extracted 8 Ent + 5 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 8 entities from doc-b44ec56b9ae5d4ae05f9444d63f17ff7 (async: 8)\n",
      "INFO: Merged: `China` | 0+1\n",
      "INFO: Merged: `Nvidia` | 0+1\n",
      "INFO: Merged: `Rhodium Group` | 0+1\n",
      "INFO: Merged: `Reva` | 0+1\n",
      "INFO: Merged: `Financial Times` | 0+1\n",
      "INFO: Merged: `Experimental Phase of Trade Talks` | 0+1\n",
      "INFO: Merged: `2025-09-17` | 0+1\n",
      "INFO: Merged: `Yahoo Entertainment` | 0+1\n",
      "INFO: Phase 2: Processing 5 relations from doc-b44ec56b9ae5d4ae05f9444d63f17ff7 (async: 8)\n",
      "INFO: Merged: `China`~`Nvidia` | 0+1\n",
      "INFO: Merged: `Financial Times`~`Rhodium Group` | 0+1\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 0.412620 seconds\n",
      "INFO: Merged: `Reva`~`Rhodium Group` | 0+1\n",
      "INFO: Merged: `Nvidia`~`Yahoo Entertainment` | 0+1\n",
      "INFO: Merged: `China`~`Experimental Phase of Trade Talks` | 0+1\n",
      "INFO: Phase 3: Updating final 8(8+0) entities and  5 relations from doc-b44ec56b9ae5d4ae05f9444d63f17ff7\n",
      "INFO: Completed merging: 8 entities, 0 extra entities, 5 relations\n",
      "INFO: [_] Writing graph with 20 nodes, 12 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-2045c31615994e0c5b122d0a639ecf19\n",
      "INFO:  == LLM cache == saving: default:extract:8abe0bd37619747731a2046a837e23c4\n",
      "INFO:  == LLM cache == saving: default:extract:46fb4dcd189000fbf97eef3ff04440b7\n",
      "INFO: Chunk 1 of 1 extracted 10 Ent + 5 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 10 entities from doc-2045c31615994e0c5b122d0a639ecf19 (async: 8)\n",
      "INFO: Merged: `Artificial Intelligence Stocks` | 0+1\n",
      "INFO: Merged: `Nvidia` | 1+1\n",
      "INFO: Merged: `Large Language Models` | 0+1\n",
      "INFO: Merged: `Big Data Centers` | 0+1\n",
      "INFO: Merged: `Robo` | 0+1\n",
      "INFO: Merged: `Yahoo Entertainment` | 1+1\n",
      "INFO: Merged: `2025-09-22` | 0+1\n",
      "INFO: Merged: `Source URL` | 0+1\n",
      "INFO: Merged: `Chips` | 0+1\n",
      "INFO: Merged: `AI Boom` | 0+1\n",
      "INFO: Phase 2: Processing 5 relations from doc-2045c31615994e0c5b122d0a639ecf19 (async: 8)\n",
      "INFO: Merged: `Artificial Intelligence Stocks`~`Nvidia` | 0+1\n",
      "INFO: Merged: `Yahoo Entertainment`~`article` | 0+1\n",
      "INFO: Merged: `AI Boom`~`Chips` | 0+1\n",
      "INFO: Merged: `Artificial Intelligence Stocks`~`Large Language Models` | 0+1\n",
      "INFO: Merged: `Artificial Intelligence Stocks`~`Big Data Centers` | 0+1\n",
      "INFO: Phase 3: Updating final 11(10+1) entities and  5 relations from doc-2045c31615994e0c5b122d0a639ecf19\n",
      "INFO: Completed merging: 10 entities, 1 extra entities, 5 relations\n",
      "INFO: [_] Writing graph with 29 nodes, 17 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-e1b27284e5130be2f9a937913358966b\n",
      "INFO:  == LLM cache == saving: default:extract:872d1a999816bc87c8a24742c06a5aa7\n",
      "INFO:  == LLM cache == saving: default:extract:02c06358abc81a3046578b80d0ad79e9\n",
      "INFO: Chunk 1 of 1 extracted 10 Ent + 7 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 10 entities from doc-e1b27284e5130be2f9a937913358966b (async: 8)\n",
      "INFO: Merged: `Intel` | 0+1\n",
      "INFO: Merged: `Apple` | 0+1\n",
      "INFO: Merged: `Nvidia` | 2+1\n",
      "INFO: Merged: `US Government` | 0+1\n",
      "INFO: Merged: `D.A.` | 0+1\n",
      "INFO: Merged: `Bloomberg` | 0+1\n",
      "INFO: Merged: `Financial Historical` | 0+1\n",
      "INFO: Merged: `Yahoo Entertainment` | 2+1\n",
      "INFO: Merged: `September 25, 2025` | 0+1\n",
      "INFO: Merged: `https://finance.yahoo.com/video/intel-needs-apple-invest-nvidia-193000697.html` | 0+1\n",
      "INFO: Phase 2: Processing 7 relations from doc-e1b27284e5130be2f9a937913358966b (async: 8)\n",
      "INFO: Merged: `Apple`~`Intel` | 0+1\n",
      "INFO: Merged: `Intel`~`Nvidia` | 0+1\n",
      "INFO: Merged: `Apple`~`Nvidia` | 0+1\n",
      "INFO: Merged: `Intel`~`US Government` | 0+1\n",
      "INFO: Merged: `Bloomberg`~`Intel` | 0+1\n",
      "INFO: Merged: `Intel`~`Yahoo Entertainment` | 0+1\n",
      "INFO: Merged: `Bloomberg`~`Yahoo Entertainment` | 0+1\n",
      "INFO: Phase 3: Updating final 10(10+0) entities and  7 relations from doc-e1b27284e5130be2f9a937913358966b\n",
      "INFO: Completed merging: 10 entities, 0 extra entities, 7 relations\n",
      "INFO: [_] Writing graph with 37 nodes, 24 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-821f4d7be36351d1c17fa3cc2a4a19ea\n",
      "INFO:  == LLM cache == saving: default:extract:42c4693d72ef0fd8126ebb210ab5a16b\n",
      "INFO:  == LLM cache == saving: default:extract:35f548d4b9a530b935b12073c4f7428d\n",
      "INFO: Chunk 1 of 1 extracted 8 Ent + 6 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 8 entities from doc-821f4d7be36351d1c17fa3cc2a4a19ea (async: 8)\n",
      "INFO: Merged: `Jim Cramer` | 0+1\n",
      "INFO: Merged: `Nvidia` | 3+1\n",
      "INFO: Merged: `AI Chips` | 0+1\n",
      "INFO: Merged: `CNBC` | 0+1\n",
      "INFO: Merged: `Yahoo Finance` | 0+1\n",
      "INFO: Merged: `Article` | 0+1\n",
      "INFO: Merged: `October 7, 2025` | 0+1\n",
      "INFO: Merged: `GuruFocus` | 0+1\n",
      "INFO: Phase 2: Processing 6 relations from doc-821f4d7be36351d1c17fa3cc2a4a19ea (async: 8)\n",
      "INFO: Merged: `Jim Cramer`~`Nvidia` | 0+1\n",
      "INFO: Merged: `Article`~`GuruFocus` | 0+1\n",
      "INFO: Merged: `AI Chips`~`Nvidia` | 0+1\n",
      "INFO: Merged: `CNBC`~`Jim Cramer` | 0+1\n",
      "INFO: Merged: `Article`~`October 7, 2025` | 0+1\n",
      "INFO: Merged: `Jim Cramer`~`Yahoo Finance` | 0+1\n",
      "INFO: Phase 3: Updating final 8(8+0) entities and  6 relations from doc-821f4d7be36351d1c17fa3cc2a4a19ea\n",
      "INFO: Completed merging: 8 entities, 0 extra entities, 6 relations\n",
      "INFO: [_] Writing graph with 44 nodes, 30 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-1e93ef679fb3285ab09e6b8a02c5b92e\n",
      "INFO:  == LLM cache == saving: default:extract:01a7fcf0f52a93ad05797d6b171b7332\n",
      "INFO:  == LLM cache == saving: default:extract:4561ccb8e51876bfa4167b440ca4adb1\n",
      "INFO: Chunk 1 of 1 extracted 10 Ent + 6 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 10 entities from doc-1e93ef679fb3285ab09e6b8a02c5b92e (async: 8)\n",
      "INFO: Merged: `NVIDIA` | 0+1\n",
      "INFO: Merged: `Microsoft` | 0+1\n",
      "INFO: Merged: `IBM` | 0+1\n",
      "INFO: Merged: `D-Wave` | 0+1\n",
      "INFO: Merged: `IonQ` | 0+1\n",
      "INFO: Merged: `Zacks Analyst Blog` | 0+1\n",
      "INFO: Merged: `Chicago` | 0+1\n",
      "INFO: Merged: `October 3, 2025` | 0+1\n",
      "INFO: Merged: `Quantum Computing` | 0+1\n",
      "INFO: Merged: `Zacks.com` | 0+1\n",
      "INFO: Phase 2: Processing 6 relations from doc-1e93ef679fb3285ab09e6b8a02c5b92e (async: 8)\n",
      "INFO: Merged: `NVIDIA`~`Zacks Analyst Blog` | 0+1\n",
      "INFO: Merged: `Microsoft`~`Zacks Analyst Blog` | 0+1\n",
      "INFO: Merged: `IBM`~`Zacks Analyst Blog` | 0+1\n",
      "INFO: Merged: `D-Wave`~`Zacks Analyst Blog` | 0+1\n",
      "INFO: Merged: `IonQ`~`Zacks Analyst Blog` | 0+1\n",
      "INFO: Merged: `Zacks Analyst Blog`~`Zacks.com` | 0+1\n",
      "INFO: Phase 3: Updating final 10(10+0) entities and  6 relations from doc-1e93ef679fb3285ab09e6b8a02c5b92e\n",
      "INFO: Completed merging: 10 entities, 0 extra entities, 6 relations\n",
      "INFO: [_] Writing graph with 54 nodes, 36 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO:updated_architectures.implementation.ice_simplified:Batch processing completed: 6 successful, 0 failed\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ Historical data ingested for NVDA: 6 documents\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetching 1 years of historical data for TSMC\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 5 news articles for TSMC from NewsAPI\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 5 total documents for TSMC\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-62625d410d19d19397adca7deda5ce89\n",
      "INFO:  == LLM cache == saving: default:extract:6ccc3904da6d01c02a616fcd9d6c2cea\n",
      "INFO:  == LLM cache == saving: default:extract:e453e3fe09639f9510fc910c6a02d22a\n",
      "INFO: Chunk 1 of 1 extracted 10 Ent + 6 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 10 entities from doc-62625d410d19d19397adca7deda5ce89 (async: 8)\n",
      "INFO: Merged: `Nvidia` | 4+1\n",
      "INFO: Merged: `Intel` | 1+1\n",
      "INFO: Merged: `Jensen Huang` | 0+1\n",
      "INFO: Merged: `Lip-Bu Tan` | 0+1\n",
      "INFO: Merged: `AMD` | 0+1\n",
      "INFO: Merged: `5 Billion Deal` | 0+1\n",
      "INFO: Merged: `The Verge` | 0+1\n",
      "INFO: Merged: `September 18, 2025` | 0+1\n",
      "INFO: Merged: `Sean Hollister` | 0+1\n",
      "INFO: Merged: `Financial Historical` | 1+1\n",
      "INFO: Phase 2: Processing 6 relations from doc-62625d410d19d19397adca7deda5ce89 (async: 8)\n",
      "INFO: Merged: `Intel`~`Nvidia` | 1+1\n",
      "INFO: Merged: `Sean Hollister`~`The Verge` | 0+1\n",
      "INFO: Merged: `Jensen Huang`~`Nvidia` | 0+1\n",
      "INFO: Merged: `Intel`~`Lip-Bu Tan` | 0+1\n",
      "INFO: Merged: `AMD`~`Nvidia` | 0+1\n",
      "INFO: Merged: `Nvidia`~`The Verge` | 0+1\n",
      "INFO: Phase 3: Updating final 10(10+0) entities and  6 relations from doc-62625d410d19d19397adca7deda5ce89\n",
      "INFO: Completed merging: 10 entities, 0 extra entities, 6 relations\n",
      "INFO: [_] Writing graph with 61 nodes, 41 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-bd113efb56f30aa14430efe26238ea72\n",
      "INFO:  == LLM cache == saving: default:extract:1abb1abd993829f0832143e93bc59131\n",
      "INFO:  == LLM cache == saving: default:extract:9520e100c1cebcc755570990521c8d2e\n",
      "INFO: Chunk 1 of 1 extracted 7 Ent + 4 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 7 entities from doc-bd113efb56f30aa14430efe26238ea72 (async: 8)\n",
      "INFO: Merged: `TSMC` | 0+1\n",
      "INFO: Merged: `Intel` | 2+1\n",
      "INFO: Merged: `Taipei Times` | 0+1\n",
      "INFO: Merged: `September 29, 2025` | 0+1\n",
      "INFO: Merged: `Partnership Rumors` | 0+1\n",
      "INFO: Merged: `Heise Online` | 0+1\n",
      "INFO: Merged: `URL` | 0+1\n",
      "INFO: Phase 2: Processing 4 relations from doc-bd113efb56f30aa14430efe26238ea72 (async: 8)\n",
      "INFO: Merged: `Intel`~`TSMC` | 0+1\n",
      "INFO: Merged: `TSMC`~`Taipei Times` | 0+1\n",
      "INFO: Merged: `Intel`~`Partnership Rumors` | 0+1\n",
      "INFO: Merged: `Heise Online`~`TSMC` | 0+1\n",
      "INFO: Phase 3: Updating final 7(7+0) entities and  4 relations from doc-bd113efb56f30aa14430efe26238ea72\n",
      "INFO: Completed merging: 7 entities, 0 extra entities, 4 relations\n",
      "INFO: [_] Writing graph with 67 nodes, 45 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-986de28ec3943eb109482d9d4c05f40c\n",
      "INFO:  == LLM cache == saving: default:extract:ebb43e461135225360fccf4df86bf356\n",
      "INFO:  == LLM cache == saving: default:extract:04889e591650b70302cf328aaa45e667\n",
      "INFO: Chunk 1 of 1 extracted 6 Ent + 5 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 6 entities from doc-986de28ec3943eb109482d9d4c05f40c (async: 8)\n",
      "INFO: Merged: `Taiwan` | 0+1\n",
      "INFO: Merged: `United States` | 0+1\n",
      "INFO: Merged: `High-Tech Strategic Partnership` | 0+1\n",
      "INFO: Merged: `Taiwan's Top Tariff Negotiator` | 0+1\n",
      "INFO: Merged: `Yahoo Entertainment` | 3+1\n",
      "INFO: Merged: `October 2, 2025` | 0+1\n",
      "INFO: Phase 2: Processing 5 relations from doc-986de28ec3943eb109482d9d4c05f40c (async: 8)\n",
      "INFO: Merged: `Taiwan`~`United States` | 0+1\n",
      "INFO: Merged: `October 2, 2025`~`Yahoo Entertainment` | 0+1\n",
      "INFO: Merged: `High-Tech Strategic Partnership`~`Taiwan` | 0+1\n",
      "INFO: Merged: `High-Tech Strategic Partnership`~`United States` | 0+1\n",
      "INFO: Merged: `High-Tech Strategic Partnership`~`Taiwan's Top Tariff Negotiator` | 0+1\n",
      "INFO: Phase 3: Updating final 6(6+0) entities and  5 relations from doc-986de28ec3943eb109482d9d4c05f40c\n",
      "INFO: Completed merging: 6 entities, 0 extra entities, 5 relations\n",
      "INFO: [_] Writing graph with 72 nodes, 50 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-42697d809be5c955fc04ae7ab759f093\n",
      "INFO:  == LLM cache == saving: default:extract:71f3a099d1ffd810dbbaccfd31b08415\n",
      "INFO:  == LLM cache == saving: default:extract:7f109b173da74a018ff6153b518d7812\n",
      "INFO: Chunk 1 of 1 extracted 9 Ent + 3 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 9 entities from doc-42697d809be5c955fc04ae7ab759f093 (async: 8)\n",
      "INFO: Merged: `Intel` | 3+1\n",
      "INFO: Merged: `Steve Jobs` | 0+1\n",
      "INFO: Merged: `Apple` | 1+1\n",
      "INFO: Merged: `1997` | 0+1\n",
      "INFO: Merged: `strategic alliances` | 0+1\n",
      "INFO: Merged: `Xataka.com` | 0+1\n",
      "INFO: Merged: `source article` | 0+1\n",
      "INFO: Merged: `2025-09-26` | 0+1\n",
      "INFO: Merged: `https://www.xataka.com/empresas-y-economia/intel-lleva-decadas-fabricando-chips-solo-para-ella-su-unica-salvacion-consiste-fabricar-chips-para-todos-demas` | 0+1\n",
      "INFO: Phase 2: Processing 3 relations from doc-42697d809be5c955fc04ae7ab759f093 (async: 8)\n",
      "INFO: Merged: `Apple`~`Intel` | 1+1\n",
      "INFO: Merged: `Apple`~`Steve Jobs` | 0+1\n",
      "INFO: Merged: `Apple`~`strategic alliances` | 0+1\n",
      "INFO: Phase 3: Updating final 9(9+0) entities and  3 relations from doc-42697d809be5c955fc04ae7ab759f093\n",
      "INFO: Completed merging: 9 entities, 0 extra entities, 3 relations\n",
      "INFO: [_] Writing graph with 79 nodes, 52 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-57c5724b60c29ba07f8f97ea8e780120\n",
      "INFO:  == LLM cache == saving: default:extract:8c22bec32485dbb6881571d5e5a0597f\n",
      "INFO:  == LLM cache == saving: default:extract:6d422cbb5b11e5a7beeae46ce7c48b67\n",
      "INFO: Chunk 1 of 1 extracted 7 Ent + 5 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 7 entities from doc-57c5724b60c29ba07f8f97ea8e780120 (async: 8)\n",
      "INFO: Merged: `Samsung` | 0+1\n",
      "INFO: Merged: `Galaxy Z Flip 8` | 0+1\n",
      "INFO: Merged: `Snapdragon 8 Elite Gen 5` | 0+1\n",
      "INFO: Merged: `Qualcomm` | 0+1\n",
      "INFO: Merged: `2nm process` | 0+1\n",
      "INFO: Merged: `Android Central` | 0+1\n",
      "INFO: Merged: `October 10, 2025` | 0+1\n",
      "INFO: Phase 2: Processing 5 relations from doc-57c5724b60c29ba07f8f97ea8e780120 (async: 8)\n",
      "INFO: Merged: `Galaxy Z Flip 8`~`Samsung` | 0+1\n",
      "INFO: Merged: `Qualcomm`~`Snapdragon 8 Elite Gen 5` | 0+1\n",
      "INFO: Merged: `2nm process`~`Snapdragon 8 Elite Gen 5` | 0+1\n",
      "INFO: Merged: `Samsung`~`Snapdragon 8 Elite Gen 5` | 0+1\n",
      "INFO: Merged: `Android Central`~`Samsung` | 0+1\n",
      "INFO: Phase 3: Updating final 7(7+0) entities and  5 relations from doc-57c5724b60c29ba07f8f97ea8e780120\n",
      "INFO: Completed merging: 7 entities, 0 extra entities, 5 relations\n",
      "INFO: [_] Writing graph with 86 nodes, 57 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO:updated_architectures.implementation.ice_simplified:Batch processing completed: 5 successful, 0 failed\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ Historical data ingested for TSMC: 5 documents\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetching 1 years of historical data for AMD\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched company overview for AMD from Alpha Vantage\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 5 news articles for AMD from NewsAPI\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 6 total documents for AMD\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-2a057e6acd82aa6b8ef136f582e8994d\n",
      "INFO:  == LLM cache == saving: default:extract:7353dbf1442e203c940c237684051d69\n",
      "INFO:  == LLM cache == saving: default:extract:36ba5402f4300b17752d4b4808b53e1d\n",
      "INFO: Chunk 1 of 1 extracted 12 Ent + 11 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 12 entities from doc-2a057e6acd82aa6b8ef136f582e8994d (async: 8)\n",
      "INFO: Merged: `Advanced Micro Devices Inc` | 0+1\n",
      "INFO: Merged: `Santa Clara` | 1+1\n",
      "INFO: Merged: `Semiconductors` | 1+1\n",
      "INFO: Merged: `NASDAQ` | 1+1\n",
      "INFO: Merged: `Technology` | 0+1\n",
      "INFO: Merged: `microprocessors` | 0+1\n",
      "INFO: Merged: `graphics processors` | 0+1\n",
      "INFO: Merged: `motherboard chipsets` | 0+1\n",
      "INFO: Merged: `revenue per share` | 0+1\n",
      "INFO: Merged: `market capitalization` | 0+1\n",
      "INFO: Merged: `profit margin` | 0+1\n",
      "INFO: Merged: `operating margin` | 0+1\n",
      "INFO: Phase 2: Processing 11 relations from doc-2a057e6acd82aa6b8ef136f582e8994d (async: 8)\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`Santa Clara` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`NASDAQ` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`Semiconductors` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`Technology` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`microprocessors` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`graphics processors` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`motherboard chipsets` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`revenue per share` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`market capitalization` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`profit margin` | 0+1\n",
      "INFO: Merged: `Advanced Micro Devices Inc`~`operating margin` | 0+1\n",
      "INFO: Phase 3: Updating final 12(12+0) entities and  11 relations from doc-2a057e6acd82aa6b8ef136f582e8994d\n",
      "INFO: Completed merging: 12 entities, 0 extra entities, 11 relations\n",
      "INFO: [_] Writing graph with 95 nodes, 68 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "WARNING: Ignoring document ID (already exists): doc-62625d410d19d19397adca7deda5ce89 (unknown_source)\n",
      "WARNING: No new unique documents were found.\n",
      "INFO: No documents to process\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-3c815629a856816b3718cd2cef26236a\n",
      "INFO:  == LLM cache == saving: default:extract:9a44bebbc0691c938cfade388df8b62a\n",
      "INFO:  == LLM cache == saving: default:extract:29b683f3b0f1b12026073400907601bc\n",
      "INFO: Chunk 1 of 1 extracted 9 Ent + 6 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 9 entities from doc-3c815629a856816b3718cd2cef26236a (async: 8)\n",
      "INFO: Merged: `Panther Lake` | 0+1\n",
      "INFO: Merged: `Intel` | 4+1\n",
      "INFO: Merged: `Apple` | 2+1\n",
      "INFO: Merged: `AMD` | 1+1\n",
      "INFO: Merged: `Qualcomm` | 1+1\n",
      "INFO: Merged: `Intel Core Ultra` | 0+1\n",
      "INFO: Merged: `The Verge` | 1+1\n",
      "INFO: Merged: `Sean Hollister` | 1+1\n",
      "INFO: Merged: `18A Process` | 0+1\n",
      "INFO: Phase 2: Processing 6 relations from doc-3c815629a856816b3718cd2cef26236a (async: 8)\n",
      "INFO: Merged: `Intel`~`Panther Lake` | 0+1\n",
      "INFO: Merged: `Sean Hollister`~`The Verge` | 1+1\n",
      "INFO: Merged: `18A Process`~`Panther Lake` | 0+1\n",
      "INFO: Merged: `Apple`~`Intel` | 2+1\n",
      "INFO: Merged: `AMD`~`Intel` | 0+1\n",
      "INFO: Merged: `Intel`~`Qualcomm` | 0+1\n",
      "INFO: Phase 3: Updating final 9(9+0) entities and  6 relations from doc-3c815629a856816b3718cd2cef26236a\n",
      "INFO: Completed merging: 9 entities, 0 extra entities, 6 relations\n",
      "INFO: [_] Writing graph with 98 nodes, 72 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-832fc2d3bef89cd51835081164d3a1ab\n",
      "INFO:  == LLM cache == saving: default:extract:0e981c800f4c05194e3b1612f9cb401d\n",
      "INFO:  == LLM cache == saving: default:extract:e7e79ee768706b78fb47befa6393ba76\n",
      "INFO: Chunk 1 of 1 extracted 9 Ent + 5 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 9 entities from doc-832fc2d3bef89cd51835081164d3a1ab (async: 8)\n",
      "INFO: Merged: `OpenAI` | 0+1\n",
      "INFO: Merged: `Sam Altman` | 0+1\n",
      "INFO: Merged: `Nvidia` | 5+1\n",
      "INFO: Merged: `AMD` | 2+1\n",
      "INFO: Merged: `6 gigawatts` | 0+1\n",
      "INFO: Merged: `multibillion-dollar deal` | 0+1\n",
      "INFO: Merged: `Gizmodo` | 0+1\n",
      "INFO: Merged: `2025-10-06` | 0+1\n",
      "INFO: Merged: `https://gizmodo.com/openai-gobbles-up-a-stake-in-amd-as-its-spending-spree-shows-no-sign-of-stopping-2000668016` | 0+1\n",
      "INFO: Phase 2: Processing 5 relations from doc-832fc2d3bef89cd51835081164d3a1ab (async: 8)\n",
      "INFO: Merged: `AMD`~`OpenAI` | 0+1\n",
      "INFO: Merged: `OpenAI`~`Sam Altman` | 0+1\n",
      "INFO: Merged: `Nvidia`~`OpenAI` | 0+1\n",
      "INFO: Merged: `Gizmodo`~`OpenAI` | 0+1\n",
      "INFO: Merged: `6 gigawatts`~`OpenAI` | 0+1\n",
      "INFO: Phase 3: Updating final 9(9+0) entities and  5 relations from doc-832fc2d3bef89cd51835081164d3a1ab\n",
      "INFO: Completed merging: 9 entities, 0 extra entities, 5 relations\n",
      "INFO: [_] Writing graph with 105 nodes, 77 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-1429e01f96d6dafa64621af6b11024a5\n",
      "INFO:  == LLM cache == saving: default:extract:fbf474eafa33a62ae026589d0c4ab178\n",
      "INFO:  == LLM cache == saving: default:extract:d06fe55cb658c4f9744288c8046c084d\n",
      "INFO: Chunk 1 of 1 extracted 9 Ent + 6 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 9 entities from doc-1429e01f96d6dafa64621af6b11024a5 (async: 8)\n",
      "INFO: Merged: `Xbox` | 0+1\n",
      "INFO: Merged: `Microsoft` | 1+1\n",
      "INFO: Merged: `Game Pass` | 0+1\n",
      "INFO: Merged: `Sony` | 0+1\n",
      "INFO: Merged: `Next-Gen Xbox` | 0+1\n",
      "INFO: Merged: `Gizmodo.com` | 0+1\n",
      "INFO: Merged: `2025-10-09` | 0+1\n",
      "INFO: Merged: `24 Years` | 0+1\n",
      "INFO: Merged: `Price Hikes` | 0+1\n",
      "INFO: Phase 2: Processing 6 relations from doc-1429e01f96d6dafa64621af6b11024a5 (async: 8)\n",
      "INFO: Merged: `Microsoft`~`Xbox` | 0+1\n",
      "INFO: Merged: `Sony`~`Xbox` | 0+1\n",
      "INFO: Merged: `Game Pass`~`Xbox` | 0+1\n",
      "INFO: Merged: `Next-Gen Xbox`~`Xbox` | 0+1\n",
      "INFO: Merged: `Gizmodo.com`~`Xbox` | 0+1\n",
      "INFO: Merged: `Price Hikes`~`Xbox` | 0+1\n",
      "INFO: Phase 3: Updating final 9(9+0) entities and  6 relations from doc-1429e01f96d6dafa64621af6b11024a5\n",
      "INFO: Completed merging: 9 entities, 0 extra entities, 6 relations\n",
      "INFO: [_] Writing graph with 113 nodes, 83 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-1321a624390cb3ff995de58a9d80bb50\n",
      "INFO:  == LLM cache == saving: default:extract:279ff929c945afb0baa34a0b4eb351a3\n",
      "INFO:  == LLM cache == saving: default:extract:589e4601ff03fd63271d48816a8e5334\n",
      "INFO: Chunk 1 of 1 extracted 7 Ent + 5 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 7 entities from doc-1321a624390cb3ff995de58a9d80bb50 (async: 8)\n",
      "INFO: Merged: `AMD` | 3+1\n",
      "INFO: Merged: `Artificial Intelligence Partnership` | 0+1\n",
      "INFO: Merged: `Yahoo Entertainment` | 4+1\n",
      "INFO: Merged: `Stock Increase` | 0+1\n",
      "INFO: Merged: `NASDAQ:AMD` | 0+1\n",
      "INFO: Merged: `2025-10-02` | 0+1\n",
      "INFO: Merged: `Stock Market` | 0+1\n",
      "INFO: Phase 2: Processing 5 relations from doc-1321a624390cb3ff995de58a9d80bb50 (async: 8)\n",
      "INFO: Merged: `AMD`~`Artificial Intelligence Partnership` | 0+1\n",
      "INFO: Merged: `2025-10-02`~`Yahoo Entertainment` | 0+1\n",
      "INFO: Merged: `AMD`~`Stock Increase` | 0+1\n",
      "INFO: Merged: `AMD`~`Yahoo Entertainment` | 0+1\n",
      "INFO: Merged: `AMD`~`NASDAQ:AMD` | 0+1\n",
      "INFO: Phase 3: Updating final 7(7+0) entities and  5 relations from doc-1321a624390cb3ff995de58a9d80bb50\n",
      "INFO: Completed merging: 7 entities, 0 extra entities, 5 relations\n",
      "INFO: [_] Writing graph with 118 nodes, 88 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO:updated_architectures.implementation.ice_simplified:Batch processing completed: 6 successful, 0 failed\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ Historical data ingested for AMD: 6 documents\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetching 1 years of historical data for ASML\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched company overview for ASML from Alpha Vantage\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 5 news articles for ASML from NewsAPI\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 6 total documents for ASML\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-8573de018e85174e3bfa447a9288cace\n",
      "INFO:  == LLM cache == saving: default:extract:941b497f7637a4be076c61fe550b9c81\n",
      "INFO:  == LLM cache == saving: default:extract:fba0ac2a3ab655fd7c125ea0f8300fb6\n",
      "INFO: Chunk 1 of 1 extracted 9 Ent + 8 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 9 entities from doc-8573de018e85174e3bfa447a9288cace (async: 8)\n",
      "INFO: Merged: `ASML Holding NV` | 0+1\n",
      "INFO: Merged: `Veldhoven` | 0+1\n",
      "INFO: Merged: `NASDAQ` | 2+1\n",
      "INFO: Merged: `Technology Sector` | 1+1\n",
      "INFO: Merged: `Semiconductor Equipment & Materials` | 0+1\n",
      "INFO: Merged: `Market Capitalization` | 1+1\n",
      "INFO: Merged: `EUV Lithography` | 0+1\n",
      "INFO: Merged: `Dividend Per Share` | 0+1\n",
      "INFO: Merged: `EPS` | 0+1\n",
      "INFO: Phase 2: Processing 8 relations from doc-8573de018e85174e3bfa447a9288cace (async: 8)\n",
      "INFO: Merged: `ASML Holding NV`~`Veldhoven` | 0+1\n",
      "INFO: Merged: `ASML Holding NV`~`NASDAQ` | 0+1\n",
      "INFO: Merged: `ASML Holding NV`~`Technology Sector` | 0+1\n",
      "INFO: Merged: `ASML Holding NV`~`Semiconductor Equipment & Materials` | 0+1\n",
      "INFO: Merged: `ASML Holding NV`~`EUV Lithography` | 0+1\n",
      "INFO: Merged: `ASML Holding NV`~`Market Capitalization` | 0+1\n",
      "INFO: Merged: `ASML Holding NV`~`Dividend Per Share` | 0+1\n",
      "INFO: Merged: `ASML Holding NV`~`EPS` | 0+1\n",
      "INFO: Phase 3: Updating final 9(9+0) entities and  8 relations from doc-8573de018e85174e3bfa447a9288cace\n",
      "INFO: Completed merging: 9 entities, 0 extra entities, 8 relations\n",
      "INFO: [_] Writing graph with 124 nodes, 96 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-e8d33af55c47ac039ecd759bc44bd9f4\n",
      "INFO:  == LLM cache == saving: default:extract:e8af6a9bc00e28c931073d5d9271f711\n",
      "INFO:  == LLM cache == saving: default:extract:2fbd28c882bf8c2fe9062df150379451\n",
      "INFO: Chunk 1 of 1 extracted 7 Ent + 4 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 7 entities from doc-e8d33af55c47ac039ecd759bc44bd9f4 (async: 8)\n",
      "INFO: Merged: `US Committee` | 0+1\n",
      "INFO: Merged: `China` | 1+1\n",
      "INFO: Merged: `ASML` | 0+1\n",
      "INFO: Merged: `Semiconductor Industry` | 0+1\n",
      "INFO: Merged: `Export Restrictions` | 0+1\n",
      "INFO: Merged: `Heise Online` | 1+1\n",
      "INFO: Merged: `Report` | 0+1\n",
      "INFO: Phase 2: Processing 4 relations from doc-e8d33af55c47ac039ecd759bc44bd9f4 (async: 8)\n",
      "INFO: Merged: `China`~`US Committee` | 0+1\n",
      "INFO: Merged: `Heise Online`~`US Committee` | 0+1\n",
      "INFO: Merged: `ASML`~`China` | 0+1\n",
      "INFO: Merged: `Report`~`US Committee` | 0+1\n",
      "INFO: Phase 3: Updating final 7(7+0) entities and  4 relations from doc-e8d33af55c47ac039ecd759bc44bd9f4\n",
      "INFO: Completed merging: 7 entities, 0 extra entities, 4 relations\n",
      "INFO: [_] Writing graph with 129 nodes, 100 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-d0cc82ea57f4e819665c453a7cbb2d0a\n",
      "INFO:  == LLM cache == saving: default:extract:20ffaf40e27d8f2e4d5517015cc6e127\n",
      "INFO:  == LLM cache == saving: default:extract:3b30c60bb5a8a1f7e22a8d8e757ef942\n",
      "INFO: Chunk 1 of 1 extracted 10 Ent + 7 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 10 entities from doc-d0cc82ea57f4e819665c453a7cbb2d0a (async: 8)\n",
      "INFO: Merged: `SMIC` | 0+1\n",
      "INFO: Merged: `Yuliangsheng` | 0+1\n",
      "INFO: Merged: `Lithography System` | 0+1\n",
      "INFO: Merged: `ASML` | 1+1\n",
      "INFO: Merged: `28-nm Chips` | 0+1\n",
      "INFO: Merged: `7-nm Chips` | 0+1\n",
      "INFO: Merged: `heise online` | 0+1\n",
      "INFO: Merged: `September 17, 2025` | 0+1\n",
      "INFO: Merged: `Lithography System Prototypes` | 0+1\n",
      "INFO: Merged: `Chips` | 1+1\n",
      "INFO: Phase 2: Processing 7 relations from doc-d0cc82ea57f4e819665c453a7cbb2d0a (async: 8)\n",
      "INFO: Merged: `SMIC`~`Yuliangsheng` | 0+1\n",
      "INFO: Merged: `Lithography System`~`Yuliangsheng` | 0+1\n",
      "INFO: Merged: `SMIC`~`heise online` | 0+1\n",
      "INFO: Merged: `ASML`~`Yuliangsheng` | 0+1\n",
      "INFO: Merged: `28-nm Chips`~`Lithography System` | 0+1\n",
      "INFO: Merged: `7-nm Chips`~`Lithography System` | 0+1\n",
      "INFO: Merged: `Lithography System Prototypes`~`Yuliangsheng` | 0+1\n",
      "INFO: Phase 3: Updating final 10(10+0) entities and  7 relations from doc-d0cc82ea57f4e819665c453a7cbb2d0a\n",
      "INFO: Completed merging: 10 entities, 0 extra entities, 7 relations\n",
      "INFO: [_] Writing graph with 137 nodes, 107 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-8ec6bbc2b6bdcebe5477260643dc54cf\n",
      "INFO:  == LLM cache == saving: default:extract:0facc236d756f9961833854766818a4d\n",
      "INFO:  == LLM cache == saving: default:extract:398b71cd97f2a9b553d4c87ffa875ca0\n",
      "INFO: Chunk 1 of 1 extracted 8 Ent + 5 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 8 entities from doc-8ec6bbc2b6bdcebe5477260643dc54cf (async: 8)\n",
      "INFO: Merged: `Mistral` | 0+1\n",
      "INFO: Merged: `Paris` | 0+1\n",
      "INFO: Merged: `Wall Street Journal` | 0+1\n",
      "INFO: Merged: `Enterprises` | 0+1\n",
      "INFO: Merged: `Post-Training` | 0+1\n",
      "INFO: Merged: `Dutch Chip-Equipment Company` | 0+1\n",
      "INFO: Merged: `Slashdot.org` | 0+1\n",
      "INFO: Merged: `2025-09-28T11:34:00Z` | 0+1\n",
      "INFO: Phase 2: Processing 5 relations from doc-8ec6bbc2b6bdcebe5477260643dc54cf (async: 8)\n",
      "INFO: Merged: `Mistral`~`Wall Street Journal` | 0+1\n",
      "INFO: Merged: `Enterprises`~`Mistral` | 0+1\n",
      "INFO: Merged: `Mistral`~`Post-Training` | 0+1\n",
      "INFO: Merged: `Dutch Chip-Equipment Company`~`Mistral` | 0+1\n",
      "INFO: Merged: `Mistral`~`Slashdot.org` | 0+1\n",
      "INFO: Phase 3: Updating final 8(8+0) entities and  5 relations from doc-8ec6bbc2b6bdcebe5477260643dc54cf\n",
      "INFO: Completed merging: 8 entities, 0 extra entities, 5 relations\n",
      "INFO: [_] Writing graph with 145 nodes, 112 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-a4305906fa75b7dad9070a804f2bb998\n",
      "INFO:  == LLM cache == saving: default:extract:54b32a5ff57a523a24848fd9f38efdb0\n",
      "INFO:  == LLM cache == saving: default:extract:573ee39f85594d39efbf839a82868099\n",
      "INFO: Chunk 1 of 1 extracted 7 Ent + 4 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 7 entities from doc-a4305906fa75b7dad9070a804f2bb998 (async: 8)\n",
      "INFO: Merged: `China` | 2+1\n",
      "INFO: Merged: `SMIC` | 1+1\n",
      "INFO: Merged: `Deep Ultraviolet Photolithography Machine` | 0+1\n",
      "INFO: Merged: `ASML` | 2+1\n",
      "INFO: Merged: `Xataka.com` | 1+1\n",
      "INFO: Merged: `2025-09-17` | 1+1\n",
      "INFO: Merged: `iPhone` | 0+1\n",
      "INFO: Phase 2: Processing 4 relations from doc-a4305906fa75b7dad9070a804f2bb998 (async: 8)\n",
      "INFO: Merged: `China`~`SMIC` | 0+1\n",
      "INFO: Merged: `Deep Ultraviolet Photolithography Machine`~`SMIC` | 0+1\n",
      "INFO: Merged: `ASML`~`China` | 1+1\n",
      "INFO: Merged: `China`~`Xataka.com` | 0+1\n",
      "INFO: Phase 3: Updating final 7(7+0) entities and  4 relations from doc-a4305906fa75b7dad9070a804f2bb998\n",
      "INFO: Completed merging: 7 entities, 0 extra entities, 4 relations\n",
      "INFO: [_] Writing graph with 147 nodes, 115 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-03f1a38a0df6b48d8a400008a51bc355\n",
      "INFO:  == LLM cache == saving: default:extract:cdaa29ab83ffe4bba1e0b6c08edce090\n",
      "INFO:  == LLM cache == saving: default:extract:ba7fd13420cad73ce54750e5913f3d8b\n",
      "INFO: Chunk 1 of 1 extracted 6 Ent + 4 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 6 entities from doc-03f1a38a0df6b48d8a400008a51bc355 (async: 8)\n",
      "INFO: Merged: `ASML` | 3+1\n",
      "INFO: Merged: `China` | 3+1\n",
      "INFO: Merged: `Chips` | 2+1\n",
      "INFO: Merged: `European Industry` | 0+1\n",
      "INFO: Merged: `Lithography Machines` | 0+1\n",
      "INFO: Merged: `United States` | 1+1\n",
      "INFO: Phase 2: Processing 4 relations from doc-03f1a38a0df6b48d8a400008a51bc355 (async: 8)\n",
      "INFO: Merged: `ASML`~`Chips` | 0+1\n",
      "INFO: Merged: `ASML`~`China` | 2+1\n",
      "INFO: Merged: `ASML`~`Lithography Machines` | 0+1\n",
      "INFO: Merged: `ASML`~`European Industry` | 0+1\n",
      "INFO: Phase 3: Updating final 6(6+0) entities and  4 relations from doc-03f1a38a0df6b48d8a400008a51bc355\n",
      "INFO: Completed merging: 6 entities, 0 extra entities, 4 relations\n",
      "INFO: [_] Writing graph with 149 nodes, 118 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO:updated_architectures.implementation.ice_simplified:Batch processing completed: 6 successful, 0 failed\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ Historical data ingested for ASML: 6 documents\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetching 1 years of historical data for FICO\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched company overview for FICO from Alpha Vantage\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 5 news articles for FICO from NewsAPI\n",
      "INFO:updated_architectures.implementation.ice_simplified:Fetched 6 total documents for FICO\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-e551f948d393f93177704ae579730dca\n",
      "INFO:  == LLM cache == saving: default:extract:e480656e56830dabbe5728ce6d9890dc\n",
      "INFO:  == LLM cache == saving: default:extract:3226a23aaaf67a811c27a9b8f197d27c\n",
      "INFO: Chunk 1 of 1 extracted 27 Ent + 6 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 27 entities from doc-e551f948d393f93177704ae579730dca (async: 8)\n",
      "INFO: Merged: `Fair Isaac Corporation` | 0+1\n",
      "INFO: Merged: `USA` | 1+1\n",
      "INFO: Merged: `San Jose` | 0+1\n",
      "INFO: Merged: `Data Analytics` | 0+1\n",
      "INFO: Merged: `Software Solutions` | 0+1\n",
      "INFO: Merged: `Financial Services` | 0+1\n",
      "INFO: Merged: `Healthcare` | 0+1\n",
      "INFO: Merged: `Telecommunications` | 0+1\n",
      "INFO: Merged: `FICO` | 0+1\n",
      "INFO: Merged: `NYSE` | 0+1\n",
      "INFO: Merged: `Technology Sector` | 2+1\n",
      "INFO: Merged: `Software - Application` | 0+1\n",
      "INFO: Merged: `Market Capitalization` | 2+1\n",
      "INFO: Merged: `PE Ratio` | 0+1\n",
      "INFO: Merged: `PEG Ratio` | 0+1\n",
      "INFO: Merged: `Book Value` | 0+1\n",
      "INFO: Merged: `Dividend Per Share` | 1+1\n",
      "INFO: Merged: `EPS` | 1+1\n",
      "INFO: Merged: `Revenue Per Share` | 1+1\n",
      "INFO: Merged: `Profit Margin` | 1+1\n",
      "INFO: Merged: `Operating Margin` | 0+1\n",
      "INFO: Merged: `Return on Assets` | 0+1\n",
      "INFO: Merged: `Return on Equity` | 0+1\n",
      "INFO: Merged: `52 Week High` | 0+1\n",
      "INFO: Merged: `52 Week Low` | 0+1\n",
      "INFO: Merged: `50 Day Moving Average` | 0+1\n",
      "INFO: Merged: `200 Day Moving Average` | 0+1\n",
      "INFO: Phase 2: Processing 6 relations from doc-e551f948d393f93177704ae579730dca (async: 8)\n",
      "INFO: Merged: `Fair Isaac Corporation`~`USA` | 0+1\n",
      "INFO: Merged: `Data Analytics`~`Fair Isaac Corporation` | 0+1\n",
      "INFO: Merged: `Fair Isaac Corporation`~`Software Solutions` | 0+1\n",
      "INFO: Merged: `Fair Isaac Corporation`~`Financial Services` | 0+1\n",
      "INFO: Merged: `Fair Isaac Corporation`~`Healthcare` | 0+1\n",
      "INFO: Merged: `Fair Isaac Corporation`~`Telecommunications` | 0+1\n",
      "INFO: Phase 3: Updating final 27(27+0) entities and  6 relations from doc-e551f948d393f93177704ae579730dca\n",
      "INFO: Completed merging: 27 entities, 0 extra entities, 6 relations\n",
      "INFO: [_] Writing graph with 169 nodes, 124 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-bac50acd741a3921e1930607f9968448\n",
      "INFO:  == LLM cache == saving: default:extract:e1c4e7fa7bf0573528db550a4f9174e1\n",
      "INFO:  == LLM cache == saving: default:extract:c08581dfdc49a1a5480ebea417d66bce\n",
      "INFO: Chunk 1 of 1 extracted 9 Ent + 6 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 9 entities from doc-bac50acd741a3921e1930607f9968448 (async: 8)\n",
      "INFO: Merged: `Gen Z` | 0+1\n",
      "INFO: Merged: `Trump` | 0+1\n",
      "INFO: Merged: `FICO` | 1+1\n",
      "INFO: Merged: `Student-Loan Debt Collections` | 0+1\n",
      "INFO: Merged: `Credit Scores` | 0+1\n",
      "INFO: Merged: `Business Insider` | 0+1\n",
      "INFO: Merged: `2025-09-16` | 0+1\n",
      "INFO: Merged: `Debt Collections Restart` | 0+1\n",
      "INFO: Merged: `Inflation` | 0+1\n",
      "INFO: Phase 2: Processing 6 relations from doc-bac50acd741a3921e1930607f9968448 (async: 8)\n",
      "INFO: Merged: `Student-Loan Debt Collections`~`Trump` | 0+1\n",
      "INFO: Merged: `Credit Scores`~`Gen Z` | 0+1\n",
      "INFO: Merged: `FICO`~`Gen Z` | 0+1\n",
      "INFO: Merged: `Business Insider`~`Trump` | 0+1\n",
      "INFO: Merged: `Debt Collections Restart`~`Gen Z` | 0+1\n",
      "INFO: Merged: `Inflation`~`Trump` | 0+1\n",
      "INFO: Phase 3: Updating final 9(9+0) entities and  6 relations from doc-bac50acd741a3921e1930607f9968448\n",
      "INFO: Completed merging: 9 entities, 0 extra entities, 6 relations\n",
      "INFO: [_] Writing graph with 177 nodes, 130 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-466de27f34ffd02363ce943c258fb247\n",
      "INFO:  == LLM cache == saving: default:extract:e8ca35a59ae00d760c9143a20bc91256\n",
      "INFO:  == LLM cache == saving: default:extract:3961d91c778e2b9e4b581bab287152fb\n",
      "INFO: Chunk 1 of 1 extracted 6 Ent + 4 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 6 entities from doc-466de27f34ffd02363ce943c258fb247 (async: 8)\n",
      "INFO: Merged: `Slovakia` | 0+1\n",
      "INFO: Merged: `National Identity` | 0+1\n",
      "INFO: Merged: `Constitution` | 0+1\n",
      "INFO: Merged: `Jan Lopatka` | 0+1\n",
      "INFO: Merged: `EU Legislation` | 0+1\n",
      "INFO: Merged: `Yahoo Entertainment` | 5+1\n",
      "INFO: Phase 2: Processing 4 relations from doc-466de27f34ffd02363ce943c258fb247 (async: 8)\n",
      "INFO: Merged: `National Identity`~`Slovakia` | 0+1\n",
      "INFO: Merged: `Constitution`~`EU Legislation` | 0+1\n",
      "INFO: Merged: `Jan Lopatka`~`Slovakia` | 0+1\n",
      "INFO: Merged: `Jan Lopatka`~`Yahoo Entertainment` | 0+1\n",
      "INFO: Phase 3: Updating final 6(6+0) entities and  4 relations from doc-466de27f34ffd02363ce943c258fb247\n",
      "INFO: Completed merging: 6 entities, 0 extra entities, 4 relations\n",
      "INFO: [_] Writing graph with 182 nodes, 134 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-42effd4decb685e3b717668883d3a723\n",
      "INFO:  == LLM cache == saving: default:extract:199a8e390c02c604fc3b3244ac731310\n",
      "INFO:  == LLM cache == saving: default:extract:00c652ec7ede438f798f9a005bcbeef4\n",
      "INFO: Chunk 1 of 1 extracted 9 Ent + 6 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 9 entities from doc-42effd4decb685e3b717668883d3a723 (async: 8)\n",
      "INFO: Merged: `Slovakia` | 1+1\n",
      "INFO: Merged: `Robert Fico` | 0+1\n",
      "INFO: Merged: `Protests Against Fico Government` | 0+1\n",
      "INFO: Merged: `Austerity Program` | 0+1\n",
      "INFO: Merged: `Vladimir Putin` | 0+1\n",
      "INFO: Merged: `17th September 2025` | 0+1\n",
      "INFO: Merged: `Tagesschau.de` | 0+1\n",
      "INFO: Merged: `URL: https://www.tagesschau.de/ausland/europa/slowakei-demos-fico-100.html` | 0+1\n",
      "INFO: Merged: `Date of Reporting` | 0+1\n",
      "INFO: Phase 2: Processing 6 relations from doc-42effd4decb685e3b717668883d3a723 (async: 8)\n",
      "INFO: Merged: `Protests Against Fico Government`~`Slovakia` | 0+1\n",
      "INFO: Merged: `Robert Fico`~`Vladimir Putin` | 0+1\n",
      "INFO: Merged: `Protests Against Fico Government`~`Robert Fico` | 0+1\n",
      "INFO: Merged: `Austerity Program`~`Protests Against Fico Government` | 0+1\n",
      "INFO: Merged: `Protests Against Fico Government`~`Tagesschau.de` | 0+1\n",
      "INFO: Merged: `Date of Reporting`~`Protests Against Fico Government` | 0+1\n",
      "INFO: Phase 3: Updating final 9(9+0) entities and  6 relations from doc-42effd4decb685e3b717668883d3a723\n",
      "INFO: Completed merging: 9 entities, 0 extra entities, 6 relations\n",
      "INFO: [_] Writing graph with 190 nodes, 140 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-833cc9d81f73cf8806fb89cd6e1cd209\n",
      "INFO:  == LLM cache == saving: default:extract:7ce6a647f7138d36171d6c4770e406f9\n",
      "INFO:  == LLM cache == saving: default:extract:116022bde53d91f91d6b7577c37e1f8d\n",
      "INFO: Chunk 1 of 1 extracted 6 Ent + 4 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 6 entities from doc-833cc9d81f73cf8806fb89cd6e1cd209 (async: 8)\n",
      "INFO: Merged: `Slowakei` | 0+1\n",
      "INFO: Merged: `Robert Fico` | 1+1\n",
      "INFO: Merged: `Protests` | 0+1\n",
      "INFO: Merged: `Putin` | 0+1\n",
      "INFO: Merged: `Austerity Measures` | 0+1\n",
      "INFO: Merged: `Die Zeit` | 0+1\n",
      "INFO: Phase 2: Processing 4 relations from doc-833cc9d81f73cf8806fb89cd6e1cd209 (async: 8)\n",
      "INFO: Merged: `Protests`~`Robert Fico` | 0+1\n",
      "INFO: Merged: `Putin`~`Robert Fico` | 0+1\n",
      "INFO: Merged: `Protests`~`Slowakei` | 0+1\n",
      "INFO: Merged: `Die Zeit`~`Protests` | 0+1\n",
      "INFO: Phase 3: Updating final 6(6+0) entities and  4 relations from doc-833cc9d81f73cf8806fb89cd6e1cd209\n",
      "INFO: Completed merging: 6 entities, 0 extra entities, 4 relations\n",
      "INFO: [_] Writing graph with 195 nodes, 144 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-57a594e7691fae9634f53be5a8f85d95\n",
      "INFO:  == LLM cache == saving: default:extract:4aea970d18f1f0c251c646187400ec54\n",
      "INFO:  == LLM cache == saving: default:extract:cfec806e550be52b63c207ef7cac5ee2\n",
      "INFO: Chunk 1 of 1 extracted 8 Ent + 5 Rel\n",
      "INFO: Merging stage 1/1: unknown_source\n",
      "INFO: Phase 1: Processing 8 entities from doc-57a594e7691fae9634f53be5a8f85d95 (async: 8)\n",
      "INFO: Merged: `Robert Fico` | 2+1\n",
      "INFO: Merged: `Bratislava` | 0+1\n",
      "INFO: Merged: `Russia` | 0+1\n",
      "INFO: Merged: `European Union (EU)` | 0+1\n",
      "INFO: Merged: `Protests` | 1+1\n",
      "INFO: Merged: `Die Zeit` | 1+1\n",
      "INFO: Merged: `September 11, 2025` | 0+1\n",
      "INFO: Merged: `Thousands of Demonstrators` | 0+1\n",
      "INFO: Phase 2: Processing 5 relations from doc-57a594e7691fae9634f53be5a8f85d95 (async: 8)\n",
      "INFO: Merged: `Bratislava`~`Robert Fico` | 0+1\n",
      "INFO: Merged: `Die Zeit`~`Protests` | 1+1\n",
      "INFO: Merged: `European Union (EU)`~`Robert Fico` | 0+1\n",
      "INFO: Merged: `Bratislava`~`Protests` | 0+1\n",
      "INFO: Merged: `Bratislava`~`Thousands of Demonstrators` | 0+1\n",
      "INFO: Phase 3: Updating final 8(8+0) entities and  5 relations from doc-57a594e7691fae9634f53be5a8f85d95\n",
      "INFO: Completed merging: 8 entities, 0 extra entities, 5 relations\n",
      "INFO: [_] Writing graph with 200 nodes, 148 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: unknown_source\n",
      "INFO: Enqueued document processing pipeline stoped\n",
      "INFO:src.ice_core.ice_system_manager:Document added: type=financial_historical, graph_updated=True\n",
      "INFO:updated_architectures.implementation.ice_simplified:Batch processing completed: 6 successful, 0 failed\n",
      "INFO:updated_architectures.implementation.ice_simplified:‚úÖ Historical data ingested for FICO: 6 documents\n",
      "INFO:updated_architectures.implementation.ice_simplified:Historical data ingestion completed: 5/5 successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Ingestion Results:\n",
      "  Status: success\n",
      "  Holdings: 5/5\n",
      "  Documents: 29\n",
      "  ‚úÖ Successful: NVDA, TSMC, AMD, ASML, FICO\n",
      "\n",
      "‚è±Ô∏è  Processing Time: 529.51s\n",
      "  Data Sources: alpha_vantage, newsapi, polygon, finnhub\n"
     ]
    }
   ],
   "source": [
    "# Execute data ingestion\n",
    "# NOTE: This operation may take several minutes. If it hangs, restart kernel.\n",
    "print(f\"\\nüì• Fetching Portfolio Data\")\n",
    "print(f\"‚îÅ\" * 50)\n",
    "\n",
    "if not (ice and ice.is_ready()):\n",
    "    raise RuntimeError(\"ICE system not ready for data ingestion\")\n",
    "\n",
    "# Fetch historical data (1 year for faster processing - adjust years parameter as needed)\n",
    "print(f\"üîÑ Fetching data for {len(holdings)} holdings...\")\n",
    "ingestion_result = ice.ingest_historical_data(holdings, years=1) # parameter\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nüìä Ingestion Results:\")\n",
    "print(f\"  Status: {ingestion_result['status']}\")\n",
    "print(f\"  Holdings: {len(ingestion_result['holdings_processed'])}/{len(holdings)}\")\n",
    "print(f\"  Documents: {ingestion_result['total_documents']}\")\n",
    "\n",
    "# Show successful holdings\n",
    "if ingestion_result['holdings_processed']:\n",
    "    print(f\"  ‚úÖ Successful: {', '.join(ingestion_result['holdings_processed'])}\")\n",
    "\n",
    "# Show metrics\n",
    "if 'metrics' in ingestion_result:\n",
    "    print(f\"\\n‚è±Ô∏è  Processing Time: {ingestion_result['metrics']['processing_time']:.2f}s\")\n",
    "    if 'data_sources_used' in ingestion_result['metrics']:\n",
    "        print(f\"  Data Sources: {', '.join(ingestion_result['metrics']['data_sources_used'])}\")\n",
    "\n",
    "# Show failures if any\n",
    "if ingestion_result.get('failed_holdings'):\n",
    "    print(f\"\\n‚ùå Failed Holdings:\")\n",
    "    for failure in ingestion_result['failed_holdings']:\n",
    "        print(f\"  {failure['symbol']}: {failure['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Knowledge Graph Building Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Knowledge Graph Building\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "‚ÑπÔ∏è  NOTE: Knowledge graph building happens automatically during data ingestion\n",
      "   The ingestion method (ingest_historical_data) already added documents\n",
      "   to the graph via LightRAG. This cell validates that building succeeded.\n",
      "\n",
      "‚úÖ KNOWLEDGE GRAPH BUILT SUCCESSFULLY\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "   üìÑ Documents processed: 29\n",
      "   üíæ Storage size: 5.47 MB\n",
      "   üîó Components ready: 4/4\n",
      "\n",
      "üéØ Graph Building Process:\n",
      "   1Ô∏è‚É£ Text Chunking: 1200 tokens (optimal for financial documents)\n",
      "   2Ô∏è‚É£ Entity Extraction: Companies, metrics, risks, regulations\n",
      "   3Ô∏è‚É£ Relationship Discovery: Dependencies, impacts, correlations\n",
      "   4Ô∏è‚É£ Graph Construction: LightRAG optimized structure\n",
      "   5Ô∏è‚É£ Storage: chunks_vdb, entities_vdb, relationships_vdb, graph\n",
      "\n",
      "üöÄ System ready for intelligent queries!\n"
     ]
    }
   ],
   "source": [
    "# Knowledge Graph Building - Already completed during ingestion\n",
    "print(f\"\\nüß† Knowledge Graph Building\")\n",
    "print(f\"‚îÅ\" * 60)\n",
    "\n",
    "if not (ice and ice.core.is_ready()):\n",
    "    raise RuntimeError(\"LightRAG not ready\")\n",
    "\n",
    "print(f\"‚ÑπÔ∏è  NOTE: Knowledge graph building happens automatically during data ingestion\")\n",
    "print(f\"   The ingestion method (ingest_historical_data) already added documents\")\n",
    "print(f\"   to the graph via LightRAG. This cell validates that building succeeded.\\n\")\n",
    "\n",
    "# Validate that building succeeded by checking storage\n",
    "storage_stats = ice.core.get_storage_stats()\n",
    "\n",
    "if storage_stats['total_storage_bytes'] > 0:\n",
    "    print(f\"‚úÖ KNOWLEDGE GRAPH BUILT SUCCESSFULLY\")\n",
    "    print(f\"‚îÅ\" * 40)\n",
    "    print(f\"   üìÑ Documents processed: {ingestion_result.get('total_documents', 0)}\")\n",
    "    print(f\"   üíæ Storage size: {storage_stats['total_storage_bytes'] / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    components_ready = sum(1 for c in storage_stats['components'].values() if c['exists'])\n",
    "    print(f\"   üîó Components ready: {components_ready}/4\")\n",
    "    \n",
    "    # Create success result for metrics tracking\n",
    "    building_result = {\n",
    "        'status': 'success',\n",
    "        'total_documents': ingestion_result.get('total_documents', 0),\n",
    "        'metrics': {\n",
    "            'building_time': ingestion_result.get('metrics', {}).get('processing_time', 0.0),\n",
    "            'graph_initialized': True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüéØ Graph Building Process:\")\n",
    "    print(f\"   1Ô∏è‚É£ Text Chunking: 1200 tokens (optimal for financial documents)\")\n",
    "    print(f\"   2Ô∏è‚É£ Entity Extraction: Companies, metrics, risks, regulations\")\n",
    "    print(f\"   3Ô∏è‚É£ Relationship Discovery: Dependencies, impacts, correlations\")\n",
    "    print(f\"   4Ô∏è‚É£ Graph Construction: LightRAG optimized structure\")\n",
    "    print(f\"   5Ô∏è‚É£ Storage: chunks_vdb, entities_vdb, relationships_vdb, graph\")\n",
    "    \n",
    "    print(f\"\\nüöÄ System ready for intelligent queries!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è NO GRAPH DATA DETECTED\")\n",
    "    print(f\"   Storage size: 0 MB\")\n",
    "    print(f\"   Check ingestion results above for errors\")\n",
    "    print(f\"   Possible causes:\")\n",
    "    print(f\"   - No API keys configured\")\n",
    "    print(f\"   - All holdings failed to fetch data\")\n",
    "    print(f\"   - Network connectivity issues\")\n",
    "    \n",
    "    building_result = {\n",
    "        'status': 'error',\n",
    "        'message': 'No graph data - check ingestion results'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Storage Architecture Validation & Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Storage Architecture Validation\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "üì¶ LightRAG Storage Components Status:\n",
      "  ‚úÖ chunks_vdb:\n",
      "    File: vdb_chunks.json\n",
      "    Purpose: Vector database for document chunks\n",
      "    Size: 0.35 MB\n",
      "  ‚úÖ entities_vdb:\n",
      "    File: vdb_entities.json\n",
      "    Purpose: Vector database for extracted entities\n",
      "    Size: 2.37 MB\n",
      "  ‚úÖ relationships_vdb:\n",
      "    File: vdb_relationships.json\n",
      "    Purpose: Vector database for entity relationships\n",
      "    Size: 1.76 MB\n",
      "  ‚úÖ graph:\n",
      "    File: graph_chunk_entity_relation.graphml\n",
      "    Purpose: NetworkX graph structure\n",
      "    Size: 0.15 MB\n",
      "\n",
      "üìä Storage Summary:\n",
      "  Working Directory: ice_lightrag/storage\n",
      "  Total Storage: 5.47 MB\n",
      "  System Initialized: True\n",
      "\n",
      "üï∏Ô∏è Knowledge Graph Status:\n",
      "  Graph Ready: True\n",
      "  All Components Present: True\n",
      "  Chunks Storage: 0.35 MB\n",
      "  Entity Storage: 2.37 MB\n",
      "  Relationship Storage: 1.76 MB\n",
      "  Graph Structure: 0.15 MB\n",
      "\n",
      "‚úÖ Validation Checks:\n",
      "  ‚úÖ System initialization: PASSED\n",
      "  ‚úÖ Storage directory: PASSED\n",
      "  ‚úÖ Storage components: PASSED (4/4 created)\n",
      "  ‚úÖ Storage content: PASSED\n",
      "\n",
      "üìä Validation Score: 4/4 (100%)\n",
      "üéâ All validations passed! Knowledge graph is ready for queries.\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive storage validation and metrics\n",
    "print(f\"\\nüîç Storage Architecture Validation\")\n",
    "print(f\"‚îÅ\" * 40)\n",
    "\n",
    "if not (ice and ice.core.is_ready()):\n",
    "    raise RuntimeError(\"Cannot validate storage without initialized system\")\n",
    "\n",
    "# Get detailed storage statistics\n",
    "storage_stats = ice.core.get_storage_stats()\n",
    "graph_stats = ice.core.get_graph_stats()\n",
    "\n",
    "print(f\"üì¶ LightRAG Storage Components Status:\")\n",
    "for component_name, component_info in storage_stats['components'].items():\n",
    "    status_icon = \"‚úÖ\" if component_info['exists'] else \"‚ö†Ô∏è\"\n",
    "    size_mb = component_info['size_bytes'] / (1024 * 1024) if component_info['size_bytes'] > 0 else 0\n",
    "    \n",
    "    print(f\"  {status_icon} {component_name}:\")\n",
    "    print(f\"    File: {component_info['file']}\")\n",
    "    print(f\"    Purpose: {component_info['description']}\")\n",
    "    print(f\"    Size: {size_mb:.2f} MB\" if size_mb > 0 else \"    Size: Not created yet\")\n",
    "\n",
    "print(f\"\\nüìä Storage Summary:\")\n",
    "print(f\"  Working Directory: {storage_stats['working_dir']}\")\n",
    "print(f\"  Total Storage: {storage_stats['total_storage_bytes'] / (1024 * 1024):.2f} MB\")\n",
    "print(f\"  System Initialized: {storage_stats['is_initialized']}\")\n",
    "\n",
    "print(f\"\\nüï∏Ô∏è Knowledge Graph Status:\")\n",
    "print(f\"  Graph Ready: {graph_stats['is_ready']}\")\n",
    "if graph_stats.get('storage_indicators'):\n",
    "    indicators = graph_stats['storage_indicators']\n",
    "    print(f\"  All Components Present: {indicators['all_components_present']}\")\n",
    "    print(f\"  Chunks Storage: {indicators['chunks_file_size']:.2f} MB\")\n",
    "    print(f\"  Entity Storage: {indicators['entities_file_size']:.2f} MB\")\n",
    "    print(f\"  Relationship Storage: {indicators['relationships_file_size']:.2f} MB\")\n",
    "    print(f\"  Graph Structure: {indicators['graph_file_size']:.2f} MB\")\n",
    "\n",
    "# Validation checks\n",
    "print(f\"\\n‚úÖ Validation Checks:\")\n",
    "validation_score = 0\n",
    "max_score = 4\n",
    "\n",
    "# Check 1: System ready\n",
    "if storage_stats['is_initialized']:\n",
    "    print(f\"  ‚úÖ System initialization: PASSED\")\n",
    "    validation_score += 1\n",
    "else:\n",
    "    print(f\"  ‚ùå System initialization: FAILED\")\n",
    "\n",
    "# Check 2: Storage exists\n",
    "if storage_stats['storage_exists']:\n",
    "    print(f\"  ‚úÖ Storage directory: PASSED\")\n",
    "    validation_score += 1\n",
    "else:\n",
    "    print(f\"  ‚ùå Storage directory: FAILED\")\n",
    "\n",
    "# Check 3: Components created\n",
    "components_exist = sum(1 for c in storage_stats['components'].values() if c['exists'])\n",
    "if components_exist > 0:\n",
    "    print(f\"  ‚úÖ Storage components: PASSED ({components_exist}/4 created)\")\n",
    "    validation_score += 1\n",
    "else:\n",
    "    print(f\"  ‚ùå Storage components: FAILED (no components created)\")\n",
    "\n",
    "# Check 4: Has storage content\n",
    "if storage_stats['total_storage_bytes'] > 0:\n",
    "    print(f\"  ‚úÖ Storage content: PASSED\")\n",
    "    validation_score += 1\n",
    "else:\n",
    "    print(f\"  ‚ùå Storage content: FAILED (no data stored)\")\n",
    "\n",
    "print(f\"\\nüìä Validation Score: {validation_score}/{max_score} ({(validation_score/max_score)*100:.0f}%)\")\n",
    "\n",
    "if validation_score == max_score:\n",
    "    print(f\"üéâ All validations passed! Knowledge graph is ready for queries.\")\n",
    "elif validation_score >= max_score * 0.75:\n",
    "    print(f\"‚úÖ Most validations passed. System is functional.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Some validations failed. Check configuration and retry building.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building Metrics & Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Building Session Metrics & Performance\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "üéØ Session Overview:\n",
      "  Holdings Processed: 5\n",
      "  Documents Processed: 29\n",
      "  Building Successful: True\n",
      "\n",
      "‚è±Ô∏è Performance Metrics:\n",
      "  Data Ingestion Time: 529.51s\n",
      "  Graph Building Time: 529.51s\n",
      "  Total Processing Time: 1059.01s\n",
      "\n",
      "üìà Efficiency Analysis:\n",
      "  Processing Rate: 0.05 documents/second\n",
      "  Holdings Rate: 0.01 holdings/second\n",
      "\n",
      "üèóÔ∏è Architecture Efficiency:\n",
      "  ICE Simplified: 2,508 lines of code\n",
      "  Code Reduction: 83% (vs 15,000 line original)\n",
      "  Files Count: 5 core modules\n",
      "  Dependencies: Direct LightRAG wrapper\n",
      "  Token Efficiency: 4,000x better than GraphRAG\n",
      "\n",
      "‚úÖ Building Session Summary:\n",
      "  üéâ Knowledge graph building completed successfully\n",
      "  üìä 29 documents processed\n",
      "  üöÄ System ready for intelligent investment queries\n",
      "  üí° Proceed to ice_query_workflow.ipynb for analysis\n",
      "\n",
      "üîó Next Steps:\n",
      "  1. Review building metrics and validate storage\n",
      "  2. Run ice_query_workflow.ipynb for portfolio analysis\n",
      "  3. Test different LightRAG query modes\n",
      "  4. Monitor system performance and optimize as needed\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive building session metrics\n",
    "print(f\"\\nüìä Building Session Metrics & Performance\")\n",
    "print(f\"‚îÅ\" * 50)\n",
    "\n",
    "session_metrics = {\n",
    "    'holdings_count': len(holdings),\n",
    "    'total_processing_time': 0.0,\n",
    "    'documents_processed': 0,\n",
    "    'building_successful': False\n",
    "}\n",
    "\n",
    "# Collect metrics from ingestion and building\n",
    "if 'ingestion_result' in locals() and ingestion_result:\n",
    "    if 'metrics' in ingestion_result:\n",
    "        session_metrics['ingestion_time'] = ingestion_result['metrics'].get('processing_time', 0.0)\n",
    "    session_metrics['documents_processed'] = ingestion_result.get('total_documents', 0)\n",
    "\n",
    "if 'building_result' in locals() and building_result:\n",
    "    if building_result.get('status') == 'success':\n",
    "        session_metrics['building_successful'] = True\n",
    "    if 'metrics' in building_result:\n",
    "        building_time = building_result['metrics'].get('building_time', building_result['metrics'].get('update_time', 0.0))\n",
    "        session_metrics['building_time'] = building_time\n",
    "\n",
    "# Calculate total time\n",
    "if 'pipeline_stats' in locals():\n",
    "    session_metrics['total_processing_time'] = pipeline_stats.get('processing_time', 0.0)\n",
    "\n",
    "print(f\"üéØ Session Overview:\")\n",
    "print(f\"  Holdings Processed: {session_metrics['holdings_count']}\")\n",
    "print(f\"  Documents Processed: {session_metrics['documents_processed']}\")\n",
    "print(f\"  Building Successful: {session_metrics['building_successful']}\")\n",
    "\n",
    "if session_metrics.get('ingestion_time', 0) > 0:\n",
    "    print(f\"\\n‚è±Ô∏è Performance Metrics:\")\n",
    "    print(f\"  Data Ingestion Time: {session_metrics['ingestion_time']:.2f}s\")\n",
    "    if session_metrics.get('building_time', 0) > 0:\n",
    "        print(f\"  Graph Building Time: {session_metrics['building_time']:.2f}s\")\n",
    "        print(f\"  Total Processing Time: {session_metrics['ingestion_time'] + session_metrics['building_time']:.2f}s\")\n",
    "    \n",
    "    print(f\"\\nüìà Efficiency Analysis:\")\n",
    "    if session_metrics['documents_processed'] > 0:\n",
    "        docs_per_second = session_metrics['documents_processed'] / session_metrics['ingestion_time']\n",
    "        print(f\"  Processing Rate: {docs_per_second:.2f} documents/second\")\n",
    "    \n",
    "    holdings_per_second = session_metrics['holdings_count'] / session_metrics['ingestion_time']\n",
    "    print(f\"  Holdings Rate: {holdings_per_second:.2f} holdings/second\")\n",
    "\n",
    "# Architecture efficiency comparison\n",
    "print(f\"\\nüèóÔ∏è Architecture Efficiency:\")\n",
    "print(f\"  ICE Simplified: 2,508 lines of code\")\n",
    "print(f\"  Code Reduction: 83% (vs 15,000 line original)\")\n",
    "print(f\"  Files Count: 5 core modules\")\n",
    "print(f\"  Dependencies: Direct LightRAG wrapper\")\n",
    "print(f\"  Token Efficiency: 4,000x better than GraphRAG\")\n",
    "\n",
    "# Success summary\n",
    "print(f\"\\n‚úÖ Building Session Summary:\")\n",
    "if session_metrics['building_successful']:\n",
    "    print(f\"  üéâ Knowledge graph building completed successfully\")\n",
    "    print(f\"  üìä {session_metrics['documents_processed']} documents processed\")\n",
    "    print(f\"  üöÄ System ready for intelligent investment queries\")\n",
    "    print(f\"  üí° Proceed to ice_query_workflow.ipynb for analysis\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è Building completed with warnings or in demo mode\")\n",
    "    print(f\"  üìã Review configuration and API settings\")\n",
    "    print(f\"  üîß Consider running with fresh data if issues persist\")\n",
    "\n",
    "print(f\"\\nüîó Next Steps:\")\n",
    "print(f\"  1. Review building metrics and validate storage\")\n",
    "print(f\"  2. Run ice_query_workflow.ipynb for portfolio analysis\")\n",
    "print(f\"  3. Test different LightRAG query modes\")\n",
    "print(f\"  4. Monitor system performance and optimize as needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Building Workflow Complete\n",
    "\n",
    "**Summary**: This notebook demonstrated the complete ICE building workflow from data ingestion through knowledge graph construction.\n",
    "\n",
    "### Key Achievements\n",
    "‚úÖ **System Initialization**: ICE simplified architecture deployed  \n",
    "‚úÖ **Data Ingestion**: Portfolio data fetched and processed  \n",
    "‚úÖ **Graph Building**: LightRAG knowledge graph constructed  \n",
    "‚úÖ **Storage Validation**: All components verified and metrics tracked  \n",
    "\n",
    "### Architecture Benefits\n",
    "- **83% Code Reduction**: 2,508 lines vs 15,000 original\n",
    "- **4,000x Token Efficiency**: vs GraphRAG baseline\n",
    "- **Mode Flexibility**: Initial build or incremental updates\n",
    "- **Complete Metrics**: Processing time, success rates, storage stats\n",
    "\n",
    "### Next Steps\n",
    "1. **Launch Query Workflow**: Open `ice_query_workflow.ipynb`\n",
    "2. **Test Investment Intelligence**: Run portfolio analysis queries\n",
    "3. **Explore Query Modes**: Test all 5 LightRAG modes\n",
    "4. **Monitor Performance**: Track query response times and accuracy\n",
    "\n",
    "---\n",
    "**Ready for Investment Intelligence Queries** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
