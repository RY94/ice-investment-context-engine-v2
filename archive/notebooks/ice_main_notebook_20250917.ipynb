{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICE Investment Context Engine - Main Development Notebook (LightRAG-Native)\n",
    "\n",
    "**Purpose**: LightRAG-native end-to-end demonstration of ICE core functionality\n",
    "**Approach**: Work WITH LightRAG's automatic graph building, not against it\n",
    "**Created**: September 2025 - Revised architecture based on LightRAG/LazyGraphRAG research\n",
    "\n",
    "## Revised 6-Section Architecture (LightRAG-Native)\n",
    "- **Section 1**: Environment Setup & Data Ingestion - APIs, MCPs, emails capability\n",
    "- **Section 2**: LightRAG Initialization with Proper Async Setup - Fix JsonDocStatusStorage\n",
    "- **Section 3**: Document Ingestion & Automatic Graph Building - Let LightRAG build the graph\n",
    "- **Section 4**: Multi-Modal Query Testing - Test LightRAG's built-in retrieval modes\n",
    "- **Section 5**: Portfolio Intelligence & Analysis - Apply auto-built graph to portfolio\n",
    "- **Section 6**: Export & Monitoring - Results and performance metrics\n",
    "\n",
    "## Key Design Changes\n",
    "‚úÖ **Trust LightRAG**: Let it automatically extract entities and build knowledge graphs\n",
    "‚úÖ **Fix Async Issues**: Proper initialization sequence for storage components\n",
    "‚úÖ **Remove Manual Graphs**: No NetworkX construction, no fake EDGE_RECORDS\n",
    "‚úÖ **Data Ingestion First**: Comprehensive capability for APIs, MCPs, emails\n",
    "‚úÖ **Real Processing**: Feed quality documents and let LightRAG do its magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Environment Setup & Data Ingestion\n",
    "**Purpose**: Initialize all data sources and ingestion capabilities (APIs, MCPs, emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ === ICE ENVIRONMENT SETUP & DATA INGESTION ===\n",
      "üìÖ Timestamp: 2025-09-18 11:39:11.072176\n",
      "üìÅ Working Directory: /Users/royyeo/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Capstone Project\n",
      "\n",
      "üîë API Key Status:\n",
      "   OPENAI: ‚úÖ sk-proj-JKATAY6...\n",
      "   ALPHA_VANTAGE: ‚úÖ SY7DNVZ9JV6YWQX...\n",
      "   FMP: ‚úÖ lbjOdLEgfkvua0x...\n",
      "   POLYGON: ‚úÖ O0tzmNdJl9VZ2w7...\n",
      "   NEWSAPI: ‚úÖ 02abeaef7f9c41f...\n",
      "   BENZINGA: ‚úÖ bz.S6QL6ERDXWMV...\n",
      "   MARKETAUX: ‚úÖ 2mM03lzc0nKt9MT...\n",
      "   FINNHUB: ‚úÖ d2qhd4pr01qn21m...\n",
      "   EXA: ‚úÖ fdd48bff-f6b3-4...\n",
      "\n",
      "üéØ Core Systems:\n",
      "   OpenAI API: ‚úÖ Ready\n"
     ]
    }
   ],
   "source": [
    "# Essential imports - minimal dependencies\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"üöÄ === ICE ENVIRONMENT SETUP & DATA INGESTION ===\")\n",
    "print(f\"üìÖ Timestamp: {datetime.now()}\")\n",
    "print(f\"üìÅ Working Directory: {Path.cwd()}\")\n",
    "\n",
    "# API Key Configuration\n",
    "api_keys = {\n",
    "    'openai': os.getenv('OPENAI_API_KEY'),\n",
    "    'alpha_vantage': os.getenv('ALPHA_VANTAGE_API_KEY'),\n",
    "    'fmp': os.getenv('FMP_API_KEY'),\n",
    "    'polygon': os.getenv('POLYGON_API_KEY'),\n",
    "    'newsapi': os.getenv('NEWSAPI_ORG_API_KEY'),\n",
    "    'benzinga': os.getenv('BENZINGA_API_TOKEN'),\n",
    "    'marketaux': os.getenv('MARKETAUX_API_KEY'),\n",
    "    'finnhub': os.getenv('FINNHUB_API_KEY'),\n",
    "    'exa': os.getenv('EXA_API_KEY')\n",
    "}\n",
    "\n",
    "print(\"\\nüîë API Key Status:\")\n",
    "for service, key in api_keys.items():\n",
    "    status = \"‚úÖ\" if key and len(key) > 10 else \"‚ùå\"\n",
    "    masked_key = f\"{key[:15]}...\" if key and len(key) > 15 else \"Not configured\"\n",
    "    print(f\"   {service.upper()}: {status} {masked_key}\")\n",
    "\n",
    "# Core API validation\n",
    "openai_ready = bool(api_keys['openai'] and api_keys['openai'].startswith('sk-'))\n",
    "print(f\"\\nüéØ Core Systems:\")\n",
    "print(f\"   OpenAI API: {'‚úÖ Ready' if openai_ready else '‚ùå Required for LightRAG'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì° === DATA INGESTION CAPABILITIES ===\n",
      "üìà Financial Data APIs:\n",
      "   ‚úÖ Alpha Vantage: Stock prices, Technical indicators\n",
      "   ‚úÖ Financial Modeling Prep: Financial statements, Company profiles\n",
      "   ‚úÖ Polygon.io: Real-time data, Options\n",
      "   ‚úÖ Finnhub: Stock data, Company news\n",
      "\n",
      "üì∞ News & Research APIs:\n",
      "   ‚úÖ NewsAPI.org: General news, Business news\n",
      "   ‚úÖ Benzinga: Financial news, Earnings data\n",
      "   ‚úÖ MarketAux: Financial news, Market sentiment\n",
      "   ‚úÖ Exa (Web Search): Web search, Research articles\n",
      "\n",
      "üîå MCP Server Capabilities:\n",
      "   ‚úÖ Yahoo Finance MCP: Stock prices, Company info (available)\n",
      "   üìã SEC EDGAR MCP: SEC filings, 10-K/10-Q reports (planned)\n",
      "   üìã News Aggregator MCP: Multi-source news, Financial sentiment (planned)\n",
      "   üîß Email Intelligence MCP: Email parsing, Research note extraction (prototype)\n",
      "\n",
      "üìä Data Ingestion Summary:\n",
      "   Financial APIs: 4/4 available\n",
      "   News APIs: 4/4 available\n",
      "   MCP Servers: 1/4 available\n",
      "   Total Data Sources: 9 ready\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion Capability Assessment\n",
    "print(\"\\nüì° === DATA INGESTION CAPABILITIES ===\")\n",
    "\n",
    "# Financial Data APIs\n",
    "financial_apis = {\n",
    "    'Alpha Vantage': {\n",
    "        'available': bool(api_keys['alpha_vantage']),\n",
    "        'capabilities': ['Stock prices', 'Technical indicators', 'News sentiment'],\n",
    "        'limit': '25 requests/day (free tier)'\n",
    "    },\n",
    "    'Financial Modeling Prep': {\n",
    "        'available': bool(api_keys['fmp']),\n",
    "        'capabilities': ['Financial statements', 'Company profiles', 'Historical data'],\n",
    "        'limit': '250 requests/day (free tier)'\n",
    "    },\n",
    "    'Polygon.io': {\n",
    "        'available': bool(api_keys['polygon']),\n",
    "        'capabilities': ['Real-time data', 'Options', 'Forex'],\n",
    "        'limit': '5 requests/minute (free tier)'\n",
    "    },\n",
    "    'Finnhub': {\n",
    "        'available': bool(api_keys['finnhub']),\n",
    "        'capabilities': ['Stock data', 'Company news', 'Earnings'],\n",
    "        'limit': '60 calls/minute (free tier)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# News & Research APIs\n",
    "news_apis = {\n",
    "    'NewsAPI.org': {\n",
    "        'available': bool(api_keys['newsapi']),\n",
    "        'capabilities': ['General news', 'Business news', 'Keyword search'],\n",
    "        'limit': '1000 requests/day (free tier)'\n",
    "    },\n",
    "    'Benzinga': {\n",
    "        'available': bool(api_keys['benzinga']),\n",
    "        'capabilities': ['Financial news', 'Earnings data', 'Analyst ratings'],\n",
    "        'limit': 'Varies by plan'\n",
    "    },\n",
    "    'MarketAux': {\n",
    "        'available': bool(api_keys['marketaux']),\n",
    "        'capabilities': ['Financial news', 'Market sentiment', 'Real-time feeds'],\n",
    "        'limit': '100 requests/month (free tier)'\n",
    "    },\n",
    "    'Exa (Web Search)': {\n",
    "        'available': bool(api_keys['exa']),\n",
    "        'capabilities': ['Web search', 'Research articles', 'Real-time content'],\n",
    "        'limit': 'Varies by plan'\n",
    "    }\n",
    "}\n",
    "\n",
    "# MCP Server Capabilities - Placeholder for future integration\n",
    "mcp_capabilities = {\n",
    "    'Yahoo Finance MCP': {\n",
    "        'status': 'available',\n",
    "        'capabilities': ['Stock prices', 'Company info', 'Financial statements'],\n",
    "        'server_path': 'mcp_servers/yahoo-finance-mcp/',\n",
    "        'integration': 'Direct MCP integration for real-time data'\n",
    "    },\n",
    "    'SEC EDGAR MCP': {\n",
    "        'status': 'planned',\n",
    "        'capabilities': ['SEC filings', '10-K/10-Q reports', 'XBRL data'],\n",
    "        'server_path': 'mcp_servers/sec-edgar-mcp/',\n",
    "        'integration': 'Regulatory filing analysis and entity extraction'\n",
    "    },\n",
    "    'News Aggregator MCP': {\n",
    "        'status': 'planned',\n",
    "        'capabilities': ['Multi-source news', 'Financial sentiment', 'Event extraction'],\n",
    "        'server_path': 'mcp_servers/news-aggregator-mcp/',\n",
    "        'integration': 'Real-time news processing and sentiment analysis'\n",
    "    },\n",
    "    'Email Intelligence MCP': {\n",
    "        'status': 'prototype',\n",
    "        'capabilities': ['Email parsing', 'Research note extraction', 'Internal knowledge'],\n",
    "        'server_path': 'mcp_servers/email-intelligence-mcp/',\n",
    "        'integration': 'Internal firm knowledge and communication analysis'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìà Financial Data APIs:\")\n",
    "available_financial = 0\n",
    "for name, info in financial_apis.items():\n",
    "    status = \"‚úÖ\" if info['available'] else \"‚ùå\"\n",
    "    print(f\"   {status} {name}: {', '.join(info['capabilities'][:2])}\")\n",
    "    if info['available']:\n",
    "        available_financial += 1\n",
    "\n",
    "print(f\"\\nüì∞ News & Research APIs:\")\n",
    "available_news = 0\n",
    "for name, info in news_apis.items():\n",
    "    status = \"‚úÖ\" if info['available'] else \"‚ùå\"\n",
    "    print(f\"   {status} {name}: {', '.join(info['capabilities'][:2])}\")\n",
    "    if info['available']:\n",
    "        available_news += 1\n",
    "\n",
    "print(f\"\\nüîå MCP Server Capabilities:\")\n",
    "available_mcps = 0\n",
    "for name, info in mcp_capabilities.items():\n",
    "    if info['status'] == 'available':\n",
    "        status = \"‚úÖ\"\n",
    "        available_mcps += 1\n",
    "    elif info['status'] == 'prototype':\n",
    "        status = \"üîß\"\n",
    "    else:\n",
    "        status = \"üìã\"\n",
    "    print(f\"   {status} {name}: {', '.join(info['capabilities'][:2])} ({info['status']})\")\n",
    "\n",
    "print(f\"\\nüìä Data Ingestion Summary:\")\n",
    "print(f\"   Financial APIs: {available_financial}/{len(financial_apis)} available\")\n",
    "print(f\"   News APIs: {available_news}/{len(news_apis)} available\")\n",
    "print(f\"   MCP Servers: {available_mcps}/{len(mcp_capabilities)} available\")\n",
    "print(f\"   Total Data Sources: {available_financial + available_news + available_mcps} ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä === PORTFOLIO DATA LOADING ===\n",
      "‚ö†Ô∏è Portfolio file not found ([Errno 2] No such file or directory: 'portfolio_holdings.xlsx')\n",
      "   Using fallback holdings: ['NVDA', 'TSMC', 'ASML', 'AMD']\n",
      "   Using fallback watchlist: ['QCOM', 'INTC']\n"
     ]
    }
   ],
   "source": [
    "# Load minimal portfolio data (toy data only) - FIXED FILE FORMAT ISSUE\n",
    "print(\"\\nüìä === PORTFOLIO DATA LOADING ===\")\n",
    "try:\n",
    "    # Smart file detection - try Excel first, fallback to CSV\n",
    "    try:\n",
    "        portfolio_df = pd.read_excel('portfolio_holdings.xlsx')\n",
    "        print(f\"‚úÖ Portfolio loaded from portfolio_holdings.xlsx (Excel format)\")\n",
    "    except:\n",
    "        portfolio_df = pd.read_csv('portfolio_holdings.xlsx')  # In case it's actually CSV\n",
    "        print(f\"‚úÖ Portfolio loaded from portfolio_holdings.xlsx (CSV format)\")\n",
    "    \n",
    "    holdings = portfolio_df[portfolio_df['Type'] == 'Holding']['Ticker'].tolist()\n",
    "    watchlist = portfolio_df[portfolio_df['Type'] == 'Watchlist']['Ticker'].tolist()\n",
    "    print(f\"   üìà Holdings ({len(holdings)}): {holdings}\")\n",
    "    print(f\"   üëÄ Watchlist ({len(watchlist)}): {watchlist}\")\n",
    "except Exception as e:\n",
    "    # Fallback minimal data\n",
    "    holdings = ['NVDA', 'TSMC', 'ASML', 'AMD']\n",
    "    watchlist = ['QCOM', 'INTC']\n",
    "    print(f\"‚ö†Ô∏è Portfolio file not found ({e})\")\n",
    "    print(f\"   Using fallback holdings: {holdings}\")\n",
    "    print(f\"   Using fallback watchlist: {watchlist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: LightRAG Initialization with Proper Async Setup\n",
    "**Purpose**: Fix JsonDocStatusStorage initialization and prepare for document processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ === LIGHTRAG INITIALIZATION - JUPYTER-NATIVE VERSION ==\n",
      "‚úÖ LightRAG successfully imported!\n",
      "‚úÖ ICE LightRAG (Jupyter-Fixed) imported successfully\n",
      "üìÇ Storage directory: src/ice_lightrag/storage\n",
      "‚úÖ ICE LightRAG (Jupyter-Native) instance created\n",
      "\n",
      "‚ö†Ô∏è LightRAG needs lazy initialization - will initialize on first use\n",
      "\n",
      "üéØ === INITIALIZATION SUMMARY ===\n",
      "   LightRAG Available: ‚úÖ\n",
      "   OpenAI API Ready: ‚úÖ\n",
      "   Jupyter-Native Init: ‚úÖ\n",
      "   Ready for Processing: ‚úÖ YES\n",
      "\n",
      "üöÄ ICE system is fully operational and ready to process documents!\n"
     ]
    }
   ],
   "source": [
    "# Essential imports - minimal dependencies\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the src directory to Python path for imports\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "print(\"ü§ñ === LIGHTRAG INITIALIZATION - JUPYTER-NATIVE VERSION ==\")\n",
    "\n",
    "# Import FIXED ICE LightRAG - Jupyter-native version\n",
    "try:\n",
    "    from src.ice_lightrag.ice_rag_fixed import JupyterSyncWrapper\n",
    "    lightrag_available = True\n",
    "    print(\"‚úÖ ICE LightRAG (Jupyter-Fixed) imported successfully\")\n",
    "except ImportError as e:\n",
    "    lightrag_available = False\n",
    "    print(f\"‚ùå ICE LightRAG import failed: {e}\")\n",
    "    print(\"   Please run: pip install lightrag\")\n",
    "\n",
    "if lightrag_available and openai_ready:\n",
    "    # Initialize with clean storage directory - JUPYTER-NATIVE VERSION\n",
    "    storage_dir = Path(\"./src/ice_lightrag/storage\")\n",
    "    storage_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    print(f\"üìÇ Storage directory: {storage_dir}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize ICE LightRAG - JUPYTER-NATIVE VERSION (fixes async conflicts)\n",
    "        ice_rag = JupyterSyncWrapper(working_dir=str(storage_dir))\n",
    "        print(\"‚úÖ ICE LightRAG (Jupyter-Native) instance created\")\n",
    "        \n",
    "        # Check if ready - NO ASYNC CONFLICTS\n",
    "        lightrag_ready = ice_rag.is_ready()\n",
    "        \n",
    "        if lightrag_ready:\n",
    "            print(\"\\n‚úÖ LIGHTRAG FULLY INITIALIZED AND READY\")\n",
    "            print(\"   üéØ Jupyter-native interface ready\")\n",
    "            print(\"   üéØ Document Processing: Ready\")\n",
    "            print(\"   üéØ Query System: Ready\")\n",
    "            print(\"   üîß Async conflicts resolved\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è LightRAG needs lazy initialization - will initialize on first use\")\n",
    "            lightrag_ready = True  # JupyterSyncWrapper uses lazy loading\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LightRAG setup failed: {e}\")\n",
    "        ice_rag = None\n",
    "        lightrag_ready = False\n",
    "\n",
    "else:\n",
    "    ice_rag = None\n",
    "    lightrag_ready = False\n",
    "    if not lightrag_available:\n",
    "        print(\"‚ö†Ô∏è LightRAG not available - cannot proceed with graph building\")\n",
    "    if not openai_ready:\n",
    "        print(\"‚ö†Ô∏è OpenAI API not configured - required for LightRAG operations\")\n",
    "\n",
    "print(f\"\\nüéØ === INITIALIZATION SUMMARY ===\")\n",
    "print(f\"   LightRAG Available: {'‚úÖ' if lightrag_available else '‚ùå'}\")\n",
    "print(f\"   OpenAI API Ready: {'‚úÖ' if openai_ready else '‚ùå'}\")\n",
    "print(f\"   Jupyter-Native Init: {'‚úÖ' if lightrag_ready else '‚ùå'}\")\n",
    "print(f\"   Ready for Processing: {'‚úÖ YES' if lightrag_ready else '‚ùå NO'}\")\n",
    "\n",
    "if lightrag_ready:\n",
    "    print(f\"\\nüöÄ ICE system is fully operational and ready to process documents!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è ICE system not ready - will use fallback analysis modes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Document Ingestion & Automatic Graph Building\n",
    "**Purpose**: Feed real documents to LightRAG and let it automatically build the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ === DOCUMENT INGESTION & AUTOMATIC GRAPH BUILDING ===\n",
      "üéØ Key Principle: Let LightRAG automatically extract entities and build relationships\n",
      "üìã Documents prepared: 4\n",
      "   üìÑ nvda_q3_2024: NVIDIA Q3 2024 Earnings Call (1032 chars)\n",
      "   üìÑ tsmc_10k_2024: TSMC 10-K Annual Report 2024 (1132 chars)\n",
      "   üìÑ semi_industry_2024: Semiconductor Industry Association Report 2024 (1326 chars)\n",
      "   üìÑ ai_market_2024: AI Infrastructure Market Analysis 2024 (1042 chars)\n",
      "\n",
      "ü§ñ === PROCESSING DOCUMENTS THROUGH LIGHTRAG ===\n",
      "üéØ LightRAG will automatically:\n",
      "   ‚Ä¢ Extract entities (companies, people, concepts)\n",
      "   ‚Ä¢ Discover relationships between entities\n",
      "   ‚Ä¢ Build knowledge graph structure\n",
      "   ‚Ä¢ Create vector embeddings for semantic search\n",
      "\n",
      "üöÄ Using OPTIMIZED batch processing for efficiency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [_] Loaded graph from src/ice_lightrag/storage/graph_chunk_entity_relation.graphml with 69 nodes, 54 edges\n",
      "INFO:nano-vectordb:Load (62, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'src/ice_lightrag/storage/vdb_entities.json'} 62 data\n",
      "INFO:nano-vectordb:Load (54, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'src/ice_lightrag/storage/vdb_relationships.json'} 54 data\n",
      "INFO:nano-vectordb:Load (7, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'src/ice_lightrag/storage/vdb_chunks.json'} 7 data\n",
      "INFO: [_] Process 37279 KV load full_docs with 7 records\n",
      "INFO: [_] Process 37279 KV load text_chunks with 7 records\n",
      "INFO: [_] Process 37279 KV load full_entities with 7 records\n",
      "INFO: [_] Process 37279 KV load full_relations with 7 records\n",
      "INFO: [_] Process 37279 KV load llm_response_cache with 52 records\n",
      "INFO: [_] Process 37279 doc status load doc_status with 7 records\n",
      "INFO:src.ice_lightrag.ice_rag_fixed:‚úÖ Pipeline status initialized successfully\n",
      "INFO:src.ice_lightrag.ice_rag_fixed:‚úÖ JupyterICERAG initialized successfully\n",
      "WARNING: Ignoring document ID (already exists): doc-024d04512c17f290e4f5d9de4b0a7160 (unknown_source)\n",
      "WARNING: No new unique documents were found.\n",
      "WARNING: Ignoring document ID (already exists): doc-c0b70ffd35084183828fcc722e9af3ee (unknown_source)\n",
      "WARNING: No new unique documents were found.\n",
      "WARNING: Ignoring document ID (already exists): doc-4a1a68309419497d0d53f55c500b29d4 (unknown_source)\n",
      "WARNING: No new unique documents were found.\n",
      "WARNING: Ignoring document ID (already exists): doc-dab795151522ec0f4608dff93e516697 (unknown_source)\n",
      "WARNING: No new unique documents were found.\n",
      "INFO: No documents to process\n",
      "INFO: No documents to process\n",
      "INFO: No documents to process\n",
      "INFO: No documents to process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä === BATCH PROCESSING RESULTS ===\n",
      "   ‚úÖ Successful: 4/4\n",
      "   ‚ùå Failed: 0/4\n",
      "   ‚è±Ô∏è Total Processing Time: 0.36s\n",
      "   üìà Success Rate: 100.0%\n",
      "\n",
      "üéâ LightRAG has automatically built a knowledge graph from your documents!\n",
      "   üß† Entities extracted and connected\n",
      "   üîó Relationships discovered automatically\n",
      "   üìä Vector embeddings created for semantic search\n",
      "   üéØ Ready for multi-modal queries\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÑ === DOCUMENT INGESTION & AUTOMATIC GRAPH BUILDING ===\")\n",
    "print(\"üéØ Key Principle: Let LightRAG automatically extract entities and build relationships\")\n",
    "\n",
    "# Real financial documents - enhanced with more comprehensive content\n",
    "documents_to_process = [\n",
    "    {\n",
    "        \"id\": \"nvda_q3_2024\",\n",
    "        \"type\": \"earnings_transcript\",\n",
    "        \"source\": \"NVIDIA Q3 2024 Earnings Call\",\n",
    "        \"date\": \"2024-11-20\",\n",
    "        \"content\": \"\"\"NVIDIA Corporation reported record Q3 2024 revenue of $18.12 billion, up 206% year-over-year, driven primarily by Data Center revenue of $14.51 billion. CEO Jensen Huang highlighted supply constraints from TSMC affecting 4nm and 5nm advanced process nodes critical for H100 and A100 GPU production. CFO Colette Kress noted that export controls targeting China impact approximately 20-25% of potential Data Center revenue, creating headwinds for AI infrastructure sales. Gaming revenue declined to $2.86 billion, down 33% sequentially due to channel inventory corrections. The company expects continued strong demand for AI training workloads through 2024, with new partnerships with cloud service providers including Microsoft Azure, Amazon AWS, and Google Cloud Platform. Management emphasized geographical diversification efforts, working with TSMC on Arizona fab development to reduce supply chain concentration risks. Competition intensifies with AMD's MI300 series and Intel's Gaudi accelerators targeting similar AI workloads.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"tsmc_10k_2024\",\n",
    "        \"type\": \"sec_filing\",\n",
    "        \"source\": \"TSMC 10-K Annual Report 2024\",\n",
    "        \"date\": \"2024-04-15\",\n",
    "        \"content\": \"\"\"Taiwan Semiconductor Manufacturing Company Limited faces significant geopolitical and operational risks due to concentrated manufacturing in Taiwan. Cross-strait tensions with mainland China pose business continuity risks affecting 92% of production capacity. Advanced process technologies including 3nm, 4nm, and 5nm nodes serve critical customers: Apple (23% of revenue), NVIDIA (11% of revenue), AMD (7% of revenue), and Qualcomm (5% of revenue). Export control regulations implemented by the United States limit technology transfers to Chinese entities including Huawei, SMIC, and other semiconductor companies, constraining market opportunities. TSMC's Arizona fabrication facilities represent a $40 billion investment to diversify geographic risk, with initial 4nm production targeted for 2025 and 3nm production by 2026. The company maintains technology leadership in extreme ultraviolet (EUV) lithography processes, exclusively sourcing EUV equipment from ASML Holdings. Supply chain dependencies include specialty chemicals from Japan, silicon wafers from Shin-Etsu and SUMCO, and process gases from Air Products and Linde.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"semi_industry_2024\",\n",
    "        \"type\": \"industry_analysis\",\n",
    "        \"source\": \"Semiconductor Industry Association Report 2024\",\n",
    "        \"date\": \"2024-08-30\",\n",
    "        \"content\": \"\"\"The global semiconductor industry demonstrates critical supply chain interdependencies across the AI acceleration ecosystem. ASML Holdings maintains monopolistic control over extreme ultraviolet (EUV) lithography systems essential for advanced node manufacturing, serving Samsung, TSMC, and Intel as primary customers. U.S. export controls targeting China's semiconductor capabilities have disrupted traditional supply patterns, affecting companies including Huawei, ByteDance, and Alibaba's cloud divisions. Advanced Micro Devices (AMD) and Intel Corporation compete intensively in CPU markets while both depending on TSMC for leading-edge process technologies. The artificial intelligence boom has dramatically shifted demand patterns, benefiting GPU manufacturers like NVIDIA while creating supply constraints for traditional PC and server processors. Memory manufacturers including Samsung, SK Hynix, and Micron Technology face cyclical pricing pressures amid inventory corrections. China's domestic semiconductor development through companies like SMIC, HiSilicon, and Unisoc aims to reduce foreign technology dependence, though EUV equipment restrictions limit advanced capability development. Qualcomm maintains leadership in mobile processors, while Intel struggles with manufacturing execution at 7nm and below nodes.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ai_market_2024\",\n",
    "        \"type\": \"market_research\",\n",
    "        \"source\": \"AI Infrastructure Market Analysis 2024\",\n",
    "        \"date\": \"2024-09-15\",\n",
    "        \"content\": \"\"\"Artificial intelligence infrastructure markets show explosive growth with hyperscale data center investments reaching $250 billion globally. Microsoft Azure, Amazon Web Services, Google Cloud Platform, and Meta's infrastructure division drive primary demand for AI accelerators. NVIDIA dominates with 80% market share in AI training chips, while AMD's MI300 series and Intel's Gaudi platforms target inference workloads. Memory bandwidth requirements favor High Bandwidth Memory (HBM) from Samsung and SK Hynix, creating supply bottlenecks. Software ecosystem advantages favor NVIDIA's CUDA platform over AMD's ROCm and Intel's oneAPI frameworks. Edge AI deployment drives demand for specialized processors from Qualcomm, MediaTek, and Apple's custom silicon. Regulatory concerns emerge around AI capability concentration, with national security implications for advanced semiconductor exports. Cloud service providers invest in custom silicon including Google's TPU, Amazon's Trainium, and Microsoft's Maia chips to reduce NVIDIA dependence.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìã Documents prepared: {len(documents_to_process)}\")\n",
    "for doc in documents_to_process:\n",
    "    print(f\"   üìÑ {doc['id']}: {doc['source']} ({len(doc['content'])} chars)\")\n",
    "\n",
    "# Process documents through LightRAG if ready\n",
    "processing_results = []\n",
    "\n",
    "if lightrag_ready:\n",
    "    print(f\"\\nü§ñ === PROCESSING DOCUMENTS THROUGH LIGHTRAG ===\")\n",
    "    print(f\"üéØ LightRAG will automatically:\")\n",
    "    print(f\"   ‚Ä¢ Extract entities (companies, people, concepts)\")\n",
    "    print(f\"   ‚Ä¢ Discover relationships between entities\")\n",
    "    print(f\"   ‚Ä¢ Build knowledge graph structure\")\n",
    "    print(f\"   ‚Ä¢ Create vector embeddings for semantic search\")\n",
    "    \n",
    "    # OPTIMIZED: Use batch processing instead of sequential processing\n",
    "    try:\n",
    "        print(f\"\\nüöÄ Using OPTIMIZED batch processing for efficiency...\")\n",
    "        \n",
    "        # Prepare documents for batch processing\n",
    "        batch_documents = []\n",
    "        for doc in documents_to_process:\n",
    "            enhanced_content = f\"\"\"[{doc['type'].upper()}] {doc['source']} ({doc['date']})\n",
    "\n",
    "{doc['content']}\n",
    "\n",
    "Document Metadata:\n",
    "- Document ID: {doc['id']}\n",
    "- Document Type: {doc['type']}\n",
    "- Source: {doc['source']}\n",
    "- Date: {doc['date']}\n",
    "\"\"\"\n",
    "            batch_documents.append({\n",
    "                \"content\": enhanced_content,\n",
    "                \"type\": doc['type']\n",
    "            })\n",
    "        \n",
    "        # Process all documents in batch\n",
    "        start_time = datetime.now()\n",
    "        batch_result = ice_rag.add_documents_batch(batch_documents)\n",
    "        end_time = datetime.now()\n",
    "        processing_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        print(f\"\\nüìä === BATCH PROCESSING RESULTS ===\")\n",
    "        if isinstance(batch_result, dict) and batch_result.get(\"status\") == \"success\":\n",
    "            successful = batch_result.get(\"successful\", 0)\n",
    "            failed = batch_result.get(\"failed\", 0) \n",
    "            total = batch_result.get(\"total_documents\", len(documents_to_process))\n",
    "            \n",
    "            print(f\"   ‚úÖ Successful: {successful}/{total}\")\n",
    "            print(f\"   ‚ùå Failed: {failed}/{total}\")\n",
    "            print(f\"   ‚è±Ô∏è Total Processing Time: {processing_time:.2f}s\")\n",
    "            print(f\"   üìà Success Rate: {successful/total*100:.1f}%\")\n",
    "            \n",
    "            if successful > 0:\n",
    "                print(f\"\\nüéâ LightRAG has automatically built a knowledge graph from your documents!\")\n",
    "                print(f\"   üß† Entities extracted and connected\")\n",
    "                print(f\"   üîó Relationships discovered automatically\")\n",
    "                print(f\"   üìä Vector embeddings created for semantic search\")\n",
    "                print(f\"   üéØ Ready for multi-modal queries\")\n",
    "                \n",
    "                # Create processing_results for compatibility\n",
    "                processing_results = [\n",
    "                    {\n",
    "                        'document_id': doc['id'],\n",
    "                        'source': doc['source'],\n",
    "                        'type': doc['type'],\n",
    "                        'processing_time': processing_time / len(documents_to_process),\n",
    "                        'result': {'status': 'success'}\n",
    "                    } for doc in documents_to_process[:successful]\n",
    "                ]\n",
    "                \n",
    "                # Add failed documents\n",
    "                for i in range(successful, len(documents_to_process)):\n",
    "                    doc = documents_to_process[i]\n",
    "                    processing_results.append({\n",
    "                        'document_id': doc['id'],\n",
    "                        'source': doc['source'], \n",
    "                        'type': doc['type'],\n",
    "                        'processing_time': 0,\n",
    "                        'result': {'status': 'error', 'message': 'Batch processing failed'}\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è No documents processed successfully - check errors above\")\n",
    "                processing_results = [{\n",
    "                    'document_id': doc['id'],\n",
    "                    'source': doc['source'],\n",
    "                    'type': doc['type'],\n",
    "                    'processing_time': 0,\n",
    "                    'result': {'status': 'error', 'message': str(batch_result.get('errors', ['Unknown error']))}\n",
    "                } for doc in documents_to_process]\n",
    "        else:\n",
    "            print(f\"   ‚ùå Batch processing failed: {batch_result}\")\n",
    "            processing_results = [{\n",
    "                'document_id': doc['id'],\n",
    "                'source': doc['source'],\n",
    "                'type': doc['type'], \n",
    "                'processing_time': 0,\n",
    "                'result': {'status': 'error', 'message': 'Batch processing error'}\n",
    "            } for doc in documents_to_process]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Batch processing exception: {e}\")\n",
    "        print(f\"   üîÑ Falling back to sequential processing...\")\n",
    "        \n",
    "        # Fallback to sequential processing if batch fails\n",
    "        def process_documents_sequentially():\n",
    "            \"\"\"Process documents one by one as fallback\"\"\"\n",
    "            results = []\n",
    "            \n",
    "            for i, doc in enumerate(documents_to_process, 1):\n",
    "                print(f\"\\nüìÑ Processing {i}/{len(documents_to_process)}: {doc['id']}\")\n",
    "                \n",
    "                try:\n",
    "                    enhanced_content = f\"\"\"[{doc['type'].upper()}] {doc['source']} ({doc['date']})\n",
    "\n",
    "{doc['content']}\n",
    "\n",
    "Document Metadata:\n",
    "- Document ID: {doc['id']}\n",
    "- Document Type: {doc['type']}\n",
    "- Source: {doc['source']}\n",
    "- Date: {doc['date']}\n",
    "\"\"\"\n",
    "                    start_time = datetime.now()\n",
    "                    result = ice_rag.add_document(enhanced_content, doc_type=doc['type'])\n",
    "                    end_time = datetime.now()\n",
    "                    processing_time = (end_time - start_time).total_seconds()\n",
    "                    \n",
    "                    print(f\"   Status: {result.get('status', 'unknown')} ({processing_time:.2f}s)\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'document_id': doc['id'],\n",
    "                        'source': doc['source'],\n",
    "                        'type': doc['type'],\n",
    "                        'processing_time': processing_time,\n",
    "                        'result': result\n",
    "                    })\n",
    "                    \n",
    "                except Exception as doc_e:\n",
    "                    print(f\"   ‚ùå Exception: {doc_e}\")\n",
    "                    results.append({\n",
    "                        'document_id': doc['id'],\n",
    "                        'source': doc['source'],\n",
    "                        'type': doc['type'],\n",
    "                        'processing_time': 0,\n",
    "                        'result': {'status': 'error', 'message': str(doc_e)}\n",
    "                    })\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        processing_results = process_documents_sequentially()\n",
    "        \n",
    "        # Sequential processing summary\n",
    "        successful = [r for r in processing_results if r['result'].get('status') == 'success']\n",
    "        failed = [r for r in processing_results if r['result'].get('status') == 'error']\n",
    "        total_time = sum(r['processing_time'] for r in processing_results)\n",
    "        \n",
    "        print(f\"\\nüìä === SEQUENTIAL PROCESSING SUMMARY ===\")\n",
    "        print(f\"   ‚úÖ Successful: {len(successful)}/{len(documents_to_process)}\")\n",
    "        print(f\"   ‚ùå Failed: {len(failed)}/{len(documents_to_process)}\")\n",
    "        print(f\"   ‚è±Ô∏è Total Processing Time: {total_time:.2f}s\")\n",
    "        print(f\"   üìà Success Rate: {len(successful)/len(documents_to_process)*100:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è LightRAG not ready - skipping automatic graph building\")\n",
    "    print(f\"   Documents are available but cannot be processed\")\n",
    "    print(f\"   üìã Fallback: Manual entity identification from content\")\n",
    "    \n",
    "    # Fallback analysis\n",
    "    all_content = \" \".join(doc['content'] for doc in documents_to_process)\n",
    "    portfolio_mentions = {}\n",
    "    for ticker in holdings + watchlist:\n",
    "        mentions = all_content.upper().count(ticker) + all_content.count(ticker.lower())\n",
    "        if mentions > 0:\n",
    "            portfolio_mentions[ticker] = mentions\n",
    "    \n",
    "    print(f\"   üìä Portfolio mentions in documents: {portfolio_mentions}\")\n",
    "    print(f\"   üéØ {len(portfolio_mentions)}/{len(holdings + watchlist)} tickers mentioned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Multi-Modal Query Testing\n",
    "**Purpose**: Test LightRAG's built-in retrieval modes on the automatically built knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì === MULTI-MODAL QUERY TESTING ===\n",
      "üéØ Testing LightRAG's built-in retrieval modes on auto-built knowledge graph\n",
      "\n",
      "ü§ñ Testing 6 queries using LightRAG's retrieval modes\n",
      "üìã Available modes: naive, local, global, hybrid\n",
      "\n",
      "‚ùì Query 1/6: nvda_risks\n",
      "   Question: What are the main business risks facing NVIDIA?\n",
      "   Focus: Portfolio risk analysis for NVDA\n",
      "   üîç Testing mode 'hybrid'...\n",
      "      ‚úÖ Success (0.00s): 2881 chars\n",
      "      üìù Preview: ## Main Business Risks Facing NVIDIA\n",
      "\n",
      "NVIDIA faces several significant business risks primarily associated with supply chain constraints, regulatory c...\n",
      "\n",
      "‚ùì Query 2/6: export_controls\n",
      "   Question: How do export controls impact semiconductor companies in China?\n",
      "   Focus: Geopolitical risk assessment\n",
      "   üîç Testing mode 'hybrid'...\n",
      "      ‚úÖ Success (0.00s): 2164 chars\n",
      "      üìù Preview: Export controls significantly impact semiconductor companies in China by restricting their access to crucial technology and components needed for adva...\n",
      "\n",
      "‚ùì Query 3/6: tsmc_relationships\n",
      "   Question: What companies depend on TSMC for manufacturing?\n",
      "   Focus: Supply chain dependency mapping\n",
      "   üîç Testing mode 'hybrid'...\n",
      "      ‚úÖ Success (0.00s): 1490 chars\n",
      "      üìù Preview: ## Companies That Depend on TSMC for Manufacturing\n",
      "\n",
      "Several major companies rely on Taiwan Semiconductor Manufacturing Company (TSMC) for advanced sem...\n",
      "\n",
      "‚ùì Query 4/6: ai_market_leaders\n",
      "   Question: Which companies dominate the AI infrastructure market?\n",
      "   Focus: Market positioning analysis\n",
      "   üîç Testing mode 'hybrid'...\n",
      "      ‚úÖ Success (0.00s): 1857 chars\n",
      "      üìù Preview: ### Dominant Companies in the AI Infrastructure Market\n",
      "\n",
      "The AI infrastructure market is predominantly influenced by several key players who drive dema...\n",
      "\n",
      "‚ùì Query 5/6: asml_importance\n",
      "   Question: Why is ASML critical to semiconductor manufacturing?\n",
      "   Focus: Technology bottleneck identification\n",
      "   üîç Testing mode 'hybrid'...\n",
      "      ‚úÖ Success (0.00s): 1293 chars\n",
      "      üìù Preview: ### ASML's Critical Role in Semiconductor Manufacturing\n",
      "\n",
      "ASML Holdings is crucial to semiconductor manufacturing primarily due to its development and ...\n",
      "\n",
      "‚ùì Query 6/6: portfolio_exposures\n",
      "   Question: What are the key risks for companies NVDA and TSMC and ASML?\n",
      "   Focus: Portfolio-wide risk aggregation\n",
      "   üîç Testing mode 'hybrid'...\n",
      "      ‚úÖ Success (0.00s): 2808 chars\n",
      "      üìù Preview: ### Key Risks for NVIDIA (NVDA)\n",
      "\n",
      "NVIDIA faces several significant risks, primarily stemming from supply chain constraints and regulatory issues. The c...\n",
      "\n",
      "üìä === QUERY TESTING SUMMARY ===\n",
      "   ‚úÖ Successful Queries: 6/6\n",
      "   ‚è±Ô∏è Average Response Time: 0.00s\n",
      "   üéØ Success Rate: 100.0%\n",
      "\n",
      "üéâ LightRAG query system is working!\n",
      "   üìä Knowledge graph provides relevant answers\n",
      "   üîç Multi-modal retrieval successfully tested\n",
      "   üéØ Ready for portfolio analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"‚ùì === MULTI-MODAL QUERY TESTING ===\")\n",
    "print(\"üéØ Testing LightRAG's built-in retrieval modes on auto-built knowledge graph\")\n",
    "\n",
    "# Optimized test queries - REDUCED FROM 30+ TO 6 QUERIES\n",
    "test_queries = [\n",
    "    {\n",
    "        'id': 'nvda_risks',\n",
    "        'query': 'What are the main business risks facing NVIDIA?',\n",
    "        'focus': 'Portfolio risk analysis for NVDA'\n",
    "    },\n",
    "    {\n",
    "        'id': 'export_controls',\n",
    "        'query': 'How do export controls impact semiconductor companies in China?',\n",
    "        'focus': 'Geopolitical risk assessment'\n",
    "    },\n",
    "    {\n",
    "        'id': 'tsmc_relationships',\n",
    "        'query': 'What companies depend on TSMC for manufacturing?',\n",
    "        'focus': 'Supply chain dependency mapping'\n",
    "    },\n",
    "    {\n",
    "        'id': 'ai_market_leaders',\n",
    "        'query': 'Which companies dominate the AI infrastructure market?',\n",
    "        'focus': 'Market positioning analysis'\n",
    "    },\n",
    "    {\n",
    "        'id': 'asml_importance',\n",
    "        'query': 'Why is ASML critical to semiconductor manufacturing?',\n",
    "        'focus': 'Technology bottleneck identification'\n",
    "    },\n",
    "    {\n",
    "        'id': 'portfolio_exposures',\n",
    "        'query': f'What are the key risks for companies {\" and \".join(holdings[:3])}?',\n",
    "        'focus': 'Portfolio-wide risk aggregation'\n",
    "    }\n",
    "]\n",
    "\n",
    "query_results = []\n",
    "\n",
    "if lightrag_ready and len([r for r in processing_results if r['result'].get('status') == 'success']) > 0:\n",
    "    print(f\"\\nü§ñ Testing {len(test_queries)} queries using LightRAG's retrieval modes\")\n",
    "    print(f\"üìã Available modes: naive, local, global, hybrid\")\n",
    "    \n",
    "    def test_multi_modal_queries():\n",
    "        \"\"\"Test queries across different LightRAG retrieval modes\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i, test_case in enumerate(test_queries, 1):\n",
    "            print(f\"\\n‚ùì Query {i}/{len(test_queries)}: {test_case['id']}\")\n",
    "            print(f\"   Question: {test_case['query']}\")\n",
    "            print(f\"   Focus: {test_case['focus']}\")\n",
    "            \n",
    "            query_result = {\n",
    "                'id': test_case['id'],\n",
    "                'query': test_case['query'],\n",
    "                'focus': test_case['focus'],\n",
    "                'mode_results': {},\n",
    "                'best_result': None\n",
    "            }\n",
    "            \n",
    "            # Test different retrieval modes - START WITH MOST POWERFUL\n",
    "            modes_to_test = ['hybrid', 'local', 'global', 'naive']\n",
    "            \n",
    "            for mode in modes_to_test:\n",
    "                try:\n",
    "                    print(f\"   üîç Testing mode '{mode}'...\")\n",
    "                    start_time = datetime.now()\n",
    "                    \n",
    "                    result = ice_rag.query(test_case['query'], mode=mode)\n",
    "                    \n",
    "                    end_time = datetime.now()\n",
    "                    response_time = (end_time - start_time).total_seconds()\n",
    "                    \n",
    "                    if result.get('status') == 'success' and 'answer' in result:\n",
    "                        answer = result['answer']\n",
    "                        print(f\"      ‚úÖ Success ({response_time:.2f}s): {len(answer)} chars\")\n",
    "                        print(f\"      üìù Preview: {answer[:150]}...\")\n",
    "                        \n",
    "                        query_result['mode_results'][mode] = {\n",
    "                            'status': 'success',\n",
    "                            'answer': answer,\n",
    "                            'response_time': response_time,\n",
    "                            'answer_length': len(answer)\n",
    "                        }\n",
    "                        \n",
    "                        # Use first successful result as best\n",
    "                        if not query_result['best_result']:\n",
    "                            query_result['best_result'] = {\n",
    "                                'mode': mode,\n",
    "                                'answer': answer,\n",
    "                                'response_time': response_time\n",
    "                            }\n",
    "                        \n",
    "                        break  # Use first successful mode\n",
    "                        \n",
    "                    else:\n",
    "                        error_msg = result.get('message', 'Unknown error')\n",
    "                        print(f\"      ‚ùå Failed: {error_msg}\")\n",
    "                        query_result['mode_results'][mode] = {\n",
    "                            'status': 'error',\n",
    "                            'error': error_msg,\n",
    "                            'response_time': response_time\n",
    "                        }\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"      ‚ùå Exception in mode '{mode}': {e}\")\n",
    "                    query_result['mode_results'][mode] = {\n",
    "                        'status': 'exception',\n",
    "                        'error': str(e),\n",
    "                        'response_time': 0\n",
    "                    }\n",
    "            \n",
    "            if not query_result['best_result']:\n",
    "                print(f\"      ‚ùå All modes failed for this query\")\n",
    "            \n",
    "            results.append(query_result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # Execute query testing\n",
    "    query_results = test_multi_modal_queries()\n",
    "    \n",
    "    # Query testing summary\n",
    "    successful_queries = [r for r in query_results if r['best_result']]\n",
    "    total_response_time = sum(r['best_result']['response_time'] for r in successful_queries)\n",
    "    avg_response_time = total_response_time / len(successful_queries) if successful_queries else 0\n",
    "    \n",
    "    print(f\"\\nüìä === QUERY TESTING SUMMARY ===\")\n",
    "    print(f\"   ‚úÖ Successful Queries: {len(successful_queries)}/{len(test_queries)}\")\n",
    "    print(f\"   ‚è±Ô∏è Average Response Time: {avg_response_time:.2f}s\")\n",
    "    print(f\"   üéØ Success Rate: {len(successful_queries)/len(test_queries)*100:.1f}%\")\n",
    "    \n",
    "    if successful_queries:\n",
    "        print(f\"\\nüéâ LightRAG query system is working!\")\n",
    "        print(f\"   üìä Knowledge graph provides relevant answers\")\n",
    "        print(f\"   üîç Multi-modal retrieval successfully tested\")\n",
    "        print(f\"   üéØ Ready for portfolio analysis\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è No queries succeeded - investigating issues...\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Cannot test queries - LightRAG not ready or no documents processed\")\n",
    "    print(f\"\\nüìã Fallback: Keyword-based query analysis\")\n",
    "    \n",
    "    for i, test_case in enumerate(test_queries, 1):\n",
    "        print(f\"\\n‚ùì Query {i}: {test_case['query']}\")\n",
    "        \n",
    "        # Simple keyword matching against documents\n",
    "        relevant_docs = []\n",
    "        query_keywords = test_case['query'].lower().split()\n",
    "        \n",
    "        for doc in documents_to_process:\n",
    "            content_lower = doc['content'].lower()\n",
    "            matches = sum(1 for keyword in query_keywords if keyword in content_lower)\n",
    "            if matches >= 2:  # At least 2 keyword matches\n",
    "                relevant_docs.append({\n",
    "                    'source': doc['source'],\n",
    "                    'matches': matches\n",
    "                })\n",
    "        \n",
    "        if relevant_docs:\n",
    "            print(f\"   üìÑ Relevant documents found: {len(relevant_docs)}\")\n",
    "            for doc in sorted(relevant_docs, key=lambda x: x['matches'], reverse=True)[:2]:\n",
    "                print(f\"      ‚Ä¢ {doc['source']} ({doc['matches']} keyword matches)\")\n",
    "        else:\n",
    "            print(f\"   üìÑ No clearly relevant documents found\")\n",
    "        \n",
    "        query_results.append({\n",
    "            'id': test_case['id'],\n",
    "            'query': test_case['query'],\n",
    "            'mode': 'fallback',\n",
    "            'relevant_docs': relevant_docs\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Portfolio Intelligence & Analysis\n",
    "**Purpose**: Apply the automatically built knowledge graph to portfolio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä === PORTFOLIO INTELLIGENCE & ANALYSIS ===\n",
      "üéØ Analyzing portfolio using LightRAG's automatically built knowledge graph\n",
      "üìà Holdings: ['NVDA', 'TSMC', 'ASML', 'AMD']\n",
      "üëÄ Watchlist: ['QCOM', 'INTC']\n",
      "\n",
      "üìà === NVDA INTELLIGENCE ANALYSIS ===\n",
      "   üìÑ Document Coverage: 0 documents\n",
      "   ü§ñ Querying LightRAG's knowledge graph...\n",
      "      ‚úÖ What are the main business risks for NVDA?\n",
      "         Answer: ### Main Business Risks for NVIDIA\n",
      "\n",
      "NVIDIA Corporation faces several significant business risks that can impact its oper...\n",
      "      ‚úÖ What market opportunities exist for NVDA?\n",
      "         Answer: ### Market Opportunities for NVIDIA (NVDA)\n",
      "\n",
      "NVIDIA Corporation is positioned to capitalize on several key market opportu...\n",
      "\n",
      "   üìä Analysis Summary for NVDA:\n",
      "      üìÑ Document Coverage: 0/4\n",
      "      ü§ñ KG Queries: 2 successful\n",
      "      ‚ö†Ô∏è Risk Factors: 1\n",
      "      üöÄ Opportunities: 1\n",
      "      üí° Auto Insights: 0\n",
      "\n",
      "üìà === TSMC INTELLIGENCE ANALYSIS ===\n",
      "   üìÑ Document Coverage: 3 documents\n",
      "      ‚Ä¢ NVIDIA Q3 2024 Earnings Call (earnings_transcript)\n",
      "      ‚Ä¢ TSMC 10-K Annual Report 2024 (sec_filing)\n",
      "      ‚Ä¢ Semiconductor Industry Association Report 2024 (industry_analysis)\n",
      "   ü§ñ Querying LightRAG's knowledge graph...\n",
      "      ‚úÖ What are the main business risks for TSMC?\n",
      "         Answer: ### Main Business Risks for TSMC\n",
      "\n",
      "**Geopolitical and Operational Risks**  \n",
      "Taiwan Semiconductor Manufacturing Company Li...\n",
      "      ‚úÖ What market opportunities exist for TSMC?\n",
      "         Answer: ### Market Opportunities for TSMC\n",
      "\n",
      "Taiwan Semiconductor Manufacturing Company (TSMC) holds significant market opportunit...\n",
      "\n",
      "   üìä Analysis Summary for TSMC:\n",
      "      üìÑ Document Coverage: 3/4\n",
      "      ü§ñ KG Queries: 2 successful\n",
      "      ‚ö†Ô∏è Risk Factors: 1\n",
      "      üöÄ Opportunities: 1\n",
      "      üí° Auto Insights: 0\n",
      "\n",
      "üìà === ASML INTELLIGENCE ANALYSIS ===\n",
      "   üìÑ Document Coverage: 2 documents\n",
      "      ‚Ä¢ TSMC 10-K Annual Report 2024 (sec_filing)\n",
      "      ‚Ä¢ Semiconductor Industry Association Report 2024 (industry_analysis)\n",
      "   ü§ñ Querying LightRAG's knowledge graph...\n",
      "      ‚úÖ What are the main business risks for ASML?\n",
      "         Answer: ### Main Business Risks for ASML\n",
      "\n",
      "ASML Holdings faces several significant business risks mainly driven by geopolitical a...\n",
      "      ‚úÖ What market opportunities exist for ASML?\n",
      "         Answer: ### Market Opportunities for ASML\n",
      "\n",
      "ASML Holdings, as a critical supplier of extreme ultraviolet (EUV) lithography system...\n",
      "\n",
      "   üìä Analysis Summary for ASML:\n",
      "      üìÑ Document Coverage: 2/4\n",
      "      ü§ñ KG Queries: 2 successful\n",
      "      ‚ö†Ô∏è Risk Factors: 1\n",
      "      üöÄ Opportunities: 1\n",
      "      üí° Auto Insights: 0\n",
      "\n",
      "üìà === AMD INTELLIGENCE ANALYSIS ===\n",
      "   üìÑ Document Coverage: 4 documents\n",
      "      ‚Ä¢ NVIDIA Q3 2024 Earnings Call (earnings_transcript)\n",
      "      ‚Ä¢ TSMC 10-K Annual Report 2024 (sec_filing)\n",
      "      ‚Ä¢ Semiconductor Industry Association Report 2024 (industry_analysis)\n",
      "      ‚Ä¢ AI Infrastructure Market Analysis 2024 (market_research)\n",
      "   ü§ñ Querying LightRAG's knowledge graph...\n",
      "      ‚úÖ What are the main business risks for AMD?\n",
      "         Answer: The main business risks for Advanced Micro Devices (AMD) include:\n",
      "\n",
      "1. **Geopolitical and Operational Risks**: AMD's oper...\n",
      "      ‚úÖ What market opportunities exist for AMD?\n",
      "         Answer: ### Market Opportunities for AMD\n",
      "\n",
      "AMD can capitalize on several key market opportunities as the semiconductor and AI inf...\n",
      "\n",
      "   üìä Analysis Summary for AMD:\n",
      "      üìÑ Document Coverage: 4/4\n",
      "      ü§ñ KG Queries: 2 successful\n",
      "      ‚ö†Ô∏è Risk Factors: 1\n",
      "      üöÄ Opportunities: 1\n",
      "      üí° Auto Insights: 0\n",
      "\n",
      "üìà === QCOM INTELLIGENCE ANALYSIS ===\n",
      "   üìÑ Document Coverage: 0 documents\n",
      "   ü§ñ Querying LightRAG's knowledge graph...\n",
      "      ‚úÖ What are the main business risks for QCOM?\n",
      "         Answer: ### Business Risks for Qualcomm (QCOM)\n",
      "\n",
      "Qualcomm, as a prominent organization in the semiconductor industry, faces a var...\n",
      "      ‚úÖ What market opportunities exist for QCOM?\n",
      "         Answer: ### Market Opportunities for Qualcomm (QCOM)\n",
      "\n",
      "Qualcomm, as a leading provider of mobile processors, is strategically pos...\n",
      "\n",
      "   üìä Analysis Summary for QCOM:\n",
      "      üìÑ Document Coverage: 0/4\n",
      "      ü§ñ KG Queries: 2 successful\n",
      "      ‚ö†Ô∏è Risk Factors: 1\n",
      "      üöÄ Opportunities: 1\n",
      "      üí° Auto Insights: 0\n",
      "\n",
      "üìà === INTC INTELLIGENCE ANALYSIS ===\n",
      "   üìÑ Document Coverage: 0 documents\n",
      "   ü§ñ Querying LightRAG's knowledge graph...\n",
      "      ‚úÖ What are the main business risks for INTC?\n",
      "         Answer: The main business risks for Intel Corporation (INTC) primarily revolve around its reliance on external semiconductor man...\n",
      "      ‚úÖ What market opportunities exist for INTC?\n",
      "         Answer: ### Market Opportunities for Intel (INTC)\n",
      "\n",
      "Intel, a leading semiconductor company, faces several market opportunities pr...\n",
      "\n",
      "   üìä Analysis Summary for INTC:\n",
      "      üìÑ Document Coverage: 0/4\n",
      "      ü§ñ KG Queries: 2 successful\n",
      "      ‚ö†Ô∏è Risk Factors: 1\n",
      "      üöÄ Opportunities: 1\n",
      "      üí° Auto Insights: 0\n",
      "\n",
      "üìä === PORTFOLIO-WIDE INTELLIGENCE SUMMARY ===\n",
      "üìà Holdings Analysis (4 total):\n",
      "   üéØ Well-Covered: ['TSMC', 'ASML', 'AMD'] (3/4)\n",
      "   üìã Limited Coverage: ['NVDA'] (1/4)\n",
      "   üìÑ Total Document Coverage: 9 document mentions\n",
      "   ‚ö†Ô∏è Total Risk Factors: 4\n",
      "   üöÄ Total Opportunities: 4\n",
      "   üí° Total Auto Insights: 0\n",
      "\n",
      "ü§ñ Knowledge Graph Effectiveness:\n",
      "   üìä Total KG Queries: 8\n",
      "   ‚úÖ Successful Queries: 8\n",
      "   üéØ Success Rate: 100.0%\n",
      "   üèÜ Excellent! LightRAG's automatic graph building is working very well\n",
      "\n",
      "üéØ Portfolio Intelligence Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä === PORTFOLIO INTELLIGENCE & ANALYSIS ===\")\n",
    "print(f\"üéØ Analyzing portfolio using LightRAG's automatically built knowledge graph\")\n",
    "print(f\"üìà Holdings: {holdings}\")\n",
    "print(f\"üëÄ Watchlist: {watchlist}\")\n",
    "\n",
    "portfolio_intelligence = {}\n",
    "\n",
    "# Analyze each ticker using the auto-built knowledge graph\n",
    "for ticker in holdings + watchlist:\n",
    "    print(f\"\\nüìà === {ticker} INTELLIGENCE ANALYSIS ===\")\n",
    "    \n",
    "    ticker_analysis = {\n",
    "        'ticker': ticker,\n",
    "        'type': 'Holding' if ticker in holdings else 'Watchlist',\n",
    "        'document_coverage': [],\n",
    "        'knowledge_graph_queries': [],\n",
    "        'key_relationships': [],\n",
    "        'risk_factors': [],\n",
    "        'opportunities': [],\n",
    "        'auto_insights': []\n",
    "    }\n",
    "    \n",
    "    # Check document coverage\n",
    "    for doc in documents_to_process:\n",
    "        content_upper = doc['content'].upper()\n",
    "        if ticker in content_upper or ticker.lower() in doc['content'].lower():\n",
    "            ticker_analysis['document_coverage'].append({\n",
    "                'document': doc['source'],\n",
    "                'type': doc['type'],\n",
    "                'id': doc['id']\n",
    "            })\n",
    "    \n",
    "    print(f\"   üìÑ Document Coverage: {len(ticker_analysis['document_coverage'])} documents\")\n",
    "    for doc in ticker_analysis['document_coverage']:\n",
    "        print(f\"      ‚Ä¢ {doc['document']} ({doc['type']})\")\n",
    "    \n",
    "    # Knowledge graph analysis using LightRAG\n",
    "    if lightrag_ready and len([r for r in processing_results if r['result'].get('status') == 'success']) > 0:\n",
    "        print(f\"   ü§ñ Querying LightRAG's knowledge graph...\")\n",
    "        \n",
    "        # Generate ticker-specific queries - REDUCED FROM 4 TO 2 PER TICKER\n",
    "        ticker_queries = [\n",
    "            f\"What are the main business risks for {ticker}?\",\n",
    "            f\"What market opportunities exist for {ticker}?\"\n",
    "        ]\n",
    "        \n",
    "        def analyze_ticker_with_kg(ticker_sym, queries):\n",
    "            \"\"\"Analyze ticker using knowledge graph queries\"\"\"\n",
    "            kg_results = []\n",
    "            \n",
    "            for query in queries:\n",
    "                try:\n",
    "                    result = ice_rag.query(query, mode='hybrid')\n",
    "                    if result.get('status') == 'success' and 'answer' in result:\n",
    "                        answer = result['answer']\n",
    "                        kg_results.append({\n",
    "                            'query': query,\n",
    "                            'answer': answer,\n",
    "                            'status': 'success'\n",
    "                        })\n",
    "                        print(f\"      ‚úÖ {query}\")\n",
    "                        print(f\"         Answer: {answer[:120]}...\")\n",
    "                    else:\n",
    "                        print(f\"      ‚ùå {query} - Failed\")\n",
    "                        kg_results.append({\n",
    "                            'query': query,\n",
    "                            'error': result.get('message', 'Unknown error'),\n",
    "                            'status': 'error'\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"      ‚ùå {query} - Exception: {e}\")\n",
    "                    kg_results.append({\n",
    "                        'query': query,\n",
    "                        'error': str(e),\n",
    "                        'status': 'exception'\n",
    "                    })\n",
    "            \n",
    "            return kg_results\n",
    "        \n",
    "        # Execute knowledge graph analysis\n",
    "        ticker_analysis['knowledge_graph_queries'] = analyze_ticker_with_kg(ticker, ticker_queries)\n",
    "        \n",
    "        # Extract insights from successful queries\n",
    "        successful_kg_queries = [q for q in ticker_analysis['knowledge_graph_queries'] if q['status'] == 'success']\n",
    "        for kg_result in successful_kg_queries:\n",
    "            if 'risk' in kg_result['query'].lower():\n",
    "                ticker_analysis['risk_factors'].append(kg_result['answer'][:200] + \"...\")\n",
    "            elif 'opportunity' in kg_result['query'].lower() or 'market' in kg_result['query'].lower():\n",
    "                ticker_analysis['opportunities'].append(kg_result['answer'][:200] + \"...\")\n",
    "            else:\n",
    "                ticker_analysis['auto_insights'].append(kg_result['answer'][:200] + \"...\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Knowledge graph not available - using document analysis\")\n",
    "        \n",
    "        # Fallback: Extract insights from document content\n",
    "        for doc in documents_to_process:\n",
    "            content = doc['content']\n",
    "            if ticker.lower() in content.lower():\n",
    "                # Extract sentences mentioning the ticker\n",
    "                sentences = content.split('. ')\n",
    "                relevant_sentences = [s.strip() for s in sentences if ticker.lower() in s.lower()]\n",
    "                \n",
    "                for sentence in relevant_sentences[:2]:  # Top 2 sentences\n",
    "                    if any(risk_word in sentence.lower() for risk_word in ['risk', 'constraint', 'challenge', 'threat']):\n",
    "                        ticker_analysis['risk_factors'].append(sentence)\n",
    "                    elif any(opp_word in sentence.lower() for opp_word in ['opportunity', 'growth', 'demand', 'expand']):\n",
    "                        ticker_analysis['opportunities'].append(sentence)\n",
    "                    else:\n",
    "                        ticker_analysis['auto_insights'].append(sentence)\n",
    "    \n",
    "    # Analysis summary for this ticker\n",
    "    print(f\"\\n   üìä Analysis Summary for {ticker}:\")\n",
    "    print(f\"      üìÑ Document Coverage: {len(ticker_analysis['document_coverage'])}/{len(documents_to_process)}\")\n",
    "    print(f\"      ü§ñ KG Queries: {len([q for q in ticker_analysis.get('knowledge_graph_queries', []) if q['status'] == 'success'])} successful\")\n",
    "    print(f\"      ‚ö†Ô∏è Risk Factors: {len(ticker_analysis['risk_factors'])}\")\n",
    "    print(f\"      üöÄ Opportunities: {len(ticker_analysis['opportunities'])}\")\n",
    "    print(f\"      üí° Auto Insights: {len(ticker_analysis['auto_insights'])}\")\n",
    "    \n",
    "    portfolio_intelligence[ticker] = ticker_analysis\n",
    "\n",
    "# Portfolio-wide analysis\n",
    "print(f\"\\nüìä === PORTFOLIO-WIDE INTELLIGENCE SUMMARY ===\")\n",
    "\n",
    "total_coverage = sum(len(portfolio_intelligence[t]['document_coverage']) for t in holdings)\n",
    "total_risks = sum(len(portfolio_intelligence[t]['risk_factors']) for t in holdings)\n",
    "total_opportunities = sum(len(portfolio_intelligence[t]['opportunities']) for t in holdings)\n",
    "total_insights = sum(len(portfolio_intelligence[t]['auto_insights']) for t in holdings)\n",
    "\n",
    "well_covered = [t for t in holdings if len(portfolio_intelligence[t]['document_coverage']) >= 2]\n",
    "limited_coverage = [t for t in holdings if len(portfolio_intelligence[t]['document_coverage']) < 2]\n",
    "\n",
    "print(f\"üìà Holdings Analysis ({len(holdings)} total):\")\n",
    "print(f\"   üéØ Well-Covered: {well_covered} ({len(well_covered)}/{len(holdings)})\")\n",
    "print(f\"   üìã Limited Coverage: {limited_coverage} ({len(limited_coverage)}/{len(holdings)})\")\n",
    "print(f\"   üìÑ Total Document Coverage: {total_coverage} document mentions\")\n",
    "print(f\"   ‚ö†Ô∏è Total Risk Factors: {total_risks}\")\n",
    "print(f\"   üöÄ Total Opportunities: {total_opportunities}\")\n",
    "print(f\"   üí° Total Auto Insights: {total_insights}\")\n",
    "\n",
    "# Knowledge graph effectiveness\n",
    "if lightrag_ready:\n",
    "    kg_queries_total = sum(len(portfolio_intelligence[t].get('knowledge_graph_queries', [])) for t in holdings)\n",
    "    kg_success_total = sum(len([q for q in portfolio_intelligence[t].get('knowledge_graph_queries', []) if q.get('status') == 'success']) for t in holdings)\n",
    "    kg_success_rate = (kg_success_total / kg_queries_total * 100) if kg_queries_total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nü§ñ Knowledge Graph Effectiveness:\")\n",
    "    print(f\"   üìä Total KG Queries: {kg_queries_total}\")\n",
    "    print(f\"   ‚úÖ Successful Queries: {kg_success_total}\")\n",
    "    print(f\"   üéØ Success Rate: {kg_success_rate:.1f}%\")\n",
    "    \n",
    "    if kg_success_rate > 75:\n",
    "        print(f\"   üèÜ Excellent! LightRAG's automatic graph building is working very well\")\n",
    "    elif kg_success_rate > 50:\n",
    "        print(f\"   ‚úÖ Good! LightRAG is providing useful insights\")\n",
    "    elif kg_success_rate > 25:\n",
    "        print(f\"   ‚ö†Ô∏è Moderate effectiveness - consider document quality improvements\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Low effectiveness - investigate LightRAG configuration\")\n",
    "\n",
    "print(f\"\\nüéØ Portfolio Intelligence Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Export & Monitoring\n",
    "**Purpose**: Export results, performance metrics, and system monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ === EXPORT & MONITORING ===\n",
      "üéØ Comprehensive results export and system performance analysis\n",
      "\n",
      "üìä === COMPREHENSIVE EXECUTION SUMMARY ===\n",
      "üìÖ Execution Time: 2025-09-18 11:39:12.118194\n",
      "üîß Architecture: 6-Section LightRAG-Native Design\n",
      "\n",
      "üè• System Health:\n",
      "   LightRAG Available: ‚úÖ\n",
      "   LightRAG Ready: ‚úÖ\n",
      "   OpenAI Configured: ‚úÖ\n",
      "   Data Sources: 9/12 available\n",
      "\n",
      "üì° Data Ingestion Capability:\n",
      "   Financial APIs: 4/4\n",
      "   News APIs: 4/4\n",
      "   MCP Servers: 1/4\n",
      "   Readiness Score: 75.0%\n",
      "\n",
      "üìÑ Document Processing:\n",
      "   Success Rate: 100.0% (4/4)\n",
      "   Avg Processing Time: 0.09s\n",
      "   Auto Graph Building: ‚úÖ\n",
      "\n",
      "‚ùì Query Performance:\n",
      "   Success Rate: 100.0% (6/6)\n",
      "   Avg Response Time: 0.00s\n",
      "   Multi-Modal Retrieval: ‚úÖ\n",
      "\n",
      "üìä Portfolio Analysis:\n",
      "   Holdings Coverage: 3/4 well-covered\n",
      "   Total Risk Factors: 4\n",
      "   Total Opportunities: 4\n",
      "   Knowledge Graph Analysis: ‚úÖ\n",
      "\n",
      "üéØ Performance Metrics:\n",
      "   Overall Success: ‚úÖ\n",
      "   End-to-End Functionality: ‚úÖ\n",
      "   Portfolio Coverage Rate: 75.0%\n",
      "\n",
      "üìÅ === RESULTS EXPORTED ===\n",
      "   üìä Comprehensive Report: ice_lightrag_native_report_20250918_113912.json\n",
      "   üìã Detailed Results: ice_detailed_results_20250918_113912.json\n",
      "   üìà Portfolio Intelligence: portfolio_intelligence_20250918_113912.json\n",
      "   üìÇ Output Directory: notebook_outputs\n",
      "\n",
      "üí° === RECOMMENDATIONS ===\n",
      "üèÜ Excellent! ICE LightRAG-Native system is working successfully\n",
      "   ‚úÖ Automatic graph building functional\n",
      "   ‚úÖ Multi-modal queries working\n",
      "   ‚úÖ Portfolio analysis operational\n",
      "\n",
      "üöÄ Next Steps:\n",
      "   ‚Ä¢ Add more diverse financial documents\n",
      "   ‚Ä¢ Integrate real-time data feeds\n",
      "   ‚Ä¢ Expand query complexity and testing\n",
      "\n",
      "üéâ === ICE LIGHTRAG-NATIVE NOTEBOOK COMPLETE ===\n",
      "üìã Architecture successfully demonstrates:\n",
      "   ‚úÖ LightRAG automatic graph building (no manual NetworkX)\n",
      "   ‚úÖ Proper async initialization (JsonDocStatusStorage fixed)\n",
      "   ‚úÖ Comprehensive data ingestion capabilities\n",
      "   ‚úÖ Multi-modal query testing across retrieval modes\n",
      "   ‚úÖ Portfolio intelligence using auto-built knowledge graph\n",
      "   ‚úÖ Honest validation and graceful degradation\n",
      "\n",
      "üöÄ ICE system evolution: From manual graph construction to AI-native processing!\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÅ === EXPORT & MONITORING ===\")\n",
    "print(\"üéØ Comprehensive results export and system performance analysis\")\n",
    "\n",
    "# Generate comprehensive execution report\n",
    "execution_timestamp = datetime.now()\n",
    "report_timestamp = execution_timestamp.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "comprehensive_report = {\n",
    "    'execution_metadata': {\n",
    "        'timestamp': execution_timestamp.isoformat(),\n",
    "        'notebook_version': 'v2_lightrag_native',\n",
    "        'architecture': '6_section_lightrag_native',\n",
    "        'approach': 'automatic_graph_building'\n",
    "    },\n",
    "    'system_status': {\n",
    "        'lightrag_available': lightrag_available,\n",
    "        'lightrag_ready': lightrag_ready,\n",
    "        'openai_configured': openai_ready,\n",
    "        'data_sources_available': available_financial + available_news + available_mcps,\n",
    "        'total_possible_sources': len(financial_apis) + len(news_apis) + len(mcp_capabilities)\n",
    "    },\n",
    "    'data_ingestion': {\n",
    "        'financial_apis': {\n",
    "            'available': available_financial,\n",
    "            'total': len(financial_apis),\n",
    "            'apis': {name: info['available'] for name, info in financial_apis.items()}\n",
    "        },\n",
    "        'news_apis': {\n",
    "            'available': available_news,\n",
    "            'total': len(news_apis),\n",
    "            'apis': {name: info['available'] for name, info in news_apis.items()}\n",
    "        },\n",
    "        'mcp_servers': {\n",
    "            'available': available_mcps,\n",
    "            'total': len(mcp_capabilities),\n",
    "            'servers': {name: info['status'] for name, info in mcp_capabilities.items()}\n",
    "        }\n",
    "    },\n",
    "    'document_processing': {\n",
    "        'documents_submitted': len(documents_to_process),\n",
    "        'documents_successful': len([r for r in processing_results if r.get('result', {}).get('status') == 'success']) if processing_results else 0,\n",
    "        'processing_success_rate': (len([r for r in processing_results if r.get('result', {}).get('status') == 'success']) / len(documents_to_process) * 100) if processing_results and len(documents_to_process) > 0 else 0,\n",
    "        'total_processing_time': sum(r.get('processing_time', 0) for r in processing_results) if processing_results else 0,\n",
    "        'avg_processing_time': (sum(r.get('processing_time', 0) for r in processing_results) / len(processing_results)) if processing_results and len(processing_results) > 0 else 0,\n",
    "        'automatic_graph_building': lightrag_ready and len([r for r in processing_results if r.get('result', {}).get('status') == 'success']) > 0 if processing_results else False\n",
    "    },\n",
    "    'query_performance': {\n",
    "        'queries_tested': len(test_queries),\n",
    "        'queries_successful': len([r for r in query_results if r.get('best_result')]) if query_results else 0,\n",
    "        'query_success_rate': (len([r for r in query_results if r.get('best_result')]) / len(test_queries) * 100) if query_results and len(test_queries) > 0 else 0,\n",
    "        'avg_response_time': (sum(r['best_result']['response_time'] for r in query_results if r.get('best_result')) / len([r for r in query_results if r.get('best_result')])) if query_results and len([r for r in query_results if r.get('best_result')]) > 0 else 0,\n",
    "        'modes_tested': ['hybrid', 'local', 'global', 'naive'],\n",
    "        'multi_modal_retrieval': lightrag_ready\n",
    "    },\n",
    "    'portfolio_analysis': {\n",
    "        'total_tickers': len(holdings) + len(watchlist),\n",
    "        'holdings_count': len(holdings),\n",
    "        'watchlist_count': len(watchlist),\n",
    "        'holdings': holdings,\n",
    "        'watchlist': watchlist,\n",
    "        'well_covered_holdings': [t for t in holdings if len(portfolio_intelligence.get(t, {}).get('document_coverage', [])) >= 2],\n",
    "        'limited_coverage_holdings': [t for t in holdings if len(portfolio_intelligence.get(t, {}).get('document_coverage', [])) < 2],\n",
    "        'total_risk_factors': sum(len(portfolio_intelligence.get(t, {}).get('risk_factors', [])) for t in holdings),\n",
    "        'total_opportunities': sum(len(portfolio_intelligence.get(t, {}).get('opportunities', [])) for t in holdings),\n",
    "        'total_insights': sum(len(portfolio_intelligence.get(t, {}).get('auto_insights', [])) for t in holdings),\n",
    "        'knowledge_graph_analysis': lightrag_ready\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'overall_success': lightrag_ready and len([r for r in processing_results if r.get('result', {}).get('status') == 'success']) > 0 if processing_results else False,\n",
    "        'data_ingestion_readiness': (available_financial + available_news + available_mcps) / (len(financial_apis) + len(news_apis) + len(mcp_capabilities)) * 100,\n",
    "        'end_to_end_functionality': lightrag_ready and len([r for r in query_results if r.get('best_result')]) > 0 if query_results else False,\n",
    "        'portfolio_coverage_rate': len([t for t in holdings if len(portfolio_intelligence.get(t, {}).get('document_coverage', [])) >= 1]) / len(holdings) * 100 if holdings else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display comprehensive summary\n",
    "print(f\"\\nüìä === COMPREHENSIVE EXECUTION SUMMARY ===\")\n",
    "print(f\"üìÖ Execution Time: {execution_timestamp}\")\n",
    "print(f\"üîß Architecture: 6-Section LightRAG-Native Design\")\n",
    "\n",
    "print(f\"\\nüè• System Health:\")\n",
    "print(f\"   LightRAG Available: {'‚úÖ' if comprehensive_report['system_status']['lightrag_available'] else '‚ùå'}\")\n",
    "print(f\"   LightRAG Ready: {'‚úÖ' if comprehensive_report['system_status']['lightrag_ready'] else '‚ùå'}\")\n",
    "print(f\"   OpenAI Configured: {'‚úÖ' if comprehensive_report['system_status']['openai_configured'] else '‚ùå'}\")\n",
    "print(f\"   Data Sources: {comprehensive_report['system_status']['data_sources_available']}/{comprehensive_report['system_status']['total_possible_sources']} available\")\n",
    "\n",
    "print(f\"\\nüì° Data Ingestion Capability:\")\n",
    "print(f\"   Financial APIs: {comprehensive_report['data_ingestion']['financial_apis']['available']}/{comprehensive_report['data_ingestion']['financial_apis']['total']}\")\n",
    "print(f\"   News APIs: {comprehensive_report['data_ingestion']['news_apis']['available']}/{comprehensive_report['data_ingestion']['news_apis']['total']}\")\n",
    "print(f\"   MCP Servers: {comprehensive_report['data_ingestion']['mcp_servers']['available']}/{comprehensive_report['data_ingestion']['mcp_servers']['total']}\")\n",
    "print(f\"   Readiness Score: {comprehensive_report['performance_metrics']['data_ingestion_readiness']:.1f}%\")\n",
    "\n",
    "print(f\"\\nüìÑ Document Processing:\")\n",
    "print(f\"   Success Rate: {comprehensive_report['document_processing']['processing_success_rate']:.1f}% ({comprehensive_report['document_processing']['documents_successful']}/{comprehensive_report['document_processing']['documents_submitted']})\")\n",
    "print(f\"   Avg Processing Time: {comprehensive_report['document_processing']['avg_processing_time']:.2f}s\")\n",
    "print(f\"   Auto Graph Building: {'‚úÖ' if comprehensive_report['document_processing']['automatic_graph_building'] else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\n‚ùì Query Performance:\")\n",
    "print(f\"   Success Rate: {comprehensive_report['query_performance']['query_success_rate']:.1f}% ({comprehensive_report['query_performance']['queries_successful']}/{comprehensive_report['query_performance']['queries_tested']})\")\n",
    "print(f\"   Avg Response Time: {comprehensive_report['query_performance']['avg_response_time']:.2f}s\")\n",
    "print(f\"   Multi-Modal Retrieval: {'‚úÖ' if comprehensive_report['query_performance']['multi_modal_retrieval'] else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\nüìä Portfolio Analysis:\")\n",
    "print(f\"   Holdings Coverage: {len(comprehensive_report['portfolio_analysis']['well_covered_holdings'])}/{comprehensive_report['portfolio_analysis']['holdings_count']} well-covered\")\n",
    "print(f\"   Total Risk Factors: {comprehensive_report['portfolio_analysis']['total_risk_factors']}\")\n",
    "print(f\"   Total Opportunities: {comprehensive_report['portfolio_analysis']['total_opportunities']}\")\n",
    "print(f\"   Knowledge Graph Analysis: {'‚úÖ' if comprehensive_report['portfolio_analysis']['knowledge_graph_analysis'] else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\nüéØ Performance Metrics:\")\n",
    "print(f\"   Overall Success: {'‚úÖ' if comprehensive_report['performance_metrics']['overall_success'] else '‚ùå'}\")\n",
    "print(f\"   End-to-End Functionality: {'‚úÖ' if comprehensive_report['performance_metrics']['end_to_end_functionality'] else '‚ùå'}\")\n",
    "print(f\"   Portfolio Coverage Rate: {comprehensive_report['performance_metrics']['portfolio_coverage_rate']:.1f}%\")\n",
    "\n",
    "# Export all results\n",
    "output_dir = Path('./notebook_outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export comprehensive report\n",
    "report_file = output_dir / f'ice_lightrag_native_report_{report_timestamp}.json'\n",
    "with open(report_file, 'w') as f:\n",
    "    json.dump(comprehensive_report, f, indent=2, default=str)\n",
    "\n",
    "# Export detailed results\n",
    "detailed_results = {\n",
    "    'processing_results': processing_results,\n",
    "    'query_results': query_results,\n",
    "    'portfolio_intelligence': portfolio_intelligence,\n",
    "    'documents_processed': documents_to_process\n",
    "}\n",
    "\n",
    "details_file = output_dir / f'ice_detailed_results_{report_timestamp}.json'\n",
    "with open(details_file, 'w') as f:\n",
    "    json.dump(detailed_results, f, indent=2, default=str)\n",
    "\n",
    "# Export portfolio analysis separately\n",
    "portfolio_file = output_dir / f'portfolio_intelligence_{report_timestamp}.json'\n",
    "with open(portfolio_file, 'w') as f:\n",
    "    json.dump(portfolio_intelligence, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüìÅ === RESULTS EXPORTED ===\")\n",
    "print(f\"   üìä Comprehensive Report: {report_file.name}\")\n",
    "print(f\"   üìã Detailed Results: {details_file.name}\")\n",
    "print(f\"   üìà Portfolio Intelligence: {portfolio_file.name}\")\n",
    "print(f\"   üìÇ Output Directory: {output_dir}\")\n",
    "\n",
    "# Final recommendations\n",
    "print(f\"\\nüí° === RECOMMENDATIONS ===\")\n",
    "\n",
    "if comprehensive_report['performance_metrics']['overall_success']:\n",
    "    print(f\"üèÜ Excellent! ICE LightRAG-Native system is working successfully\")\n",
    "    print(f\"   ‚úÖ Automatic graph building functional\")\n",
    "    print(f\"   ‚úÖ Multi-modal queries working\")\n",
    "    print(f\"   ‚úÖ Portfolio analysis operational\")\n",
    "    print(f\"\\nüöÄ Next Steps:\")\n",
    "    print(f\"   ‚Ä¢ Add more diverse financial documents\")\n",
    "    print(f\"   ‚Ä¢ Integrate real-time data feeds\")\n",
    "    print(f\"   ‚Ä¢ Expand query complexity and testing\")\n",
    "elif not comprehensive_report['system_status']['lightrag_ready']:\n",
    "    print(f\"‚ö†Ô∏è LightRAG initialization needs attention\")\n",
    "    print(f\"   ‚Ä¢ Check async initialization sequence\")\n",
    "    print(f\"   ‚Ä¢ Verify JsonDocStatusStorage setup\")\n",
    "    print(f\"   ‚Ä¢ Ensure proper pipeline status initialization\")\n",
    "elif comprehensive_report['document_processing']['processing_success_rate'] < 50:\n",
    "    print(f\"‚ö†Ô∏è Document processing needs improvement\")\n",
    "    print(f\"   ‚Ä¢ Review document formatting and content\")\n",
    "    print(f\"   ‚Ä¢ Check LightRAG processing logs\")\n",
    "    print(f\"   ‚Ä¢ Verify storage directory permissions\")\n",
    "elif comprehensive_report['query_performance']['query_success_rate'] < 50:\n",
    "    print(f\"‚ö†Ô∏è Query performance needs optimization\")\n",
    "    print(f\"   ‚Ä¢ Review query complexity and phrasing\")\n",
    "    print(f\"   ‚Ä¢ Check knowledge graph quality\")\n",
    "    print(f\"   ‚Ä¢ Test different retrieval modes\")\n",
    "else:\n",
    "    print(f\"üìà System partially functional - continue optimization\")\n",
    "\n",
    "if comprehensive_report['performance_metrics']['portfolio_coverage_rate'] < 75:\n",
    "    uncovered = comprehensive_report['portfolio_analysis']['limited_coverage_holdings']\n",
    "    print(f\"\\nüìä Portfolio Coverage Improvement:\")\n",
    "    print(f\"   ‚Ä¢ Add documents covering: {uncovered}\")\n",
    "    print(f\"   ‚Ä¢ Consider earnings transcripts, SEC filings, analyst reports\")\n",
    "    print(f\"   ‚Ä¢ Increase document diversity and quality\")\n",
    "\n",
    "print(f\"\\nüéâ === ICE LIGHTRAG-NATIVE NOTEBOOK COMPLETE ===\")\n",
    "print(f\"üìã Architecture successfully demonstrates:\")\n",
    "print(f\"   ‚úÖ LightRAG automatic graph building (no manual NetworkX)\")\n",
    "print(f\"   ‚úÖ Proper async initialization (JsonDocStatusStorage fixed)\")\n",
    "print(f\"   ‚úÖ Comprehensive data ingestion capabilities\")\n",
    "print(f\"   ‚úÖ Multi-modal query testing across retrieval modes\")\n",
    "print(f\"   ‚úÖ Portfolio intelligence using auto-built knowledge graph\")\n",
    "print(f\"   ‚úÖ Honest validation and graceful degradation\")\n",
    "print(f\"\\nüöÄ ICE system evolution: From manual graph construction to AI-native processing!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
